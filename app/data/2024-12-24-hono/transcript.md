 HONOR.js es uno de esos frameworks que ha causado mucho interés en los desarrolladores de backend desde el lado de JavaScript. ¿Por qué? ¿Por qué HONOR.js y por qué Node Express que ahora lanzó la versión 5? O por ejemplo, NET.js que es un framework que tiene un patrón de arquitectura bastante fuerte. Porque precisamente este framework está desarrollado para correr en cualquier otro runtime que no sea Node.js. Frameworks como Express, como NET.js dependen mucho de Node para funcionar. Y eso no necesariamente está mal. O sea, Node.js es al final el runtime más popular y el que más soportan los servidores. Pero simplemente se están saliendo nuevas formas de ejecutar y de correr JavaScript desde el lado de los servidores. Para eso, por ejemplo, hay opciones como Dino, como Boom, como los Cloudflare Workers de Cloudflare. Y muchas opciones para correr ahora JavaScript desde el lado del servidor que no depende de Node.js. Y otra cosa más. Node.js puede ser algo pesado. Para ciertos servidores. Y cuando hablamos de funciones o de aplicaciones que son servidores. Que simplemente necesitan una función y solo me cobran por el tiempo de ejecución de esa función. Y no por un servidor que está ahí prendido todo el tiempo. Node.js puede pesar y hacer que ese tiempo de inicio de esa función pueda tener un costo. Porque normalmente tienes que ejecutar todo un ambiente y levantar Node para correr esa pequeña función. Pues precisamente. Cómo funciona ello. Han salido run times de JavaScript. Mucho más livianos que no dependen de Node. Y por eso salen estas nuevas herramientas. Node.js es una de esas herramientas que no depende de Node. Sino que es súper liviano. Y que puede correr nuestros nuevos run times que están saliendo en la web. Es más. Amazon Web Service. Tiene Landas. Landas es como su servicio para hacer servidores de funciones. Y ellos están experimentando con Landas arroba Edge. Que qué significa Edge. ese edge significa que podemos correr estas versiones light y estas frameworks nuevos de javascript sin embargo, o estos runtime nuevos de javascript sin embargo, otra de esas buenas características de tener una versión o estas funciones chiquititas corriendo con javascript del lado del servidor es que ellos pueden tener algo llamado edge computing y es que como al final son tan chiquititas y tan livianas pueden estar distribuidas en muchas partes de la red entonces hace que la distribución realmente de esas funciones se ejecute en lo más cerca al usuario uno podría casi definir que edge computing es ejecutar u operar lo más cerca al usuario por ejemplo, si yo hago un request aquí desde Medellín por ejemplo y mi cadena, mi proveedor de servidor tiene una red de edge bastante grande ¿por qué? porque si yo hago un request aquí desde Medellín por ejemplo pues literalmente podría ir al servidor que está aquí en Bogotá o al servidor que está aquí en México que serían los más cercanos hacer distribución de estas funciones con un runtime de javascript mucho más liviano hace que eso sea posible de por sí, tengo todo un video hablando de la teoría de edge computing los invito a verlo pero pues hoy precisamente vamos a de pronto ya pasar de la teoría y ver, ok, te compro esa parte del edge computing te compro que tiene un tiempo de inicio mucho más largo mucho más liviano porque simplemente no tenemos a javascript pues a node como tal corriendo bien, entonces precisamente y aparte de eso va a estar distribuido de la mejor manera entonces vamos a ver cómo hacer eso y desplegarlo en Cloudflare así que empecemos de una vez a ver cómo sería HonoJS así que hoy vamos a explicar qué es Hono y escribir nuestra primera aplicación fíjense que es algo muy sencillo y literalmente el hola mundo son estas unidades de la aplicación que es un 2, 3, 4 líneas de código en la cual podemos hacer un hola mundo literalmente sacarlo y ya, y fíjense que aquí seguimos utilizando TypeScript sé que esto va a correr en un runtime mucho más chiquito que Node por ende es más acotado pero igual vamos a tener todo el poder allí entonces vamos a literalmente iniciar entonces si voy aquí a la documentación voy a escoger aquí Cloudflare Workers fíjense acá muchas maneras en las que yo puedo iniciar una aplicación en Hono acá me dicen que puedo hacerla con Gino con Boon Berser, si lo quiero de esa manera Netlify precisamente este servicio de Lambda Edge que es el servicio de Amazon para correr este tipo de funciones en el Edge Computing de nuevo, Edge Computing es algo muy interesante les recomiendo ver ese video en mi canal acerca del tema pero en fin, entonces tenemos y es más, algo muy interesante es que igual lo podríamos hacer con Node es decir, si en algún momento escribes una aplicación en Hono y al final te va a llegar un código de Hono y al final de pronto no te convenció correrlo en este tipo de ambientes de Runtimes como Boon con Deno podrías volver a Node.js y correrlo en un servidor de Node normal, entonces no pierdes eso literalmente creo que eso es lo bueno de este tipo de framework como Hono.js como que escribes una vez tu aplicación y lo puedes distribuir en varios Runtimes que no solo sea Node, ¿bien? en cambio con Nes, con Express literalmente no tienes muchas opciones que no sea correrlo en un servidor que soporte Node.js como tal, ¿bien? entonces vamos a iniciar con este que es Cloud for Workers y pues vamos a, acá nos dan como un setup de la aplicación inicial así que literalmente vamos a correrlo entonces vamos a ir a la terminal estando aquí en la terminal, entonces vamos a ejecutar esa aplicación, aquí voy a llamarlo MyAPI y él va a crear como un boilerplate de nuestra aplicación, le digo que sí, que quiero iniciar como con este setup me dice que en donde quiero distribuir la aplicación, entonces acá yo le voy a decir que voy a escoger Cloud for Workers que es este Runtime de JS que tiene Cloud for, que me parece bastante interesante, de por sí mi opción para escoger Cloud for es que ellos tienen inferencia de modelos de inteligencia artificial entonces en algún punto también quiero hacer algunos laboratorios y mostrarles cómo podemos, por ejemplo gracias a Cloud for, consumir modelos como Open Source o la Language Model Open Source como LAMA3, que son igual de potentes a un GPT-3 o ese tipo, bien entonces por eso me interesa mucho la red de Cloud for y sé que para desplegar allí tengo Home.js para escribir ese tipo de aplicaciones entonces escojo allí, le digo que quiero instalar mis dependencias que qué manejador o package voy a utilizar, npm, voy a utilizarlo y esperemos que clone, acá ya creo el proyecto, así que simplemente entonces voy a entrar a la carpeta él me ha creado una carpeta, entonces voy a llamarlo MyAPI y acá está el código, literalmente es un código, vemos que hay un NodeModules, prior line y igual estamos utilizando NPM para la gestión de dependencias, pero realmente Home.js no tiene muchas dependencias per se porque no utiliza mucho el codigo de Node.js pero vamos a verlo voy a abrir Cringor y abrir드릴게요 cada vez que abramos nuestra aplicación vamos a encontrar cosas como bastante interesantes y sencillas por ejemplo tenemos como por defecto al creador dejó no no le gusta el punto y coma entonces vemos que no tenemos un punto y coma por acá pero si ustedes les gusta poner el punto y coma me gusta no sé por qué pero me causa cierto tipo de el punto y como al final no es que no me guste python me encanta python pero en javascript ya estoy un poquito acostumbrado a eso y si ponen cualquier linter se los van a poner por defecto así que no está pero bueno acá tenemos esta aplicación bien y está súper chiquita que qué dependencias tiene esto nos creó unas dependencias acá tenemos grande que es básicamente una forma de correr ese runtime de y es porque al final si no corren no guíes entonces en que corren pues literalmente está corriendo en el runtime de javascript que ofrece clover bien si corriéramos continuo pues tendríamos algo como dino o boom en fin nos toca decirle en qué runtime normalmente como nosotros corremos no de nuestras computadoras pues aquí se instala esta dependencia extra que es una dependencia de cásper para correr el runtime de cláusula y ver pues que todo ande bien bien acá fíjense que sólo tenemos uno y es tenemos estos tie pins para el para clóver porque lo vamos a desplegar en su red y ya eso es básicamente lo que tenemos un test de config este archivo de configuración es bastante importante sin embargo ya nuestro configuró entonces acá tenemos un nombre de mi piel el desde dónde y una fecha aquí de por sí nosotros podríamos si realmente necesitamos algo de no guíes como buffer por ejemplo estas estas de estas primitivas de no guías que necesitamos de pronto para leer archivos que no vienen en este runtime chiquito y liviano de clover workers pues ellos sí pueden agregar una compatibilidad lo único malo es que entonces no aprovechas todo el edge de ese runtime de clóver sin que corren algunos puntos y luego no se va a poder hacer nada más que hacer un punto en donde si tienen out pero la gracia es pues correrlo como en toda la red no sólo en los puntos donde tienen out pero en fin igual también se podría decir oye yo sí quiero compatibilidad con la otra así que activo esta banderita bien entonces cómo se corre esto bueno aquí de por si ya nos dejaron unos como unos indicadores como en el primer run death y podríamos ya correrlo entonces veamos eso veamos ya vamos aquí a la terminal hagamos una primer de un death y veamos cómo corre acá me dice que está corriendo en el local host 87 87 y acá nos dice un hello al final si lo vemos no no es tan complicado fíjense que yo declaro una aplicación y esa aplicación le pongo un get y simplemente le puse un el award o sea es muy parecido y literalmente tiene muchas parecidas coincidencias con exprés no que expresan en funciona de esta manera tenemos middle world yo puedo empezar a hacer routing y luego de ahí vamos a hacer el run death y ahora vamos a hacer el run death puedo empezar a hacer servicios si se lo quieren asimilar algo sería muy similar a un express o un flags en python o fase y pie en pautón es como muy declarativo de esa manera pero entonces vamos a desplegar esta aplicación vamos a literalmente vamos a iniciar desplegando esta aplicación y acá tenemos este que se llama este otro comando que se llama grande de play en donde lo vamos a desplegar pues lo vamos a desplegar en cloud ford para ahí ustedes tienen que ya tener una cuenta en el하다 un o en este caso vamos a desplegar el o en este al ap summation para el abordaje que va a connect con chat donde vamos a actuales y conferencia o en si zodiac vamos a test theelost al 있죠 48 lo que g 뭘 para el oink sorb Occ con base en este sec campscares que la verde acción está handle con X vamos a viajar por ahí vamos a encontrar un autor jegs económico que un Google Cloud, etc. Entonces voy a desplegar esto. Entonces lo que normalmente te pide es unir tu cuenta y esto te lo va a poder ir aquí con el Grandler. Cuando ya corra el deploy, él te va a decir ok, pero dime cuál es tu cuenta. Me va a permitir hacer como un match con mi cuenta y por ende lo va a desplegar. Obviamente esto también se podría hacer en integración continua. Tocaría ya configurar unos tokens para que en un servidor de integración continua con Jethal Actions o con cualquier otra forma que utilices para tu integración. Pues simplemente cada vez que haya un, no sé, un comida main se conecte a el proveedor de Cloudflare y haga el deploy. Ahorita lo voy a hacer como manual desde mi terminal, pero obviamente se puede integrar a una red si quieren. Luego lo podemos también hacer. Entonces voy a correr. Voy a salirme de acá. Y voy a correr deploy a ver qué pasa. Entonces aquí, como venía diciendo, me está permitiendo como el ancho. Le digo que sí, que voy a permitir esa conexión entre Cloudflare. Y aquí ya dice login. Dice que está subiendo my API y aquí ya me dio una URL y acá tenemos ya una URL en vivo de la aplicación. My API. Bueno, me pone como un hash ahí. B2B me pone workers.dev. Por ejemplo, yo puedo hacer algo como lo siguiente, como tengo aquí ya Cloudflare de por si aquí debería estar ese. Ahí está, my API. Ahí está. Tiene logs de métricas para empezar a ver qué peticiones llegan acá. De por si acá yo puedo habilitar esos logs. Y automáticamente ver eso. Creo que por si hay un comando para habilitar logs porque tienen una nueva fórmula. Y es una forma de hacer el log que llega a este sistema. Y esas variables normalmente se configuran como servicio aquí en el rounder.tomp. Y de por si, no sé si está por acá. Debería estar por acá. Déjenme ver. Lo buscamos rápidamente. Este es el nuevo sistema de logs. Acá nos dicen exacto. Nos dicen observability y le decimos que true. Y por acá nos dice opcional default 1. Vamos a colocarlo. Por acá. Y entonces cuando yo haga un nuevo deploy, pues habilite esto. Todavía no lo voy a hacer deploy porque probablemente también quiero habilitar este de AI. De por si lo voy a habilitar de una vez. Para que vean cómo yo puedo conectarme ya a un sistema, a la red también de cómputo de modelos que tiene Cloudflare. Y que ya utilizando esos servicios y ya teniendo ahí Cloudflare, no sólo utilizo la red de Edge Computing. Sino sus modelos que también son inferidos en esa misma red. Y bueno, y acá literalmente es muy similar. A Amazon de alguna manera. Yo tengo cosas como un R2 que sería como el S3 de Amazon. O sea, para generar archivos. Una base de datos todavía experimental. Bueno, no está experimental. Realmente ya la sacaron de forma general. Es un D1 que es una base de datos que también se comporta en el Edge. Es altamente distribuida. De por si Amazon hace poco lanzó también una base de datos que es altamente distribuida y serverless. Pues Cloudflare tenía una que se llama D1. Ah mira, que si estaba el Observability por acá. Y tiene una base de datos clave valor. Un KeyStore que también funciona bastante bien. En fin, uno como que va habilitando sus servicios y su aplicación entonces puede conectarse. Base de datos, subir archivos, inferencia de inteligencia artificial, etcétera. Fíjense que acá entonces ya lo debería tener. Acá está. Pues ahorita que haga deployment habilitó eso. Tengo aquí como el log de los deployments, pero quisiera ver si aquí puedo hacer una integración. Y domiños, dominios y rutas. Custom Domain. Aquí yo tengo varios dominios aquí, porque Cloudflare también deja un del dominio. Entonces, por ejemplo, que yo le diga jona.js. Jona.nicobytes. Porque acá tengo mi dominio.com. Entonces ahí déjenme que creo que no ven esta parte. Acá. Eso. Entonces. Entonces acá me dice que yo lo quiero explicar a que actualiza tu Rounder para que esté sincronizado. Esto me causa interés. No sé si yo tengo que habilitarlo en el Rounder también, pero a ver, agregámoslo igual. A ver qué pasa. Entonces aquí me dice que ya tengo un custom domain. Y obviamente esto podría demorarse porque pues replicación de DNS y eso. Pero generalmente es muy rápido. Déjame ver. Nicobytes.jona.jona. . Listo. Y ya tengo literalmente mi aplicación allí de por si yo tengo una que se llama api.nicobytes. . En donde empecé a experimentar jona, en donde tengo la API, una fake API, pero toda hecha en jona. Yo había hecho una primera versión de por si hice la versión de Platzi, que es muy buena. PlatziStoreFakeAPI. Esta, esta está hecha en .NES.js. en un servidor de Heroku. Bien, entonces aquí básicamente es como una fake API de productos, entonces uno jala productos y sirve mucho para practicar hacer CRUDs y todo ese tipo de cosas. Pues esa misma API la estoy pasando, pero utilizando HONO, HONO.js para utilizar la red de computador de Xcomputing por ende las respuestas serían más rápidas porque una de las cosas que tiene Xcomputing es que la latencia es mucho menor porque pues está lo más cerca al usuario entonces en vez de ir, no sé, a Estados Unidos a hacer el request, va y lo hace, no sé en tu locación más cercana que sería, no sé si estoy en Latinoamérica, por ejemplo si estoy aquí en La Paz, digo si estoy aquí en Bolivia, que estoy en Cochabamba por ejemplo lo haría en La Paz y realmente la red de computador de Cloudflare en Xcomputing es mucho más grande que cualquier otra de nuevo no es porque vean el video pero si quieren entender mucho de esta profundidad véanse el video de Xcomputing y ahí van a entender realmente mucho más por qué. Listo este, por si este proyecto es open source si quieren ir a verlo checarlo un poquito más van a ir a eCommerce Full Stack y en Apps en la API literalmente esto es un poquito con más cosas con ya una base de datos para manejar las migraciones y ya tiene una estructura, como rutas servicios, entonces acá tengo un servicio como para tokens, por ejemplo acá locations ya literalmente es una API como tal funcional, pero de hecho en Hono si quieren ver algo ya un poquito más avanzado o no solo un Hello World pero por ahora vamos bien por ahora tenemos un Hono HonoNikowitz.com que lo acabamos de hacer en unos minutos, acabamos de explicar una aplicación normalmente esta aplicación es para servir un servicio tipo API tipo REST API, tipo GraphQL aunque Hono es utilizado también para hacer rendering literalmente hay unas algunas si nosotros miramos acá la documentación de Hono vemos que hay cosas interesantes donde uno puede habilitar renderizado de RxJS, es decir yo podría renderizar una aplicación de Next, de React una aplicación de View una aplicación de Angular directamente utilizando el Edge Computing, pero va, aquí literalmente ya tenemos nuestro Hello World ok y ya con esto tienes tu Hello World en HonoJS, pero al final ¿cuál es la ventaja? ¿cuál es la ventaja al final de utilizar Hono en vez de por ejemplo Express o algo con mejor arquitectura como NextJS? recuerda que al final Hono lo que te da es poder desarrollar tu aplicación que puede correr en múltiples Runtimes de Javascript, sea NodeJS per se o también sea BUN, Dino o los Cluster Workers que son un Runtime de Javascript mucho más liviano, por ende no tienen como este tiempo de inicio en las Serverless Functions que se demoran un poquito en la primera función porque como que tienen que alistar el ambiente, pues esto no pasa con los CloudFood Workers o con cualquier cosa mucho más liviana como BUN o como Dino, porque pues NodeJS es un poquito pesado y estos son mucho más ligeros, son Runtimes mucho más ligeros, además que aprovechando el Edge Computing, pues corren mucho más cerca al usuario porque tienen una mejor distribución, te voy a dejar un video aquí acerca del Edge Computing y para que realmente no solo sea probar HONO y decir, ah que cool es esta tecnología sino aprovechar el poder de cómputo que sería utilizar el Edge y además de eso para no quedarnos en el típico Hello World, he subido un video en donde directamente ya con este Hello World utilizamos los modelos de Inteligencia Artificial que tiene CloudFord en su nube, así que no siendo más me despido pero por aquí ya debe aparecer disponible este video para que literalmente saltes de este Hello World a literalmente probar la red de cómputo de IA y por acá también te voy a dejar el video de Edge Computing si quieres profundizar en esta técnica y porque precisamente HONO-GE sería una gran ventaja, así que suscríbete y nos vemos en el siguiente video