¿Te imaginas poder ejecutar modelos de lenguaje avanzados sin necesidad de conexión a la nube? Hoy quiero compartir con ustedes una experiencia increíble que tuve al trabajar con Gema, un modelo de lenguaje grande Open Source de Google. Lo más fascinante es que Gema es accesible y puede funcionar offline, lo cual es ideal en situaciones donde la conexión a internet es limitada o la privacidad es una preocupación.

Decidí poner a prueba las capacidades de Gema integrándolo en una aplicación de chat con Ionic y Angular, y compilándola para Android. Utilicé la tecnología MediaPipe de Google para ejecutar modelos de IA directamente en dispositivos, reduciendo significativamente la latencia. Aunque el modelo Gema 1 tiene ciertas limitaciones, fue emocionante ver cómo interactuaba y respondía a preguntas desde mi dispositivo Android.

Durante este proyecto, aprendí la importancia de manejar archivos grandes adecuadamente para no sobrecargar la aplicación. También exploré el uso de WebGPU para correr modelos de IA, lo cual fue todo un desafío. Esta experiencia abre la puerta a muchas aplicaciones futuras en privacidad y accesibilidad offline. ¡Espero que mi proyecto inspire a otros desarrolladores a explorar el mundo de los modelos de lenguaje Open Source! Descubre más en este video: [https://youtu.be/XTvV3m1ncPQ](https://youtu.be/XTvV3m1ncPQ)