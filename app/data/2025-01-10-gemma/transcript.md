 El tema es el modelo open source de Google, un large language model que funciona bastante bien y es open source, de por sí es una de esas novedades o de esas cosas interesantes que tiene Google de que lanza un modelo open source, normalmente estos modelos son muy cerrados, por ejemplo de OpenAI no hemos visto mucho del open source, de por sí solo liberaron Whisper como open source y lo podemos utilizar, lo podemos desplegar en nuestros propios servidores, etc. Realmente el que ha tomado una gran liderazgo en liberar modelos es a sorpresa de todos Meta, Facebook, en donde ha liberado los modelos o la familia de modelos de Lama, de por sí estos modelos de Lama tienen un muy buen rendimiento, muy casi similar a llegarle a un nivel a un GPT-4, un GPT-3.5, depende del modelo que uno escoja, de por sí hace muy poco lanzaron Lama 3.3 que tiene más novedades, entonces, eh, Facebook lanza estos modelos open source y Google pues tiene Gemini, ¿no? Gemini como su modelo o su large language model que está en la nube, que está a través de sus servicios, pero lanza una familia de modelos ligeros, pequeños, eh, open source, ¿bien? Esas son la familia de modelos de Gema. Gema, eh, es un poquito, no es tan poderoso realmente, pero sí es un large language model que podemos correr de forma, eh, offline. De por sí, Gema tiene algo muy interesante y es que lo están tratando de correr o integrar directamente, por ejemplo, a navegadores como Google Chrome, o sea, como que tu Google Chrome ya viene integrado con inteligencia artificial, también en los dispositivos como Samsung, como el Pixel, ya viene integrado como un Gema, entonces, como que uno puede acceder a él y este modelo es open source, entonces, uno lo puede descargar, de por sí hay varios, eh, servidores, por ejemplo, los servidores de Cloudflare ofrecen el modelo de Gema para que uno lo pueda utilizar, eh, no lo pueda utilizar y lo, lo más interesante es lo que se conoce como el Edge, el AI Edge, que no es Edge Computing, sino el correr AI en el Edge, que es como lo más cerca al usuario y vamos a ver de qué trata esto, Google AI Edge, ¿a qué se refiere esto? ¿a qué se refiere el Edge en los términos de inteligencia artificial? Aunque si yo quisiera resumir el Edge como en un resumen general, es como correrlo más cerca al usuario, ¿no? Como que hacer la ejecución de algo, ¿no? Lo más cercano al usuario, normalmente nosotros tenemos un servidor en la nube, eh, y pues va, no sé, a un servidor en Estados Unidos y hace el cálculo y no lo devuelve, el Edge Computing, por ejemplo, es una forma de hacer ese cómputo, pero más cerca, de pronto no ir hasta Estados Unidos, sino a lo, lo más cercano que esté, que estemos a un punto de, de conexión, por ejemplo, si yo me estoy conectando aquí desde Cochabamba, hay un Data Centers, en el caso de Cloudflare, en La Paz, y ahí sería el punto más cercano, ¿no? Pero si hablamos del Edge en términos de inteligencia artificial, o al menos a los que pone Google, es literalmente correr esa inferencia, ni siquiera en la nube, sino directamente en el hardware, o lo que ellos llaman como On-Device Machine Learning, es decir, literalmente yo compilo o como que traigo ese modelo directamente como parte de mi aplicación, y entonces puedo ejecutar esos modelos como parte de la aplicación. De pronto eso va a cambiar en el futuro, de nuevo, Android. Android está como cambiando estas reglas y está viendo que ya estas APIs, o tengamos un modelo, un Language Model, que no necesitemos como compilarlo como parte de la aplicación, sino que ya sea parte del sistema operativo como Android, así como cuando uno accede a la serie de leómetro, a la geolocalización, ¿no? Esas son cosas que no nos toca como descargar, literalmente, son simplemente cosas que ya accedemos como parte del hardware de nuestro dispositivo. Entonces, GEMA también va a estar, o un Language Model también va a estar ahí en el dispositivo. Sin embargo, GEMA al ser open source, igual lo podemos como tratar de correr en servidores de nuestra nube, en Cloud, o literalmente compilarlos como parte de la aplicación, y es lo que vamos a hacer hoy. Hoy voy literalmente a hacer un demo en donde vamos a usar Ionic con Angular. Esto lo vamos a compilar a una aplicación en Android y vamos a descargar el modelo de GEMA. Y vamos a crear un chat que en teoría, una de las ventajas es la parte de offline. De por si aquí nos dicen, mira, aquí nos dice Google AI, ¿no? Entonces, lo primero que nos dice es en dispositivo, es decir, reduce latencia, literalmente ni siquiera habría latencia porque no se conecta a un servidor. Literalmente se está conectando, la inferencia ocurre en el dispositivo. Y como ocurre en el dispositivo y no en un servidor, en teoría tendríamos... Un modelo, un large language model como parte de la aplicación. Y eso quiere decir que correría de forma offline, no necesita una conexión a internet para ejecutarse. Eso para ciertos casos de IoT, de lugar de por si en donde hay poca conexión, donde nuestra aplicación de pronto necesita del offline, pero aún así necesitamos brindar herramientas de AI, es donde tendríamos una gran opción. Porque entonces podríamos correr este tipo de lenguajes, digo, este tipo de modelos directamente, como parte de nuestra aplicación. Y lo otro es esto, como al final no estamos enviando conexiones a una cloud, literalmente si de pronto la privacidad es una de tus preocupaciones, pues literalmente aquí toda tu... la data que le estás enviando al modelo nunca va a la nube porque todo ocurre en un device. Entonces mantiene tus datos locales y privados, ¿no? Entonces aquí ya hay unas características, multiplataforma, de por si... Ionic al final... Que es lo que... la tecnología de Ionic que nos permite compilar hacia Android, al final es un webview. Entonces realmente lo que vamos a hacer es utilizar la parte web que nos deja correr el modelo en la web, solo que tiene más sentido pues correr una aplicación que luego nos deje hacer el offline. Pero en teoría también lo podríamos correr una aplicación web y literalmente que el modelo sea parte de nuestros assets. Solo que creo que ahí no le halla tanto sentido porque simplemente si ya estoy en la web, pues llamar a un OpenAI, a un modelo LAMA 3.3 con la red de Cloudflare creo que está bien y ya. O literalmente probar que Google Chrome ya tiene un GEMA integrado, solo que todavía está en desarrollo, todavía no está... no es parte de las APIs del navegador, pero muy... como muy pronto vamos a tener ya un, no sé, Navigator.geolocalizations, sino Navigator.ai y ahí hay un GEMA que podemos interactuar con él. Entonces me hace más sentido que lo compilemos en una aplicación de Android y pues lo probemos de esta forma, de esta manera. Bien, y bueno, hay otras características, multi-framework, etc. Entonces vamos a ir viendo. Ahora, esto lo vamos a hacer gracias a una tecnología que tiene Google, que es MediaPipe, que es el que permite como hacer correr este motor de inferencia. Entonces vamos a empezar con esta guía. Déjame ver esto, yo creo que lo puedo ocultar. Eso. Entonces básicamente voy a utilizar esta guía. Para hacerlo, pero primero necesitamos nuestra aplicación básica en Ionic, como un Hello World rápido en Ionic, para que luego simplemente empecemos a utilizar toda esta... acá está literalmente la guía, para poder hacer toda la... descargar el modelo, compilarlo, etc. Entonces acá nos dice cómo hacerlo, de por sí por acá nos dice tenemos que descargar el GEMA, ahorita vamos a descargarlo, y luego empezar a ver cómo lo podemos correr. Vamos a ver, de por sí aquí debería estar la parte web, vamos a ver acá, está la guía, y acá está, de por sí creo que tiene mucho zoom, eso. Acá está el ejemplo de código, y necesitamos empezar a instalar estas dependencias, y con ello vamos a poder lograrlo. Entonces básicamente hagamos rápidamente, hagamos como un template rápido de una aplicación en Ionic. Vamos acá, vamos a ir a mi carpeta personal. Tararán. Entramos acá. Listo. Entonces vamos a un Ionic Star. Vamos a iniciar nuestro proyecto, yo le digo que no, no quiero el Creation Wizard. Le digo que en qué framework, le voy a decir Angular, el proyecto se va a llamar GEMA. Quiero una aplicación de tabs, un side menu. Qué bueno, un side menu, me gusta siempre. Me dice que si quiero utilizar ngModules o Standalone, Ionic ya soporta como la... forma de programar en Angular sin módulos, entonces le voy a decir que es un Standalone, es un proyecto que va a utilizar como las nuevas APIs de Angular. Va a ser Standalone, y listo. Y ahí automáticamente, de por sí me está como lanzando la integración con Capacitor, que es al final lo que me va a permitir compilar hacia un dispositivo en Android, ¿no? Compilar hacia Android o compilar hacia iOS. Entonces dejemos aquí que termine esa instalación. Pues aquí ya se creó nuestro proyecto base. Entonces en teoría creo que con el proyecto de GEMA, ahí está. Y pues abrámoslo, yo normalmente utilizo Cursor. Entonces abramos el proyecto. Entonces yo abro aquí mi proyecto, y pues al final es un proyecto normal de pues una aplicación en Ionic. Con sus... con el routing. Acá tenemos como iniciamos con un side menu. Pues tenemos una aplicación sencilla, vamos a ver si utiliza Standalone. Al parecer utiliza Standalone, y vamos a ver qué versión me trajo. Por defecto. Vamos a ver acá, debe estar en el package. Me trajo la versión 19, y eso es interesante porque en la versión 19 de Angular ya no hace falta el flag de Standalone true. Eso ya no hace falta, porque por defecto son Standalone. Entonces fíjense que igual Ionic se mantiene muy conectado con las nuevas innovaciones de Angular, y pues está bastante bien. Vamos a correr esta aplicación. Normalmente la corremos con un Ionic SERP. Ahí va a correr en el puerto 8.0. Ahí va a ser pues el building normal de nuestra aplicación. Y pues tenemos aquí la aplicación. Ahí está corriendo. Ahí está. Déjenme hago un... Acá voy a correrla como emulando el dispositivo. Pues ahí está, ¿no? Es nuestra aplicación corriendo como con un side menu. Perfecto. Ahí es nuestro Hello World normal de Ionic. Todo bien. Voy a crear una página como desde cero que se llame chat. Y lo integro aquí al menú lateral. Y ya con eso, pues ahí es donde vamos a hacer como un chat e integrar Gema como la Language Model. Entonces aquí lo que podría hacer es quitar esto y vamos a crear una nueva página. Vamos a ver en dónde la pone. Normalmente en app, folder. Podemos decirle que esta página está en Pages. Y le voy a decir que se llame chat. Vamos a ver. Entonces genera esto. Yo por acá le digo que sí. Listo. Ahí creo. Acá una página. Bueno, creo el folder Pages. Y dentro de ese Pages creo chat. Acá está como el template normal con el header, con el toolbar de Ionic. Un CSS. Un archivo de pruebas. Y pues nuestro componente, ¿no? Acá lo dejo. Está en Alan True. En teoría este ya no lo necesitamos. No necesitamos que sea. Está en Alan True. Y acá al parecer ya le entregó la ruta. Fíjense acá. Que ya está integrado. De por si aquí un truquito chiquito. Es que nos podemos ahorrar este punto den. Si nosotros le ponemos a este export default. Creo que es. Default. Si nosotros le ponemos export default. Literalmente como es la exportación por defecto. Lo podemos dejar así y ya. Si se quieren ahorrar ese truco. Literalmente se pueden ahorrar este punto den. Y que resuelva cuál es lo que tiene que exportar. Porque normalmente. Pues queremos exportar eso. Entonces simplemente le agregas el default. Y listo. Te ahorras ese pedacito. Ahora ahí ya está. Ahí ya está la página. Y podemos por aquí por ejemplo poner. Un H1. Diciendo chat. Y. Vamos a integrarlo al menú. Normalmente por acá debería estar el menú. En nuestro app component. Y yo creería que por acá está. Ahí está como el menú que está apareciendo. Como al costado. Entonces aquí voy a crear uno nuevo. Acá literalmente le digo. Va a ser la página de chat. Va a ser la ruta. Va a ser slash chat. Que es literalmente esta nueva ruta. Y por acá creo que le va a poner. Pues un icono. No sé si este icono exista. Dentro de la iconografía de Ionic. Vamos a buscar igual. Si nosotros buscamos la iconografía de Ionic. Ionic icons. Acá está. Vamos a ver si existe ese. Porque a veces simplemente puede que. Me haya autocompletado. Pero parece que sí. Acá hay un. Acá este es. No, se llama chatbox outline. Y bueno y acá hay otro. Creo que sirvería. Acá hay varios iconos de chat. Llamamoslo chatbox. Entonces este chatbox. Es más, si no está. Si no lo encuentra. Pues ahí va a haber un error. Es más, volvámoslo a lanzar. Hagamos un Ionic surf. Lancemoslo. Otra vez va a estar. El puerto 8100. Vamos a ver. Vamos a recargar este que ya tenía abierto. Entonces por acá. Debe estar chat. Pero fíjense que el icono no sale. Porque de nuevo no está como dentro de la iconografía. Entre el paquete de iconos que tiene Ionic. Por defecto. Entonces normalmente creo que el icono es chatbox. Vamos a ver si ese sí lo toma. Vamos a ver. Y parece que tampoco. A ver, vamos a ver. A ver cuál de estos sale. A ver cuál de estos será. Creo que hay uno que es message. No, a ver. Alarma. Creo que hay que ponerle un outline o algo así. Acá solo le pusieron warning. Pero quiero ver si aquí en el momento del rendering. Le pusieron. Ah, fíjense que sí le agregan el outline. Pero ellos le agregan el outline. Y después le ponen. Le ponen para IOS un icono. Y para lo que es material design. Le ponen este icono. Este sharp. Y aún así debería creo que funcionar. Porque el chat. Que tenemos acá. Creo que está para los dos. O sea está chatbox outline. Y también está en sharp. Chatbox. Sí ahí está. A ver por qué no me está funcionando. Esta parte. Chatbox. Si lo estoy copiando bien. Chatbox. Chatbox. Vamos a ver. Lo vamos a volver a guardar. Y ver por qué no me está cargando el icono del chat. Lo voy a volver a recargar. No, algo me está pasando con ese icono del chat. Déjenme ver, inspeccionar. Chun chun chun. Acá está chatbox. Pero parece que sí, no lo está tomando. O sea ahí deja como la posición. De donde debería ir el icono. Pero no lo está reconociendo, qué raro. A ver, ponemos cualquier otra. A ver esta personita. Accessibility. Vamos a ver. Si este sí me lo toma. Y así mira si es que yo estoy teniendo aquí un problema. O definitivamente no está renderizando ese icono. O definitivamente no está renderizando ese icono. No, qué raro. Qué raro que no me esté renderizando este icono de acá. Qué raro que no me esté renderizando este icono de acá. A ver si repito este de mail. Si no, algo estoy teniendo ahí. Como con los iconos. Ah mira, aquel de mail. Sí me lo renderizó. Sí me lo renderizó. Bueno, si quieren no me voy a sentar tanto en esto. Debe ser algún error tonto que estoy cometiendo. Pero pues la vuelta de hoy no es ver cómo funciona tanto Yannick y los iconos. Sino ver cómo integramos Gema a una aplicación compilada en Android. Entonces voy a dejarlo así. Chat. Y luego vemos qué onda con el icono. Pero listo. Entonces vamos a ver. Algo que vemos es que si yo entro aquí como que como que me deja el header y eso como mal. Y no puedo como acceder al menú. Fíjense que acá me salió un menú para pues un... esto es menú hamburguesa. En donde puedo volver como acá. Eso normalmente es sencillo de poner. Simplemente lo que podríamos hacer es aquí simplemente necesitamos el IonBurns. Y luego necesitamos el IonMenuBurns. Entonces simplemente lo ponemos como parte del toolbar. Aquí no está. Entonces por eso no aparece. Y de por si aquí esto lo tengo que borrar. IonBurns. Ahí está. Y creo que ahora lo que me dice es que no encuentra IonBurns. Porque normalmente pues tenemos que importarlo como parte de los módulos. Entonces aquí le voy a poner que voy a importar IonBurns. Acá está. IonBurns. Y el IonMenuBurns. Y se los implemento como parte de sus imports. Y ahí ya debería funcionar. Vamos a ver. Ahí está. IonContent. Déjenme ver hasta ahí. Creo que ahí ya está. Entonces el chat ya tiene acá. Fíjense que por ejemplo acá tengo la emulación de un iPhone. Entonces como que me muestra la interfaz de un iPhone. Pero si yo corro un Galaxy por ejemplo. Y lo vuelvo a recargar. Ya el menú cambia un poquitito. Porque es ya el estilo de Material Design. Y eso es un poco lo que tiene Ion. IonMenuBurns. Y ahora me deja pues literalmente con una sola base de código. Pues si tener o respetar los estilos para cada una de las plataformas. Entonces de nuevo aquí ya me aparece como más el estilo de un tipo de Material. Listo. Entonces aquí es donde vamos a implementar el chat. Literalmente. Entonces ya voy a cerrar acá. Y vamos a por ahora tener una caja de texto. Bien. Una caja de texto. Y de pronto pues un array de mensajes. Entonces voy a tener acá messages. Y que tiene messages. Por acá me dejan un prototipo interesante. Me dejan un Timestamp. Un sender de quien lo envió. Y un Tempestamp. Yo creo que me quedo con ese. Me gustó la sugerencia. Entonces voy a crear una interfaz para eso. Ahí está la interfaz message. Entonces lo que podría decir es que. Y voy a utilizar Signals. Entonces lo que voy a utilizar es que esto va a ser un Signals de un array de mensajes. Y listo. Entonces estos son los mensajes que va a tener esta estructura. También deberíamos tener un ID normalmente. Entonces tenemos ID, texto, quien lo envía y un Timestamp. Perfecto. Listo. Eso es para construir como nuestro historial. Luego pues vamos a construir rápidamente un... pues como una caja de texto. En donde podamos escribir. De nuevo, no me voy a de pronto fijar tanto en la UI. Simplemente quiero que podamos correr Gemma. Entonces aquí voy a ver si hay un componente para un Tesaria. Hay un Tesaria. Al final este de acá me puede servir. Ahí está. Ahí está como varias formas de que puede funcionar un Tesaria. Para poder escribir como este. Staked. Creo que me gusta. Entonces me voy a robar este. Que tiene el Staked Label. Entonces creo que este me va a servir. Creo que este tal cual. Entonces me lo copio y me va a traer un Tesaria. Ahora Tesaria no existe. Tengo que importarlo. Tengo que seguir haciendo como mis importaciones. Entonces voy y tengo el Tesaria. Ahí hay un Tesaria. Lo importo. Y ya debería pues no tener ningún problema. Ahí está. Entonces vamos a ver si está dentro de nuestra aplicación. Ahí está. Ahí tenemos ya como una forma de escribir como... pues un mensaje. ¿Cómo lo vamos a unir? Pues yo necesito como chatear con Gema. Voy a tener como un chat sencillo con Gema. Entonces lo que voy a hacer es pues de pronto un método que diga SendMessage. Bien. Acá fíjense que estoy creando. Acá algo interesante es que me dijo que utilizar esta librería. Pero pues obviamente esta librería no la tengo para generar un ID. Pero voy a generar el ID con un con el Date. Y ya. Ahora acá es el texto. ¿Cómo voy a obtener el texto? Bueno pues aquí lo que podría hacer es algo sencillo sin módulos ni nada. O sea sin un formulario reactivo ni nada. Voy a crearle un Message Input a esto. Y voy a organizar esto de esta manera para que lo veamos como organizado. Y acá fíjense que había un ngModel pero realmente lo que voy a hacer es que cuando yo le dé Enter pues manda el mensaje. Entonces voy a hacerle un... no me acuerdo cuál es el... Vamos a ver si acá dentro de los eventos del textarea. Acá hay unos eventos. Hay un chain, hay un focus, hay un input. Creo que podría funcionar el Keyboard. O sea como presionar el... Como un Enter. Eso aquí Enter. Y eso manda el mensaje. Y pues aquí lo que podría hacer es Message.Input.Value que sería el valor. De ese Message Input. Ahora aquí hay algo. Ah pues claro. El SendMessage no me recibe pues el texto. Entonces le voy a hacer que el texto es un String. Que ahí lo recibe. Y lo asignamos. Y listo. Entonces ahora tengo un problema con el InputValue. Me dice que posiblemente eso sea nulo onDefine. Podría utilizar un NullageCollection y de pronto pues si no existe enviar un String en vacío. Pero luego podríamos realmente mostrar una validación y decir como hay realmente escribo un mensaje etc. Aquí le voy a decir escribe tu mensaje. Type your message. Y listo. Y no va a tener un botón de enviar sino el botón de Enter es el que va a hacer la labor de envío. Entonces acá se construye el mensaje y lo que podría hacer es algo como lo que me sugiere acá. Hacer un Set. Realmente podría hacer un Update. Y como Update me devuelve el estado anterior pues simplemente lo tengo que pushar. Exacto. Esto queda más bonito. Entonces literalmente los mensajes anteriores con el nuevo mensaje que está construido de esta manera. Listo. Ahora necesito simplemente un IonList podría hacer. Y con el IonItem lo itero y imprimo el mensaje. Sin embargo pues este componente IonList no lo tengo. Entonces voy a volverlo a importar. Entonces acá necesito un IonList y un IonItem. Listo. Y esto lo voy a organizar también como para abajo para tenerlo bien. Ah y el IonLabel también lo necesito. El IonLabel también lo voy a necesitar. Aunque no sé si un IonLabel de esto debería ser si lo imprimo debería ser un párrafo porque es texto. No, no. No un IonLabel. Listo. Entonces ahí está el texto. Esta es la sintaxis antigua de Angular. Entonces vamos a utilizar la sintaxis nueva. Hacemos un for y listo. Entonces tenemos ya eso. Y de pronto podríamos utilizar el IonLabel otra vez, pero sólo para imprimir el sender, como quién envió el mensaje y luego el texto. Vamos a ver si este prototipo rápido y sencillo nos sirve. Entonces digo hola enter y ahí está. User hola. Aunque está raro. El mensaje, el mensaje, el mensaje, el mensaje. Sí, acá está el mensaje. No me gusta mucho que esté como de un lado a otro. Creo que le voy a quitar el label. Y a ver cómo se lo sale con el texto. Si no podría imprimir un array de texto y ya. Ahí está. Sí, ahí está. Ahí está un poco cómo funciona. Acá es que le doy enter. De pronto deberíamos limpiar obviamente nuestro textarea cada vez que se envía un mensaje. Sólo porque es buena práctica. Pero como al final no tengo el control, creo que ahora sí voy a crear un ngModel. Y ya. Sí, vamos a crear un ngModel. NewMessage. Entonces con eso lo manejamos mejor. NewMessage. Entonces tararán. Dice que IonLabel ya no lo estamos utilizando, por eso me sale el error. Pero aquí vamos a tener NewMessage y esto también lo vamos a crear pero como un model. Que es un string, lo importamos. Esto también es un signall. Y lo ponemos ahí. NewMessage. Todo bien. Listo. Ahí está. Entonces lo que podemos hacer es que esto ya no recibe el texto. Por ende esto ya no va. Y pues como ya se conecta, pues básicamente lo que podríamos hacer es un text con el estado del mensaje. Listo. Ahí está. Y una vez que se envíe, literalmente le hago un set en vacío y ya debería limpiarme. Entonces vamos a ver si funciona. Hola. Ahí está. Se limpia. Y creo mi hola. Luego hago otro enter y ahí va. Listo. Ya tenemos un chat sencillo. Algo que no es del otro mundo. Simplemente utilicé los componentes de Ionic y pues programación reactiva utilizando signalls con Angular. Ahora lo interesante va a ser es integrar Gema. La forma en la que vamos a implementar Gema de forma offline en una aplicación que va a estar compilada para Android pero al final utilizamos Ionic y Capacitor para hacer esa compilación. Pues lo que vamos a utilizar es una de las librerías interesantes que tiene Google, que es esta que está por acá. En la cual nosotros vamos a poder literalmente ejecutar no solo Gema, sino varios modelos open source como los de Microsoft, los de Apple, los de Falcon. Que pues también como son modelos que corren open source que están ahí, también los podemos correr con una librería llamada MediaPipe de Google. MediaPipe no solo sirve para correr este tipo de modelos, este tipo de LLM, también se pueden correr otro tipo de modelos como reconocimiento de imágenes, patrones, bueno, Google MediaPipe es una librería muy interesante de inteligencia artificial. Pueden checar un video de mi canal en el cual literalmente solo hablo de Google MediaPipe como en general y todas las cosas que ofrece, pero hoy me voy a centrar en utilizar esa librería pero para correr un LLM en un modelo open source. Listo, entonces acá nos dice un poco qué es lo que tenemos que hacer, entonces lo que vamos a hacer es instalar nuestra librería, en este caso es MediaPipe y nos descargamos esta que es para tareas que son de AI generativa. Entonces vamos a instalar esta librería, es lo primerito que vamos a hacer. Aquí voy a abrir como un proceso aquí al lado y vamos a limpiar. Listo, y vamos a instalar. Voy a hacer un poquito más de zoom. Ahí estamos bien. Ahí entonces simplemente instalamos MediaPipe que es el que nos va a permitir hacer esta gestión. Luego, pues básicamente acá nos dice, mira pues una forma de utilizar también MediaPipe es desde el CDN pero pues para eso mejor lo instalamos pues directamente y ya. Luego nos dice, oye pues ahora tienes que escoger un modelo, ¿no? ¿Qué modelo quieres correr? Acá está el de Gema 2, Gema 1, estos que son los de Microsoft, el de Falcon, etc. Yo probé el de Gema 2 y no está funcionando bien. No está funcionando bien. Yo por ahí hablé con, pues dentro de alguno de estos canales de Google y están arreglando ese tipo de issue, pero vamos a hacer el ejemplo hoy con Gema 1 porque Gema 2 no está funcionando bien para hacer la inferencia pues con la API de MediaPipe, sobre todo en la web. No estoy muy seguro si directamente para Android ya tengan eso solucionado o para iOS, para el SDK de iOS, pero al menos para JavaScript no me estaba funcionando Gema 2. Si ustedes lo prueban y ya les funciona Gema 2, déjenlo en los comentarios por favor. Pero por ahora vamos a correr Gema 1. ¿Listo? ¿Cómo lo corren? ¿Cómo descargan estos modelos? Normalmente Google tiene una como un partnership con Kaggle, que es donde normalmente encontremos los modelos open source, donde podemos descargarlos. Entonces por acá tenemos la descarga, acá tenemos la licencia y por acá básicamente nos dicen que como lo queremos instalar, entonces aquí literalmente como que ya me dejó seleccionado tenemos que escoger como, que modelo vamos a correr, como lo vamos a correr, etc. Si yo me voy aquí como a la guía básicamente aquí nos dicen cual modelo deberíamos descargar Gema, Gema 1 con estos parámetros GPU INT4, bien, entonces este es el que vamos a descargar, que es este literalmente este segundo link, ¿listo? Entonces de nuevo van a Kaggle y descargan ese modelo open source normalmente tienen que registrarse en Kaggle para descargar el modelo ¿Bien? O creo que no, creo que ya quitaron esa restricción al parecer y lo podemos descargar. Aquí fíjense que tenemos como una librería en Python como para descargar el modelo también se puede descargar con el CLI, Kaggle tiene un CLI, entonces uno como que le dice que lo descarga pero al final también se puede descargar como un, pues como un zip básicamente. El lío es que normalmente estos modelos pues, pues al final es un LLM, son pesados si bien Gema es un LLM liviano para correr de forma offline, para correr en dispositivos móviles no deja de ser pesado estos LLM pesan bastante entonces aquí básicamente estamos descargando Gema en esa versión, en lo que descarga pues vamos a ir siguiendo como con la guía y haciendo la implementación bien, acá por ejemplo nos dicen mira algo importante es que yo luego que lo descargue y esto es muy importante, una vez yo descargue el modelo acá por ejemplo lo que me sugieren es que yo lo ingrese o lo meta como parte de los assets del proyecto y está bien, o sea literalmente en Ionic y en cualquier aplicación web tenemos una carpeta de assets entonces normalmente por ejemplo acá tengo los assets, entonces por si yo ya descargue el modelo, acá está models y yo creo una carpetica llamada models, pero si se fijan ese archivo está ignorado, entonces si nosotros vamos al Jikignore por acá yo ignoré esa carpeta, crc slash assets slash models, ¿por qué se ignora? porque esto pesa muchísimo y si ustedes mandan esto a su repo, pues se tiran su repo literalmente, porque es un archivo muy pesado y GitHub les va a decir, oiga esto no es para almacenar archivos grandes o sea no es para almacenar videos, etc, es para código, entonces se les explota su Jithub, ¿vale? entonces ignórenlo, por favor ignórenlo entonces eso es súper importante si no también les empieza a decir que utilice la versión de Jithub para archivos grandes que Jithub tiene como una versión para gestionar archivos muy pesados, pero esto como complique, no es el workflow normal que tienen con Jithub, entonces normalmente se ignora, ¿bien? ignoren esa carpeta en donde tengan ese modelo porque si no, les queda bastante pesado, sin embargo eso también tiene otras complicaciones, y es que como es un archivo pesado, normalmente cuando creas o compilas aplicaciones entonces, sobre todo para Android y IOS y este tipo de cosas la aplicación tiene un peso, normalmente debería ser liviana, pero ahora si tú metes tu modelo dentro de los assets de la aplicación, puede que no esté en el repo de Jithub, pero cuando lo compilas, pues para una aplicación en Android, pues ahí si lo queremos incluir, ¿no? porque al final necesitamos que corra el modelo de forma offline entonces lo vamos a meter en la parte de la compilación para Android ahí toca ser bastante delicados ¿por qué hay que ser delicados? déjenme les cuento, ¿por qué hay que ser delicados en este punto? porque también cuando compilas para una aplicación en Android o IOS pues, súmale el peso normal de tu aplicación, que normalmente es de megabytes, y ahora le vas a incluir un modelo que pesa 2 gigas, entonces digamos que tu aplicación pesa, no sé, un megabyte más 2 gigas pues ahí tu aplicación queda bastante pesada sólo por incluir este tipo de modelos hoy lo vamos a hacer así, hoy literalmente voy a hacer esa mala práctica de simplemente dejar la aplicación muy pesada ¿listo? con un modelo que pesa 2 gigas, por ende la aplicación va a pesar 2 gigas, lo cual es una mala práctica porque normalmente cuando el usuario instala aplicaciones y luego es muy pesada, pues primero se le va a tardar como en descargar, instalar, y eso al usuario no le gusta, normalmente es instalar y que sea rápido, ¿no? pero si es una aplicación pesada, pues el usuario no va a querer instalarla, ¿cuál sería la buena práctica? normalmente la buena práctica es no incluir el modelo dentro de los assets sino decirle al usuario que si quiere descargar ese modelo a su open source o si quiere la, pues no le vamos a decir tan técnicamente, oye si quieres descargar el modelo a open source pues, tienes que darnos permiso y guardarlo ya en la memoria del dispositivo como en el storage, en la sincar o en el almacenamiento que tenga el usuario, pero no es parte de la aplicación, simplemente queda como parte de, como si uno descargara un pdf, un archivo y lo almacena en un espacio específico en donde nosotros sabemos ese espacio específico y podemos ir allá y decir mira, ya está el modelo, entonces normalmente el usuario ya a nivel de UX se le coloca un mensaje, hey si quieres habilitar estos features de IA que funcionan de forma offline, pues descarga aquí el modelo y ahí si ya lo descargas ahí necesitaríamos un proceso un poco más complejo normalmente utilizaríamos un plugin en Ionic para hacer como el acceso a la memoria del dispositivo, al storage del dispositivo y guardar con los permisos del usuario, pues el modelo allí eso probablemente también vaya a cambiar en un futuro, porque normalmente Android dentro, dentro específicamente dentro de Android, del hardware digamos, de los nuevos celulares, los Pixel, los Samsung normalmente ya tienen un Gema instalado, entonces tal vez en un futuro ni siquiera nos toque pedirle al usuario que descargue el modelo, porque ya tenemos un Gema directamente en celulares como Pixel o como celulares como Samsung, sin embargo pues de pronto queremos utilizar Gema en IOS pues ahí no tenemos literalmente Gema disponible en Android entonces ahí si nos tocaría pedirle al usuario que lo descargue y que lo guarde en el storage del dispositivo o tal vez no queremos utilizar Gema, queremos utilizar los modelos Open Source de Microsoft que también los podríamos correr con MediaPipe entonces le decimos, mira si quieres correr este otro tipo de modelo o este que funciona mejor, pues todo el proceso pero hoy lo vamos a hacer como fácil porque no quiero ahorita programar toda la parte de manejar el archivo pedir permisos al usuario del File System, eso puede ser otro video de por si en Ionic lo haríamos con Capacitor con este plugin, déjenme se los muestro si vamos a Capacitor que es al final el Bridge que hace como la implementación nativa y vamos a el File el File System, normalmente con este plugin básicamente lo que haríamos es acceder pues con permisos del usuario tanto en Android como en IOS, pues básicamente podemos escribir, descargar y eso queda almacenado como en el storage del dispositivo del usuario como en, no hace parte del peso de la aplicación, hace parte de los archivos que tiene el usuario en su en su teléfono y simplemente necesitamos la ubicación en donde quedó guardado y lo consumimos que al final es lo que nos piden acá o sea si al final nosotros vemos aquí como en el tutorial nos dicen, hey necesitamos saber en que espacio está, en este momento lo voy a incluir dentro de los assets de la aplicación pero si lo hiciéramos con la buena práctica lo que haríamos es apuntar a donde haya quedado guardado en el storage del dispositivo listo, teniéndose en cuenta entonces vamos a pues correrlo con los assets y todo esto en cuenta acá ya se me descargó pues el modelo, simplemente ya lo que tienen que hacer es descomprimirlo y lo pasan a su carpeta de assets o si quieren hacer ya toda la programación del manejo de archivos, bien yo ya lo tengo acá, como se los mostré, yo ya lo tengo acá, es este que ya está descargado y está ignorado, entonces ahora lo que vamos a hacer es crear un servicio que se encargue, pues siguiendo las prácticas de Angular y Ionic, vamos a crear un servicio que se encargue como de interactuar con la librería de media pipe para interactuar con Gema, listo, entonces vamos a crear un servicio, lo vamos a hacer al estilo de Ionic, Ionic generate service Gema entonces lo creamos, ahí crea nuestro nuestro service, ahí está es un servicio que ahorita está vacío ¿qué va a tener este servicio? pues me va a copiar un poquito este código que está acá, que es al final lo que necesitamos, esto que está acá pero pues ya ponerlo en un modo angular digamos, o en un servicio de angular, entonces ¿qué necesitamos? al final necesitamos este GEM y este file resolver que sale de media pipe, entonces lo lo importamos acá fíjense que todo esto al final es como un método entonces yo podría crear un proceso que al final es asíncrono y le digo cargar Gema model y ahí lo voy a dejar ahí, y me copio el código que teníamos acá, listo por acá por ejemplo guarda esto pues como que eso lo guarda en un lado, en teoría siguiendo de pronto un patrón singleton, voy a guardar eso como en una referencia en el servicio, entonces acá tengo LAR language inference este tipado también sale de media pipe entonces básicamente lo lo instalo, bueno lo importo y acá lo que voy a hacer es para no duplicar el import pues simplemente lo coloco aquí al lado, entonces acá básicamente le diríamos oye el inference puede ser una instancia o puede ser nulo porque todavía no lo tenemos, entonces acá literalmente cambio esto por un dis y ahí ya más o menos lo vamos teniendo entonces acá dejamos esto por acá estos parámetros los voy a dejar, acá literalmente le estoy poniendo el el pad, acá fíjense que acá me detecto un problemita, literalmente yo no tengo el modelo así en assets, recuerden que lo tengo en una subcarpeta llamada models, entonces pues antes de que me falle le voy a poner models, listo entonces acá tengo ya el el load model, como que literalmente esto va a cargar el modelo de gema, el que tengamos en los assets, listo, todo bien por ahí ahora una vez hecho eso pues que es lo que hacemos simplemente ya lo que tenemos que hacer es ejecutarlo, literalmente una vez tenemos la instancia y ese modelo se cargó, dentro de nuestra instancia o variable de la language inference, pues básicamente podemos correr el método generateResponse hacia un texto en específico, entonces voy a copiarme por acá y voy a crear por acá también un un assign y acá lo que me dice es generateResponse lo cual acá ya me autocompleto el código recuerden que estoy utilizando cursor y tengo un video de cursor como idea de inteligencia artificial entonces es un editor que me autocompleta entonces aquí me autocompleto bien fíjense que acá ya supo que oiga, si no hay una instancia o si pues básicamente es diferente o no hay nada, es decir es nulo, pues va a lanzarme un error diciendo que el modelo de gema no ha sido cargado y si si está cargado, pues ok, pues lo llamo y le digo generateResponse con el texto, aquí es donde yo lo puedo escribir, pues le puedo mandar el mensaje del usuario y puedo hacer ya prompt engineering y de más para que pues de acuerdo de pronto a un system prompt me conteste, etcétera, pero ahorita simplemente le voy a decir que responda el mensaje del usuario y ya ok, entonces ya tenemos nuestro servicio, entonces ahora es el momento de usarlo, entonces acá voy a utilizar gemaService, lo inyectamos vamos a importarlo, entonces por acá lo importo, acá lo importo de esta manera, no me gusta que haga esa referencia así, entonces voy a decirle que vaya a service y pues vaya y me traiga este servicio de Angular, listo, tengo gemaService, entonces aquí lo que me falta es, yo ya estaba como poniendo el mensaje del usuario, no, y por acá le puedo poner en HTML, voy a ponerlo acá de pronto el sender acá, el sender y de pronto lo pongo en strong para que para que esté como en negrita, entonces tengo el strong, cuál es el mensaje que está escribiendo el usuario o la IA y pues responde el texto en este momento por ejemplo, entonces lo que haría es, bueno primero tendremos que cargar el modelo, no, o sea, no he ejecutado el loadGemamodel lo podríamos cargar aquí en el ngOnInit, o sea como decirle, hey una vez ya pues está vista cargó, pues cargó el yema podría que sí, o sea podría ser solo que normalmente yo ya cargaría esto casi en el inicio de la aplicación, para que no sólo cuando entre en esta chat page cargue el modelo, no, como que sólo por iniciar la aplicación como que ya cargue el modelo por default, para ahorrar tiempo, bien es más lo cargaría en el de inicio, no, por acá en el app donde tenemos acá el app component que es como el root de la aplicación ahí por ejemplo me parece que es un buen momento, o es más podríamos cargarlo aquí en el constructor y simplemente cuando se instancie este service, pues por defecto también va a cargar o va a correr el loadModel pero por ahora lo voy a dejar explícito, literalmente cuando cargue esta página pues va a cargar el modelo, bien esto es una promise, se va a demorar, le podríamos poner loading, bien como decirle, oye no puedes acceder a esta página hasta que, porque esta página necesita del modelo de yema, entonces hasta que no lo cargue, pues no voy a poder brindarte al servicio, entonces podríamos crear aquí un loading, creo que Ionic tiene un spinner como fullscreen, déjenme lo miro y podríamos crear como este spinner este loading en fullscreen, déjenme entrar la documentación aquí directa components acá lo busco debería estar por acá, Ionic acá, loading Ionic loading, es que tiene unos loadings este es el que yo necesito, este este es el que yo necesito, el que como que está en toda la pantalla, vamos a ver como se hace en angular al final lo que haríamos es tener un Ionic loading y con un true o false al parecer lo habilito ok aquí no se muestra mucho como lo habilito acá está el controller, ese controller a veces me gusta más que simplemente inyectar el controller y lo apuro, creo que este me me gusta más, creo que este me gusta más este, vamos a implementarlo loading controller entonces es un inject un inject, además voy a copiarlo por acá, loading controller y lo copio por acá pero lo vamos a poner en forma de inject entonces por acá y luego pues esto debería importarse no me está importando porque no me está importando no lo reconoce, según esto lo debería traer de Ionic standalone y standalone creo que ya lo tenemos importado por acá si no estoy mal es este de acá entonces deberíamos ponerlo, loading controller listo entonces acá tenemos al loading controller y viendo el código pues al final lo que haríamos es crear este loading con esta constante podríamos ponerlo por acá acá es un await entonces recuerden que una engine init también puede ser asíncrono, acá le puedo decir que voy a cargar el modelo loading model acá hago un await, lo presento luego entonces haría un await de esperar a que el modelo cargue y luego finalmente una vez cargue el modelo le hago un dismiss al al controller, al loading vamos a ver si funciona lo ejecuto, fíjense que ahí está como el loading y en teoría cargó en teoría, ahora acá hay un lío y es, acá tengo un issue acá tengo un problema, bien dice que nosotros necesitamos al final parte de correr el modelo de este tipo de modelos es que necesita un feature que es webgpu, webgpu es también una forma interesante pues de correr modelos y hacer inferencia de inteligencia artificial solo que ahorita es muy limitado por ejemplo fíjense que todavía no está en Chrome de por si no está en nada, solo está en Netsh que raro que está en Netsh por defecto está en Chrome, digo está en Netsh pero todavía no está estable en Chrome en Firefox, en Safari pero básicamente es una forma de utilizar la GPU para correr pues modelos webgpu, es una cosa muy interesante, podemos hablar de este tema en específico, pero básicamente aquí lo que me está diciendo es, oye yo no puedo correr el modelo de Gema, no lo pude cargar porque necesito habilitarme webgpu y dentro de Chrome ya vimos que no está habilitado por defecto no entonces que hay que hacer, habilitar ¿cómo se habilita? eso se habilita dependiendo, pues ahorita lo voy a habilitar como en mi Chrome pero recuerden que al final lo que queremos es correrlo en Android, bien en Android si está habilitado por defecto en el Pixel y hay otra restricción, pues depende del celular, normalmente son celulares de alta gama que tienen esto habilitado en el dispositivo, en Chrome no está habilitado pero en dispositivo si está habilitado, vamos a verlo, entonces sólo como para que corra aquí en la web, voy a habilitar webgpu en pues para correrlo aquí como en Chrome básicamente ahora, ¿qué se necesita para eso? es más aquí debería darme un link ... normalmente me da, ah no si acá literalmente me dio el link mire para habilitar el link pues necesitamos hacer esto, bla, bla normalmente si estás en en en Mac o Linux, vas a esta como a este link para habilitar un feature flag y lo habilitas y ya, pero tú me preguntarás bueno si tú lo tienes habilitado, ¿por qué no te está funcionando? porque pues estoy en Ubuntu, y en Ubuntu las cosas son más complicadas, en Ubuntu lo que toca hacer o si tienes una distribución de Linux no sólo basta con habilitarlo aquí el feature flag, sino que literalmente toca toca, toca, toca ... ... toca correr como Chrome con este feature flag que se llama enable feature Vulkan, que Vulkan de por sí también es un motor que utiliza webgpu, bueno en fin ... para plataformas, entonces básicamente hay que correr Chrome con Vulkan habilitado y ¿cómo se corre? pues otra vez, estamos en Ubuntu, entonces vamos a hacerlo de esta manera, entonces voy a cerrar este Chrome por ejemplo, voy a cerrar Chrome ... no encuentro el cerrado de Chrome, ah ya ya está, vamos a cerrar Chrome y vamos a volverlo a lanzar pero Chrome creo que es ay no me acuerdo cuál es el el ... ... Si voy a Inbox y vuelvo acá, acá literalmente asciende el loading. Aquí precisamente es lo que no quiero. Cada vez que entra a la página como que está cargando el modelo. Por eso digo que deberíamos guardar un singleton o como guardarlo en otra parte de la memoria. Porque está raro que pues obviamente cada vez que yo entre a la página, pues se ponga a cargarlo. Entonces deberíamos cargarlo de otra manera. Pero por ahora para este demo nos funciona. Ahí ya está cargado. ¿Qué quiere decir? Que nos falta la parte de... Ya se cargó el modelo, ahora pues que el modelo responda. Entonces básicamente aquí lo que haríamos es lo siguiente. Y aquí otra vez la guía me autocompletó bien lo que quería hacer. Es decir, General Response. Aquí tengo Cloud, o sea tengo configurado Cursor con Cloud. Y es lo que me está haciendo el autocompletado con Inteligencia Artificial. Entonces acá dice, mira, el texto que es el del usuario. Pues básicamente estoy yendo al General Response, que es esto que teníamos acá. Y está guardando la respuesta. Esa respuesta básicamente le hago un Response Message con el formato que dijimos. Que era un ID, un texto. Y en este caso el sender es GEMA. O sea, el que me está respondiendo es la Inteligencia Artificial. Y simplemente lo añade a los mensajes. Bien. Entonces literalmente ya debería funcionar. Vamos a ver. Entonces acá está cargando el modelo. GEMA. Vamos a ver. Se demora un tantito en cargar. Bla, bla, bla. Ya, al parecer ahí ya cargó. Entonces vamos a escribirle Hola GEMA. ¿Cómo? ¿Cómo estás? No estoy muy seguro si este modelo, como es chiquito, responda bien en español. Pero pues vamos a ver. Ahora, también habría que poner un loader. Y luego ir a la respuesta. Porque esto es al final también una Promise. Entonces GEMA, si bien corre offline, tiene un delay. También no es tan rápido realmente. Y también depende mucho de dónde lo estemos corriendo. Aunque en esta máquina debería correr súper rápido. Pero experimentando GEMA realmente sí se demora en responder. Creo que LAMA y otros modelos que corren on device. O sea, así como corriéndolo directamente en la máquina. Responden más rápido. Pero GEMA en particular no estaba respondiendo como, ah, como que se demora en responder. Y deberíamos ponerle precisamente un loading para saber qué, pues indicarle al usuario que GEMA está respondiendo. Sólo que no quiero hacer una modificación de código ahorita. Porque lo que haríamos acá es volver a crear otro loading. Presentarlo. Diciendo GEMA está generando tu respuesta. Y cuando ya la tenga, cuando este await ya haya pasado, pues lo volvemos a apagar. Pero a ver. ¿Qué pasa? Esta vez está demorando un montón. Aquí ya respondió GEMA. Se demoró un montón en responder. Lo cual a veces es como, realmente podemos correr estos modelos a nivel de experiencia de usuario. Obviamente hablando de, pues un usuario se esperaría como casi un minuto en esperar la respuesta del chat. Normalmente un chat debería ser inmediato. Pero hay que ver cómo corre ahorita en el pixel. Hay que ver cómo corre ahorita en mi Android. A ver si de pronto esa respuesta falla. Si no, podríamos probar GEMA 2. Que es más rápido. Pero tenía, como les comentaba, algunos issues. Entonces tocaría esperar a ver. O si no, podríamos probar otros. Pueden probar el de Microsoft. Pueden probar los de Lama. Que también se pueden correr offline. Lo bueno de MediaPipe es que literalmente, así como cargamos GEMA. O sea, por acá le pusimos en dónde quedó nuestro modelo. Literalmente ahí ponen su modelo. El de Falcon. El de Microsoft. Los de Lama. Que puedan correr en este formato. Ahí Google MediaPipe dice como, pues cuáles son los que ya están listos en el formato. Ahí les dan los links. Así como descargamos el de GEMA. Pues también están los links para descargar otros. Pero bueno, aquí ya respondió. Veamos qué respondió GEMA. Dice, hola. Bueno, creo que me contestó en... Como en Brasil, en portugués. Dice, hola, una mensaje a Activity como a... Sí, esto está raro. Me va a... Me va a escribirle en inglés. Vale. Hello. What is your propose? Como, ¿cuál es tu propósito? Propose. Bueno, escribámoslo mal y a ver qué. Vamos a ver si se vuelve a demorar tanto en la respuesta. Pero, en fin, estábamos queriendo correr un modelo. Ahorita es raro correrlo en el browser. Porque normalmente, pues en el browser corremos... No sé, le pegamos a la API de OpenAI y ya. Y pues si ya está en la web, corren de vuelta. Pero tal vez hayan escenarios que ustedes necesiten correrlo de forma local. Correr un modelo de forma offline, etc. Vamos a ver si ya me responde. Y sería bueno ponerles el log, ¿no? Creo que hay algunas cosas que uno puede empezar a jugar con este tipo de parámetros. Con la temperatura también. Para de pronto mejorar un poquito esa respuesta. O literalmente de pronto ver algo como Gema 2. Que en teoría es un poquito más rápido. Vamos a ver. Se está demorando un montón. También puede ser esta forma de correrlo. Creo que con Vulkan no corre tan rápido. Yo creo que corramoslo directamente en Android, en Pixel y verlo. Y entonces aquí va la parte final de nuestra sesión. Nuestra sesión y es, pues compilémoslo hacia Android. Entonces, mientras aquí a Gema se le da por responder en mi Chrome y demás. Y le damos el beneficio de la duda que sea mi Ubuntu y demás. Vamos a ver al final qué es lo que haríamos. Recuerden que nosotros estaríamos utilizando Capacitor para compilar esto a una aplicación en Android. ¿Cuáles son los pasos para eso? Los pasos simplemente son los siguientes. Simplemente vamos a... Ir a nuestra terminal. Por acá. Por acá está nuestra terminal. Todavía no ha respondido. Qué rara. Vamos a ir acá a nuestra terminal. Y vamos a instalar... Bueno, no instalar. Hay que correr un comando que se llama Ionic Cap Android. Ese básicamente comando es el que va a agregar el soporte para Android en nuestra aplicación. Entonces vamos a instalarlo. Aquí me está instalando una versión en específico. Ionic Cap Android. Y me dice que está instalando la 6.2.0. Y aquí falló algo. Acá me dice que no encontró el directorio www. Normalmente necesita de ese directorio para generar el package hacia Android. Y básicamente eso lo hacemos con el ngBuild. O sea, generamos un ngBuild. Y ahí va a generar como un www. Con todos los aces de la aplicación. Entonces hacemos el ngBuild. Y luego ahí sí hacemos el Ionic Cap Android. Me dice que la plataforma ya está agregada. Al parecer aquí la alcanzó a agregar. Pero no alcanzó como a hacer este update o este copy. Entonces, ¿cómo hacemos? Simplemente para asegurar que eso funcione. Le hacemos un Ionic Cap Sync Android. Que básicamente es la forma en la que decimos ok. Ya hicimos cambios. Hicimos como cosas en nuestra aplicación de Ionic. Y ahora vamos a hacer un update. Y aquí vamos a hacer un update. Y aquí vamos a hacer un update. Y aquí vamos a hacer un update. Y aquí vamos a hacer un update. Entonces, simplemente le corro un Ionic Cap Sync. Y él va a hacer el build. Y otra vez va a sincronizarlo con el build de la aplicación. Y otra vez va a sincronizarlo con el build de la aplicación. Acá hay otro error. Acá hay otro error. Acá me dice mira, el www no tiene un index html. Acá me dice mira, el www no tiene un index html. Y este si es un error específico de Ionic. Y este si es un error específico de Ionic. Y sobre todo de Ionic. Pues utilizando el nuevo builder. Recordemos que Angular tiene unos nuevos builders. Desde la versión del 10. Desde la versión del 10. Pero en este caso, pues utilizando el nuevo builder, recordemos que Angular tiene unos nuevos builders, desde la versión 18, 17, tiene como unos nuevos builders, y resulta que cuando uno compila con el builder de application, que debe estar por acá, ¿dónde está el builder? No lo encuentro, creo que es este, ah sí, build Angular application. Ahora como esta application de builder tiene server-side rendering, normalmente deja una carpeta llamada browser, que es la single page application, y otra server, en caso que queramos generar una server-side rendering, pero en este caso es Ionic, así que no quiero hacer server-side rendering, porque literalmente no va a correr en el servidor, va a correr en un Android, entonces no lo quiero hacer, sin embargo, él estaba esperando que directamente aquí esté, o sea, como que todos estos archivos de browser estén aquí afuera directamente. ¿Cómo lo solucionamos? Podríamos cambiar la carpeta y decirle que browser lo deje afuera, ¿no? ¿Cómo lo solucionamos? Podríamos cambiar la carpeta y decirle que browser lo deje afuera, pero no lo solucionamos, porque literalmente no lo solucionamos, pero es más fácil decirle a este archivo de capacitor que esté en browser, que literalmente todo lo que necesitamos que esté por allá en Android sea la carpeta browser, ¿no? En browser, o sea, ahí está. Entonces, haciendo esta pequeña configuración, y le hacemos otra vez un Ionic AppSync a Android, él debería generar ya la compilación final de nuestra aplicación, que es el ng-build, y mover eso a una estructura en Android para compilar eso para un Android. Entonces, acá, al parecer, todo estuvo correcto. Entonces, ahora nos queda abrir esto en Android Studio y mandarlo. Para eso, el comando es ionic app open android. Vamos a ver si me funciona. Ahí está, me abre Android Studio. Entonces, aquí ya tengo el proyecto en Android Studio, ¿no? Entonces, acá tengo todo. Tengo la aplicación, tengo etcétera, ¿no? Entonces, vamos a... Acá ya tengo mi Google 8, mi Pixel 8 Pro. Le vamos a decir que compile la aplicación. Entonces, vamos a ver si la compila, si la carga aquí en mi dispositivo, y si, pues, sigue funcionando bien, ¿no? Acá creo que está el proceso. Acá está haciendo el building. Sí, acá está haciendo el building. Y acá nos va a dar un error. Este error, esperaba este error. Que es este error de acá. Compress debug assets. ¿Por qué? Por, de nuevo, por defecto, Android nos va a decir, oye, tienes un asset... Es muy similar a lo que hace Github, ¿no? Como, oye, tienes un archivo muy pesado y no lo subas. Aquí nos está diciendo, oye, ¿estás seguro que quieres compilar una aplicación que va a pesar 2 GB? Porque ese asset no lo puedo comprimir, ¿no? Como que está muy pesada la aplicación, ¿estás seguro? Y por defecto... Como que falla. Voy a pasar como este alert, mandándole una configuración, pero voy a pasar como... Básicamente me voy a ignorar esta buena práctica para que me deje hacer la compilación. ¿Listo? ¿Qué tenemos que hacer? Básicamente, ese error... Ese error... Lo tenemos por acá. Es este... Este link. El error me lo diga el número cual. Vale. ¿Nos vamos a poner 500? Acá en la documentación... Ay, nunca respondió. Ah, sí, por acá. Fíjense que acá ya respondió Gemma, después de mucho tiempo. Yo soy... Yo soy curioso saber acerca de ti. Bueno, yo soy muy curioso. Déjame saber acerca de ti y tu propósito. Yo apreciaría si tú me puedes contar más acerca de tu background, tus objetivos y cómo yo puedo contribuir a mis objetivos. En particular, si tú eres interesado en aprender acerca de tu background, cómo yo puedo contribuir a mis objetivos. Yo sé que tú tienes un objetivo. Yo sé que tú tienes un objetivo. Yo sé que tú tienes un objetivo. Yo sé que tú tienes un objetivo. Tu base de conocimiento, tus capacidades y tu forma de resolver problemas. Gracias por tu tiempo y consideración. Saludos cordiales. No sé, a Kajema me respondió raro. Raro me respondió. Recordemos que no es un Gemini 2.0. Es un modelo que tiene ciertas limitaciones. Hay que hacerle buen prompting para que realmente funcione bien. Pero respondió, respondió. ¿Ok? Entonces, ahora, ¿qué es lo que haríamos? Entonces, básicamente, si yo quiero incrementar esa memoria para que compile, tengo que ponerle esta banderita en como los properties del Gradle. Que Gradle, básicamente, es el gestor de archivos de... Es como el NPM de Java, básicamente. Aunque es más que un NPM, también hace building, hace testing y también gestiona dependencias. Entonces, básicamente, si lo quieren rápidamente, como tener un simil, es como el NPM. Pero realmente creo que el simil es como BUN. Que BUN.js, básicamente, BUN.js, que es como este nuevo runtime de JavaScript, literalmente corre el test, hace el building, también gestiona las dependencias, como que hace todo. Acá dice Package Manager, hace el Builder. ¿Qué más hace? Vamos a ver. Hace el Test Runner, etc. Así que esto sería el Gradle, pero en Java. ¿Listo? Aquí, básicamente, vamos a buscar el archivo dentro de nuestro proyecto Android, Gradle Properties, y vamos a encontrarnos con este. Entonces, básicamente, lo que vamos a hacer es cambiarlo. ¿Por qué? Por este que dice 6 GB. 6 GB, ¿no? Básicamente, cambiamos esto por esto, ¿no? Lo podemos comentar por si en algún momento queremos, pues, tener registro de lo que estaba antes. Lo guardamos. Y aquí, cuando lo guardamos, él nos dice que, pues, necesita sincronización. Entonces, le decimos que sincronice. Entonces, él va a devolverse un poquito cómo sincronizar esa nueva configuración. Y, en teoría, ya podríamos hacer Build sin que nos diga que tuvo un problema con compilar la aplicación. Entonces, vamos a volver a compilar la aplicación y esperemos, esta vez, que compile de forma, pues, bien, correcta. Listo. Aquí dice que generó el Builder bien. Vamos a ver si por aquí ya en mi Android sale la aplicación. Y, no, todavía tenemos aquí el Loading. Todavía está corriendo la aplicación. Fíjense, por acá dice Running y está como el Loading por acá. Entonces, algo va... Ahí ya está, ahí ya está. Ahí parece que ya está. Listo, tenemos la aplicación. Literalmente, tenemos nuestra aplicación corriendo. Fíjense que es una aplicación que está corriendo. Aquí está. Es una aplicación en Android corriendo. Normalmente, me instala... No me acuerdo qué nombre quedó. Ah, ahí está, Gema. Ahí está, ¿no? No sé si la alcanzan a ver. Por acá quedó. Gema, Gema, Gema. Gema, Gema, Gema. Acá está, Gema. Listo. Y acá está el chat. Entonces, vamos a ver. Acá está haciendo el Loading del modelo. Aquí cargó aparentemente más rápido. Vamos a ver si tú le has dado. Vamos a darle un emoji. Y... Aquí va a tener un error. Porque... Ah, creo que con Enter es que... Ah, sí, Enter, Enter. Ah, mire que acá respondió. Relativamente respondió más rápido. Así que... El beneficio de la duda de cómo corría en Chrome, con Vulkan y demás, se lo dejamos porque aquí realmente respondió muy rápido. Vamos a ver en español. Vamos a ver. Hola. Vamos a ver. Ah, ya sacó un error. Bueno, igual me sigue respondiendo como en... En... Inglés. Y no en español. Pero es una de esas limitaciones. Pero igual, mira lo que estás pudiendo hacer. Estás pudiendo correr un modelo que es open source, que no le estás enviando... Datos, pues... Interacciones o de pronto si quieres hacer... Lo normal, que son las tareas normales de un LLM, como ponerlo a resumir, ponerlo a corregir un texto, no sé. Ponerlo a contestar un chat. Recuerda que no solo un LLM, la expresión de un LLM se ve en un chat. Normalmente uno le puede hacer tareas de resumen, tareas de sacar un análisis, sacar una recomendación. Todo obviamente en base a texto, porque es un LLM. Pero... Pero, ajá, pues... No está funcionando. A ver, vamos a escribirle así como una petición. Una petición, ¿no? Give me a Python... Déjenme aquí, le voy a... El otro mirroring me gusta más que el de Chrome. Es más como... Como limpio. Este. Give me a Python script to resolve... A Fibonacci... A Fibonacci... A Fibonacci... Fibonacci... Fibonacci... Fibonacci... Fibonacci, a ver, vamos a escribirle eso. ¿Por qué? Porque también puede escribir código. Ahora, el lío es cómo me lo va a entregar. Y toca parcial el formato, pero vamos a ver cómo me lo entrega. Y obviamente nos faltó el loading, al parecer. Eh... Pues para respuestas un poquito más grandes, se está demorando un poquito más. Vamos a ver. A ver si es que no... Hay otro error por ahí. No, no. No, ahí sí ya está cargando bien. ¿Por qué? Pues ya se está demorando en responder. Eh... Ash, ¿por qué se está...? Ah, bueno, ahí ya. Entonces, fíjense que me respondió y me respondió como en un formato Markdown, ¿no? Aquí, por ejemplo, me dice, ay, la función y etcétera, ¿no? Obviamente ya esta respuesta que tiene un formato Markdown, yo debería ya interpretarla en Angular y ponerla bonita hacia el usuario con algo que soporte Markdown y mostrársela, etcétera. Pero, literalmente, logramos correr Gema y hacer la inferencia del modelo. ¿Por qué? Porque es la inferencia del modelo directamente desde la aplicación de Ionic. Nos falta lo de offline. Eso se los puedo deber y se los resuelvo por ahí. Pero creo que al final mostrar esta capacidad de poder correr estos modelos que son open source y usar simplemente JavaScript, porque al final sí lo que miramos es que lo que usamos finalmente fue la librería de MediaPy, que es como la que nos permite hacer esto, que es la de Google, y simplemente descargamos un modelo y lo podemos empezar a usar. Esto no solo funciona para JavaScript, funcionaría también en Python. O sea, si yo tengo de nuevo un modelo, digamos, un servicio backend en Python y quiero correr Gema de forma en mi nube, literalmente también podría utilizar MediaPy, pero pues el SDK para Python y así para iOS y así para Android. Bien. Entonces. Y recordemos que Gema a lo que iba es que Gema tiene como otra familia de modelos. O sea, no solo está Gema. Gema uno fue el que probamos hoy, pero literalmente pues está Gema dos. Está CodeGema, que es un modelo también chiquito que uno que es literalmente solo para generación de código o un modelo específicamente en código. Está RecurringGema, que es la verdad, no sé qué es, pero Palingema sé que básicamente era un modelo que incluía. Visión. Entonces, si tú le pasas una foto, podría analizar qué hace la foto o qué hay en la foto y literalmente no lo puede también descargar en Keygold, etcétera. Entonces hay ciertos modelos de pronto de Gema. Este Recurring. A ver qué es. Es un modelo de Riffen que tiene. Al parecer es como que tiene otra arquitectura adecuada para esta generación de texto, responder preguntas. En fin, literalmente Gema tiene una familia de modelos interesantes. Palingema. Recurring. Uno solo basado en código y es un modelo. Ya los podrías correr de forma offline o de forma directa en tu dispositivo sin necesidad de ir a una nube. Listo. Y de esta manera, entonces literalmente puedes correr de Gema un modelo Open Source de Google de forma en el que corre directamente en el dispositivo. No estás corriendo o estás apuntando a ninguna nube, sino directamente tienes el modelo ahí directo para ejecución. Y todo lo hicimos también con la API. O la SDK de Google Media Pipe, que es el que nos permite literalmente correr estos modelos. Y en este caso lo utilizamos y lo integramos en una aplicación de Ionic con Angular. Así que no siendo más, esto es todo por este video y recuerda suscribirte a este canal. Nos vemos en la próxima.