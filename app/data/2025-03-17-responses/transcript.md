 OpenAI ha lanzado una nueva API que es Responsive, Responsive API, que va diferente al típico o al mítico endpoint que siempre habíamos utilizado del chat completations para poder hacer como todo lo que son chatbots, agentes, etc. Entonces vamos a explorar en este video cuáles diferencias hay, qué debemos tener en cuenta con esta nueva API y sobre todo qué beneficios tiene, qué es lo diferente y cómo nosotros podemos abordar esas diferencias. Entonces, explorando directamente con el SDK nativo en Python. Así que vamos a ver las diferencias en este video y qué cosas debemos tener en cuenta. Y de por sí, esta nueva API tiene una nueva característica que me pareció bastante interesante, que es que a diferencia de otras APIs o la mayoría de APIs son stainless, pero esta nueva API es stayful, es decir, mantiene el estado, cosa que va a ser muy interesante. Así que pues nada, empecemos el video y veamos de qué trata. Y de esto se trata. Realmente hay una nueva... Un nuevo endpoint, una nueva forma de llamar a los modelos, a los diferentes modelos que tenemos en OpenAI y este se llama Responses API, diferente a Chat Completitions. Bien. Ahora, realmente aquí tenemos la diferencia. La diferencia es bastante interesante. Realmente podemos hacer exactamente lo mismo que teníamos con Chat Completitions, solo que todavía no tenemos audio. Es como la única parte que falta, digamos, implementar en Responses API. Pero lo que sí tenemos o lo que sí va a haber, o sea, no es que no va a haber, esto está todavía en trabajo, muy posiblemente ya luego tengamos el check. Pero entonces lo que sí hay es unos checks bien interesantes que son unas tools. Y esto es muy importante porque al final OpenAI está cada vez lanzando más cosas y se está moviendo más al approach de los agentes. ¿Qué significa esto? Bueno, significa normalmente que OpenAI lo que está haciendo es casi cada... Uno de los productos que está lanzando, como el web search, por ejemplo, la búsqueda profunda, el computer use, casi todo lo está volviendo una tool, una tool que nosotros podríamos utilizar en nuestros agentes. Y esta nueva API, Responses API, precisamente trata de abordar esto. Trata de como cambiar la forma en la que normalmente nosotros trabajamos con la API para volverla un poco más agent. Y sobre todo vamos a empezar a manejar tools. Tools nativas, obviamente que vienen desde OpenAI. Entonces cosas como una búsqueda en la web se vuelve una tool. Una búsqueda privada se vuelve una tool. Hacer computer use se vuelve una tool. Posiblemente el producto que tienen que es hacer estas investigaciones, como esta investigación, este research, el research, el modo research que tiene OpenAI, que por ahora está como un producto dentro de ChatGPT, posiblemente lo vuelvan una tool. Y así entonces vamos a empezar y van a empezar a sacar como más características, entonces esto requiere que ellos hayan cambiado esta API como para que se alinee un poco más. Y de pronto pues también para que, pues es una gran manera de empezar a probar diferentes approaches sin romper la API anterior. Entonces de eso se trata. Entonces vamos a explorar precisamente esta nueva API. Ok, entonces ¿qué tenemos ahora? Tenemos, o sea, de nuevo tenemos como lo típico, estructural outputs, function calling. Lo que tenemos nuevo que no había antes es file to be, y lo que tenemos ahora es el file to be. Search, computer use y el interpretador de código, pero ese todavía no está listo, literalmente viene pronto. Sin embargo, si bien, si bien todo esto está como en check, o sea, está disponible para usar, pero no significa que no rompa cosas. Si rompe cosas en cuanto a que si utilizas la nueva response API, hay que hacer ciertos ajustes para utilizarlo. Acá básicamente podemos ver esos ajustes, acá podemos ver como la diferencia, por ejemplo, cuando tú utilizas... la API de ChatCompletitions, que recuerdan, esto es el SDK de Python, que también está en JavaScript, que se puede consumir de esta manera, pero realmente al final por detrás lo que hace es un request a la API de OpenAI, porque al final el modelo no corre en tu máquina. Tienes a Python como un wrapper básicamente y una forma más fácil de consumir la API, pero básicamente pues todo es un request a la API, a la de los servidores de OpenAI que devuelven la información. Entonces, también si nosotros ya lo miramos a nivel de endpoints, tenemos un nuevo endpoint. Déjenme ver si por acá tengo los endpoints, RealTime, Agents, Build Tools... a ver, pues, qué vamos a sacar? Responses, responses... acá tenemos responso, vamos a ver si lo encontramos. Y acá, literalmente, acá vemos, bueno, acá... acá lo vemos en Python, pero lo podemos ver como Qrk... y literalmente este es el nuevo endpoint responses b1 slash responses ah bueno acá también se podía ver diferente al chat completitions chat completitions acá vuelvo a mi artículo donde nos mostraron las diferencias pero acá básicamente es el otro endpoint de chat completitions déjenme ver si lo encuentro rápido creo que acá lo puedo ver si lo cambio acá ahí cambia a chat completitions y bueno no acá me sigue ah bueno por acá lo puedo cambiar a javascript no, no me dejó ver el curl bueno por acá debe estar a veces la documentación de openAI cambia bastante pero en fin simplemente es un nuevo endpoint va y ataca a un nuevo endpoint y eso es lo que también tenemos que tener en cuenta pero podemos ver algunas diferencias por ejemplo si tú consumes la API ya sea por el endpoint o por el SDK de javascript o python vamos a ver que por ejemplo ya el mensaje no viene por ejemplo como en un array en donde tienes que hacer sub cero sino que ya la respuesta viene directa como en output text y también las cosas cambian un poquito acá por ejemplo nosotros enviamos messages ahora enviamos inputs bien entonces eso hay que tenerlo en cuenta porque eso también cambia si tú estabas consumiendo la API nativa desde request a punta de request pues también tienes que cambiar esos parámetros y si estabas utilizando el SDK de javascript o python pues tendrías que hacer este tipo de migraciones entonces cambiar response ahora enviar inputs etc vamos a hacer el ejemplo de cada una de las cosas y vamos a ver cuáles son las diferencias porque acá si hay unas diferencias notables por ejemplo al utilizar structural outputs como se llama los modos de razonamiento y sobre todo aquí hay algo muy interesante que es que ahora en esta nueva API que eso es algo que no tiene chat competitions maneja algo que es el estado de la conversación por defecto entonces para eso vamos a abrir un notebook y vamos a explorar esta API entonces déjenme abro mi editor aquí tenemos un notebook desde cero en el cual está cargando pues las APIs de OpenAI acá literalmente estoy llamando a la nueva versión o al SDK actualizado de OpenAI y vamos a copiarnos el bloque de código de ejemplo que tienen ellos ahí voy a eliminar esta parte porque ya el client lo tengo por acá fíjate que por acá ya lo tengo solo creo que falta ah no el client acá ya lo tengo literal entonces estas dos líneas me las puedo guardar y listo entonces acá que tenemos tenemos si yo le hago si yo corro esto vamos a ver que todo corre bien y acá por acá me dice ah acá creo que hay un error con input ahí vamos a correrlo acá se está demorando un poquito listo y esto es raro esto es raro porque es un error en la documentación directa de OpenAI es decir ellos también cometen errores y por ejemplo aquí el ejemplo en el código no es inputs es input y por eso me estaba dando un error así que simplemente corrijan esto en input seguramente ya en la documentación van a corregir esto pero fíjate que ahora pues lo que hacemos es en vez de usar chat completicios utilizamos response y pues ahora ya la respuesta viene directamente en output text ahora en inputs viene normalmente lo que nosotros teníamos como el array de mensajes en el cual le indicábamos el rol básicamente esto es un mensaje del usuario un mensaje del sistema un mensaje del asistente y acá me dice que escriba en una sola sentencia como una historia acerca pues para dormir de un unicornio y acá pues tenemos la respuesta bien entonces bien acá tenemos un primer cambio y es input vamos a ver un segundo cambio que vemos aquí en la API y es el siguiente ahora ellos tienen un parámetro que se llama instructions bien instructions es básicamente lo que conoceríamos como el system prompt en donde acá le decimos que tú eres un vamos a decirle que es un asistente que habla como un pirata bien entonces fíjate que acá yo este es el input del usuario que es lo que el usuario le escribe le pide al chat pero acá le doy algo que son las instructions esta nueva como variante o esta nueva variante que es el parámetro no estaba dentro de chat completición básicamente se lo es es nuevo también es parte de esta nueva API de response entonces ahora el system prompt podríamos enviarlo acá y vamos a probarlo vamos a ver le estamos diciendo que escriba o sea que el usuario le sigue pidiendo como una historia de un unicornio pero ahora en el system prompt le decimos que tiene que hablar como pirata entonces y si quieren le podemos decir que tiene que hablar como un pirata y your response are in en spanish spanish listo entonces ahí vamos a ver vamos a correr entonces en teoría debería responder en español hola una vez navegado por la sierra estrellada dejando un rastro acá no no veo que responda tanto como pirata vamos a correrlo una vez más pero acá literalmente le voy a decir que es un pirata puede ser ah bueno acá ya es como que había una vez en altamar un unicornio bueno y bueno de alguna manera digamos que si lo puso en modo pirata es decir tiene un contexto de las olas y no sé qué más cosas entonces aquí ahora nosotros podemos darle directamente como el system prompt en vez de como dentro del array de mensajes ponerle el system sin embargo sin embargo si nosotros tenemos código legacy y queremos hacer una migración hacia responses entonces pues también igual nosotros podríamos seguir teniendo nuestro system prompt con el array esto se sigue soportando es decir yo le digo que esto es ese es el rol del sistema y podría ponerle este mismo prompt aquí y pues comento esta parte esto seguiría o debe seguir funcionando vamos a ponerlo navego acá todavía me sigue diciendo que por los mares y cosas así entonces ahora de nuevo por por por por por por por por por por por por por, por mantener la compatibilidad con chat competition si tú cambias hacia responses igual sigues enviando dentro del array de mensajes sigues enviando el system prompt pues lo puedes seguir haciendo de esta manera o puedes utilizar la nueva variable del nuevo parámetro que es instructions que actuaría como el system prompt entonces eso es parte de esos ajustes de esos cambios ahora otro cambio bien interesante viene dentro de de los structure outputs ven todo lo que es como un output estructurado entonces si nosotros acá por si tienen como un drop down en donde podemos cambiar hacia la nueva API responses o hacia chat competitions y acá pues miran como es bueno acá nos manda la documentación de comparar las api's pero qué es lo que cambia acá acá también si tú estabas manejando pues data estructurada o querías que el modelo te retorne data estructurada pues si estás utilizando el chat competitions normalmente en python enviabas algo como respond format ven acá está el prompt del sistema y acá están los mensajes esto es lo que ha cambiado pero acá enviabas como respond format y le enviabas como un modelo en python en javascript podría ser un modelo en sot si no estoy mal es más si lo cambiamos a javascript fíjate que utiliza sot para mapear el modelo y le dices que responda como en ese formato es un tipo de y le dices que responda como en ese formato es un tipo de respond format respond format como sería ahora la nueva api ya no hay respond format en el ejemplo todavía no está que se pueda enviar como una clase en python de pydantic o de sot en javascript entonces lo que están haciendo aquí es enviar el esquema directamente y ya no sería respond format sino sería text y en text va format y en format va pues como todo el esquema que queremos que responda es más vamos a copiarnos este pedazo de código y vamos a ponerle un nombre y vamos a probarlo y ver cómo funciona en nuestro notebook entonces vamos a abrir por acá otro vamos a abrir por acá otro vamos a abrir por acá otro voy a hacerle un poquito de menos zoom voy a hacerle un poquito de menos zoom ahí está y bueno esto ya lo tengo instanciado ahí está y bueno esto ya lo tengo instanciado entonces de nuevo usando la nueva api ok tenemos acá el de nuevo todavía tenemos el rol del sistema pero sabemos que también podríamos ya enviarlo directamente en instructions cosa que va a ser muy interesante luego pero de nuevo por compatibilidad podemos seguir enviando el system prompt luego entonces ya no sería respond format luego entonces ya no sería respond format sino acá le enviamos format y acá le enviamos un json esquema recordemos que este json esquema no es cualquier json esquema es el estándar json esquema vamos a ver este es literalmente tienes que seguir el estándar no puedes poner cualquier cosa acá hay una especificación de cómo armar un json esquema no por ejemplo acá está a ver si me encuentro con un ejemplo introduction use cases get started acá json esquema lo básico por ejemplo entonces por acá nosotros tenemos que declarar como un esquema el tipo esta es una forma en json de decirle cómo debería retornarlo esto es muy usado por ejemplo para documentar apis con swagger bueno un montón de cosas y aquí vemos de por sí qué bonita landing en donde nos dicen como los tipos primitivos por ejemplo acá tenemos una forma en la que podemos declarar tenemos una forma en donde cómo mapear las propiedades es muy interesante porque también nos dice cómo podríamos mapear a rise por ejemplo los decimales o sea nosotros podemos decirle por ejemplo un patrón que cumpla con un patrón que cumpla con cierto parte en específica por ejemplo estos enums vamos a ver acá nosotros le estamos diciendo aunque acá no hay un ejemplo de enums vamos a ver si encuentro los enums por acá objetos a rise a rise tu por validation vamos a ver si aunque estos son enumated bueno acá se define como un enum este es interesante esto quiere decir que la variable va a ser tipo a rise pero va a tener unos ítems o sea va a haber un string y tiene que elegir algo de ese string pues un enum en un enum en typescript o un enum en python etcétera y eso se puede definir como esquema y es muy interesante porque entonces tú le puedes pedir a chagpt que por favor analice o te devuelva la información en ese formato bien entonces por acá bueno aquí tengo que importar jason la librería de python import jason vamos a ver si si ahí está y acá lo que estamos haciendo es lo siguiente acá el system prompt es extraer información de un evento y acá tenemos digamos que el usuario escribió esto Alicia y Bob están yendo hacia una feria de ciencia el viernes entonces aquí este este no es como un chat conversacional aquí lo que estamos haciendo es de acuerdo a un string que me envía el usuario detectar entidades y yo quiero que me las identifique y además que me las devuelva en un objeto jason entonces aquí es donde yo le envío el formato y le digo mira necesito que lo envíes como un calendar calendar event y primero me envapees el nombre del evento que sea de tipo string que me envíes la fecha que sea tipo string aquí es donde también puedo poner un patrón por ejemplo si yo quiero decirle oye devuélvemelo en no sé en día mes año etcétera eso también lo podemos hacer entonces aquí es donde uno le pone el patrón por ahora lo voy a dejar todavía como string y los participantes y los participantes es un array y cada uno de los ítems del array es otro string luego le digo que es requerido que sea estricto etcétera entonces vamos a ver si este texto logra extraer esa información y utilizando el structural output pues puedo devolver eso en jason vamos a ver retornamelo acá ah bueno no lo imprimí entonces vamos a imprimirlo print event esto de por si es una o sea esto es una pieza clave para los agentes porque porque utilizar structural output me permite identificar patrones partes en la conversación cosas con el cual yo puedo saber por ejemplo llamar a una API esto es muy útil para hacer function calling porque puedo detectar la fecha el día parámetros y eso enviárselo a una API entonces por ejemplo aquí ya no me responde un texto porque yo le dije que no me respondiera un texto le dije que me responda pues en un formato que es este entonces me dice así mira el nombre del evento es pues feria de ciencias la fecha viernes si yo le hubiera pedido el patrón de día etcétera probablemente me lo de sin embargo aquí hay que hacer unos trucos en cuanto a ok es el viernes pero el viernes cual viernes entonces a veces hay que darle como contexto la fecha de hoy uno puede aquí por prompting decirle ten en cuenta que hoy es y uno puede enviar aquí pues la fecha actual para que el sepa la fecha actual y con base en ello y luego me dice que el viernes es el viernes que sería pues el viernes de este mes que es marzo en fin y luego me dice los participantes que es Alice y Bob y me los envió como un string digo como un array de strings porque yo se lo pedí como parte del esquema y pues acá está Alice y Bob entonces acá esto es súper fundamental para los para los agentes para hacer cosas de agentes es muy interesante poder analizar y decirle al modelo que responde en un formato en específico para luego analizarlo y sobre todo que jason es un formato súper amable para poder tomar decisiones como que yo puedo saber si viene o no viene cuál es el parámetro y con base en ello pues tomar una decisión dentro de mi agente entonces esto cambia un poquito realmente la funcionalidad sigue siendo la misma sigo teniendo una forma estructurada de volver pues de decirle a OpenAI que me devuelva la información sólo que ahora viene en este formato de la web este parámetro text y format cosa que en el de chat completitions venía como aquí en response format entonces ese es otro pequeño ajuste que hay en este nuevo responses bien y hay que tenerlo en cuenta si al final quieres irte y migrar hasta esta nueva API listo que de nuevo al final esta API viene con lo mismo de chat completitions pero luego viene con las nuevas ventajas que son las tools que pues vamos a ir viendo pero si al final tú quieres migrarte a responses porque ahora quieres utilizar tools y quieres pues ya pegarte a esta nueva API pues tendrías que hacer este tipo de migraciones o si quieres utilizar structural output y cosas de ese estilo bien ahora veamos otro bien interesante parte de esos ajustes que es como yo elijo un modelo de razonamiento acá tienen un ejemplo bastante interesante también me lo voy a copiar y lo voy a llevar a mi notebook entonces vamos a ir acá al notebook y acá lo que tenemos es que bueno el prompt es y este prompt es del digamos que lo que pide el usuario yo aquí ya le puedo poner un instructions y le digo que tú eres un asistente pues de código como a you you app suscribiendo mal you are an code asistente listo como parte de la instrucción digamos y tengo el prompt y etcétera acá hay una nueva como también parámetro en el cual estoy diciendo cuál es la forma de razonamiento sin embargo esto para mí debería ser automático es decir si yo escojo razonamiento medio también está low y también está alto lo voy a poner medio y eso va pegado normalmente a utilizar también un modelo de razonamiento yo quisiera por ejemplo que si yo elijo razonamiento es porque pues por debajo automáticamente openai deberías elegir el modelo de razonamiento por ejemplo acá yo no le puse cuál modelo ah bueno si acá está gpt4 y acá está por defecto normalmente es gpt4 o que es el que es multimodal pero acá estoy escogiendo uno de la serie de modelos de razonamiento que es los de los 0 0 1 0 3 en este caso estoy utilizando 0 3 realmente uno puede utilizar el 0 1 pero esto pues creo que ya hay que pagar un poquito más para utilizar el modelo de razonamiento más fuerte que tienen pero por ahora podemos utilizar el 0 3 y aún así controlar el razonamiento entre bajo medio y alto como para que piense un poquito más antes de escribir entonces vamos a ponerle vamos a ver qué script me pone acá yo puedo empezar a fusionar cosas o sea yo podría utilizar esto y también utilizar y decirle que yo lo quiero en una forma estructurada acá por ejemplo como le puse razonamiento pues se demora más básicamente entonces fíjate que acá la respuesta es ok mira este es un script que en teoría cumple con lo que dice el usuario escribió un script que tome una matriz representada en un string con esto y pues haga la traspuesta etc entonces acá literalmente me escribió un archivo en teoría que es batch y ese ese archivo tendría pues este este contenido otra de las características que es muy importante de responses es que ahora es stayful realmente uno puede cambiarlo puede ser stayless y stayfull ¿qué quiere decir esto? que normalmente nosotros para como que guardar contexto o el historial de la conversación hacemos varias cosas por ejemplo en input o messages normalmente con alguna base de datos cargamos como el historial de mensajes y con eso el agente o el bot tiene el contexto de lo que ha venido hablando pues para responder con mejor pues con una mejor experiencia de usuario para recordar un poco qué es lo que habían hablado y seguir respondiendo con base en ello sin embargo normalmente se utilizan como bases de datos cosas externas para poder lograr esa característica ahora la API de forma nativa puede manejar el historial de la conversación por nosotros y nosotros no tendríamos que como que utilizar una base de datos per se realmente para mi punto de vista sigue siendo más útil inyectarle ese contexto con una base de datos y metérselo en los inputs o messages pero vamos a ver esta nueva opción que tiene que es la API de las respuestas para guardar el historial veamos cómo se maneja el stayfuls o como le decimos a esta API que maneje el historial de la conversación fíjate muy bien este es el ejemplo clásico en donde simplemente estoy escribiendo algo verdad entonces yo el usuario envía algo lo estoy enviando como el contexto en un array no le voy a cargar el historial que es normalmente lo que se hace para manejar pues el contexto de la conversación le voy a decir a OpenAI que lo maneje por mí ¿cómo lo hace? vamos a ver lo siguiente al final lo que normalmente ahora tiene es que él tiene un id o sea por cada una de las respuestas él tiene un id acá por ejemplo tengo una identificación le puedo decir que no le puedo decir oye no no no me guardes el store este en false por favor no me guardes esto vamos a ver si con false id debería ser nulo o le estoy diciendo la variable que no sea la incorrecta esto va a estar aquí en la documentación por acá en la en el mismo texto en donde nos dicen acá por acá por acá por acá acá nos dicen cómo manejar el estado de la conversación realmente con decirle store en false por ejemplo acá debería no guardar el id aunque puede que me guarde el id pero lo que puede hacer es que simplemente ya no haga retrieve del contexto anterior puede simplemente ser eso pero pues seguimos probando entonces aquí si no quiero que me guarde el historial parece que sí me tiene un id pero no el historial entonces vamos a probarlo entonces voy a volverle a decir que sí le voy a dar true entonces aquí tendría el id y qué pasa a ver vamos a probarlo de esta manera voy a por ejemplo yo voy a escribirle en el primer mensaje voy a escribirle mi nombre es nicolás hola mi nombre mi nombre es nicolás va está bien entonces si yo lo ejecuto qué pasa pues me dice hola qué tal en que puedo ayudarte y me da un id de ese response perfecto ahora qué pasa si yo le vuelvo a preguntar hola recuerdas recuerdas mi nombre entonces si yo le digo esto no debería recordarlo porque es otro request es literalmente sería aquí estamos utilizando stales es decir no tiene estado hola no tengo la capacidad de recordar nombres bla bla perfecto estos stales pero qué pasa que ellos ahora tienen una variable que si yo le digo previous response y le envío el id del previo de la respuesta anterior él como que empieza a concatenar y a tener referencia al mensaje anterior entonces si yo le envío el id entonces lo envío aquí como strings y le vuelvo a preguntar hola recuerdas mi nombre recuerda que el mensaje anterior era que mi nombre es nicobites entonces vamos a ver si ya lo recuerda entonces lo ejecuto hola claro que sí es nicolás nicobites qué tal va tu día perfecto entonces ahora esta api tiene esta funcionalidad de que con base en el id yo al siguiente mensaje le podría enviar el previous response y el inautomático entonces bailando la conversación bailando la conversación cosa que es bastante interesante porque pues esto básicamente en programación es guardar el id anterior y enviárselo por cada nuevo mensaje entonces en automático ahora responses guardaría el estado de la conversación cosa que normalmente lo que hacíamos es guardarlo en una base de datos y írselo enviando acá no como normalmente uno lo enviaba acá el rol del usuario esto respondió el assistant luego uno guardaba luego ahora el usuario respondió esto y como que en el caso de que el usuario respondió esto en el array le enviabas todo el historial de la conversación y por último pues el mensaje más actual del usuario se lo enviabas ahí pero ahora parece que simplemente podemos olvidarnos de eso enviar el previous response y ya con eso él maneja el contexto de la conversación y listo esas son como las diferencias más fuertes que hay entre chat completations api y responses api realmente hay otras cositas un poco más de detalle que acá pues te invito ya que le das la documentación pero creo que aquí cubrimos como las más importantes también cambia un poquito el funcional cabin pero es similar a la estructura de output es decir lo que cambia es un poco el formato en que se le envía por ejemplo acá tenemos type el name description y los parámetros si nosotros lo comparamos con chat completations básicamente lo que cambia es como como mapeamos y como enviamos esa información básicamente acá tenemos un type function y en responses y si le damos directamente type el nombre la función y los parámetros básicamente un como que una anidación menos entonces eso es parte de los cambios sin embargo lo importante de esta nueva api no tanto son estos ajustes estos son como breaking chains cosas que tendrías que cambiar si quieres utilizar el nuevo response api pero cuáles son las ventajas pues vimos primero que ya podría guardar el stores de la conversación por ti es un poquito más simple más sencillo como que la api no tiene tanto anidamiento o literalmente obtener la respuesta es un poquito más fácil entonces puede que haga más fácil utilizar pues este tipo de apis pero lo más importante para mí es estas nuevas herramientas las tours esto es un acercamiento a openai a ya manejar esto un poco más al al modo de agentes en el cual una gente puede tener cierto contexto cierto historial y ejecutar tools y ejecutar tools yo creo que a medida del tiempo openai va a sacar más tools aparte de estas aparte del web search aparte de que uno ya le puede poner cualquier o sea con function calling uno podría poner muchas tools las que uno quiera pero estas son nativas de openai o sea el web search lo hacen ellos el file search lo hacen ellos entonces creo que este es el mayor habilidad de esta nueva response api claro podemos seguir utilizando lo mismo que utilizábamos antes pero probablemente esta lista de acá va a empezar a crecer un poco más rápido y eso es lo que nos va a ayudar a que la gente se sienta más a la hora de hacer un nuevo search entonces es bueno empezar de pronto de cambiar y utilizando el response api porque luego vamos a poder utilizar tools y con esto sabes como los cambios que tiene chat completista versus respuesta y que es esta nueva propuesta de nuevo sigue siendo como las mismas características pero ahora con una y mucho más digamos simple y una oportunidad a utilizar tools y precisamente tools vamos a hablar voy a grabar un video de mi canal así que suscríbete y si quieres puedes seguirte viendo todos los videos que tengo aquí en el canal danos un like si te ha gustado el video y nos vemos en el próximo video nos vemos en el próximo video chau directamente a ese video en donde ya analizamos estas nuevas tools utilizando response API. Así que suscríbete.