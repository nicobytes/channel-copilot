En este video comparto cómo, al trabajar con agentes de inteligencia artificial, me di cuenta de que más allá del framework que use –ya sea LangGraph, Cloudflare Agents, Vercel AI SDK, Microsoft Agent Framework, Trigger, Mastra, etc.– siempre reaparecen los mismos patrones de arquitectura. Por eso decidí centrarme menos en “qué herramienta usar” y más en “qué patrones entender”, apoyándome en el famoso blogpost de Anthropic sobre cómo construir agentes efectivos. La idea es que, si comprendo estos patrones, podré reconocerlos e implementarlos en cualquier stack, incluso con código “vainilla”, aunque personalmente recomiendo usar frameworks porque facilitan muchísimo la orquestación y el manejo de la complejidad.

Primero parto de lo básico: un Large Language Model como un “nodo” que recibe un input y produce un output. A ese nodo se le pueden ir añadiendo recursos como retrieval (RAG) para ampliar contexto, herramientas (tools) para interactuar con sistemas, conexiones vía MCP, memoria para manejar historial, etc. Eso ya nos permite hacer cosas poderosas con un solo modelo. Sin embargo, cuando hablo de agentes y workflows, empiezo a pensar en varios nodos colaborando entre sí, cada uno con su propio system prompt, su propio modelo (incluso multimodelo: uno open source para extraer datos, otro más potente como GPT-4 para conversar, etc.) y conectados mediante patrones que se repiten una y otra vez.

El primer patrón que explico es el de chaining. Es el más sencillo: la salida de un nodo se convierte en la entrada del siguiente, como una cadena. Muestro un ejemplo con LangGraph donde tengo un nodo extractor que toma una conversación, le saca información estructurada (por ejemplo, nombre y correo del usuario) y luego pasa esos datos a un nodo de conversación que ya responde al usuario aprovechando lo extraído. Esto permite dividir una tarea compleja en pasos: primero extraer, luego conversar, o primero generar un texto y después, en otro nodo, generar una imagen que lo acompañe. También señalo que, con los modelos más recientes que ya tienen fuerte capacidad de razonamiento (Chain-of-Thought integrado, como Gemini 3 Thinking, etc.), a veces basta un buen prompt con pasos bien diseñados en lugar de construir toda una cadena de nodos. Pero cuando la tarea se vuelve muy compleja o el prompt se hace inmanejable, dividir en varios LLM calls encadenados suele ser más robusto y controlable.

Luego paso al patrón de routing. Aquí el foco ya no es encadenar, sino derivar. Me gusta ilustrarlo con un caso de soporte al cliente: tengo varios agentes especializados (por ejemplo, uno que hace reservas/booking y otro que responde preguntas frecuentes basadas en manuales y PDFs). Un nodo “router” –que también es un LLM con su propio prompt– lee el contexto de la conversación y decide a qué agente derivar la petición. Ese nodo no responde al usuario; solo decide el destino. En la demo muestro cómo, si el usuario dice “hola, ¿cómo estás?”, el router manda la conversación al agente de conversación general, pero si el usuario pide “quiero una cita para mañana”, entonces dirige el flujo al agente de booking que sigue con preguntas específicas (nombre, hora, doctor, etc.). Así es como este patrón se vuelve básico para construir centros de soporte inteligentes con múltiples competencias internas.

El siguiente patrón es el de paralelización. A diferencia del chaining (donde un nodo espera al anterior) o del routing (donde se elige uno u otro agente), aquí quiero ejecutar varios agentes al mismo tiempo y luego unir sus resultados. Lo ejemplifico con un agente de code review: en vez de pedirle a un solo modelo que evalúe seguridad, mantenibilidad y performance en un único prompt gigante, puedo tener tres nodos especializados, cada uno con su propio prompt y posiblemente su propio modelo optimizado para esa tarea. Los ejecuto en paralelo sobre el mismo bloque de código y luego un nodo aggregator recoge todas las respuestas y genera un informe unificado para el usuario. Es un patrón muy potente cuando necesitas varias perspectivas simultáneas (pueden ser dos, cinco o más agentes). La desventaja es el costo: cada nodo es una llamada al modelo con sus propios tokens, y además el aggregator también consume tokens, así que hay que balancear precisión y presupuesto.

A partir de ahí introduzco uno de los patrones más sofisticados: el orchestrator. Me gusta describirlo como un “project manager” de agentes. A diferencia del router, que escoge uno, y de la paralelización, que lanza varios fijos, el orchestrator decide dinámicamente qué agentes utilizar según la tarea. Conoce las capacidades de cada agente (mediante su system prompt y una especie de catálogo de habilidades) y, para cada input, analiza qué combinación de agentes tiene sentido. Puede seleccionar uno solo, dos, tres… y, de los que elige, los ejecuta en paralelo. Después, de nuevo, hay un aggregator que consolida la respuesta final. Muestro una demo en la que el orchestrator, según el mensaje que envío, va tomando decisiones distintas: en una ocasión invoca al nodo 2 y 3, en otra al 1 y 2, y a veces solo uno. Este patrón me recuerda al paper “HuggingGPT” de Microsoft (2023), donde ya se hablaba de tener un planner que analiza la tarea, selecciona los modelos adecuados, ejecuta y luego genera una respuesta final. Ese artículo, aunque ya es “viejo” en tiempo de IA, ilustra muy bien el espíritu del orchestrator actual.

Después entro en el patrón de evaluator/optimizer. Aquí lo interesante es poner a un modelo a juzgar la salida de otro (o incluso su propia salida), según unas reglas definidas en un system prompt. La arquitectura básica es: un nodo generador produce una respuesta; luego un nodo evaluator la evalúa frente a criterios que yo definí (puede ser un simple True/False o una calificación estructurada). Si no cumple los requisitos, el evaluator devuelve feedback concreto al generador y se repite el ciclo. Este loop es clave en muchos agentes modernos, porque convierte el sistema en algo iterativo: no se queda con la primera respuesta mediocre, sino que la refina hasta que satisface las condiciones. En la demo uso un generador de chistes: el evaluator tiene reglas como “debe tener más de dos párrafos” y “debe ser divertido” (algo subjetivo, pero que puedo guiar con ejemplos, few-shot, etc.). El primer chiste que genera el modelo es muy corto; el evaluator lo rechaza y le devuelve feedback (“es muy corto, extiende la historia…”). El generador produce una nueva versión más larga y finalmente pasa la evaluación. También advierto que hay que ponerle límites al número de iteraciones para evitar loops infinitos y gastos innecesarios.

Con estos patrones sobre la mesa –chaining, routing, paralelización, orchestrator y evaluator– enseño cómo se pueden combinar para construir arquitecturas mucho más ricas. En LangGraph muestro un ejemplo complejo de un agente que genera contenido para redes: hay nodos que redactan el post, loops con evaluators que condensan o mejoran el texto, agentes que buscan y rankean imágenes, pasos de “human in the loop” para validación manual, reescrituras, etc. Además, cada “nodo” visible en el grafo puede a su vez encapsular un subgrafo interno con su propio patrón. Por ejemplo, un agente que desde fuera parece un simple nodo puede internamente ser un loop evaluator tipo React o un pequeño workflow de chaining. De esta forma, las arquitecturas escalan por capas: patrones dentro de patrones.

Hacia el final conecto estos patrones con una arquitectura muy popular en la industria: React (Reasoning + Acting). React no necesariamente divide la lógica en múltiples agentes explícitos, sino que aprovecha las capacidades del LLM para razonar y decidir qué herramienta (tool) llamar en cada paso. Funciona en bucle: el modelo analiza el contexto y la tarea, decide qué acción tomar (por ejemplo, llamar una API, hacer una búsqueda, leer de una base de datos), ejecuta, observa el resultado, vuelve a razonar y así, iterativamente, hasta resolver el problema o pedir más información al usuario. Este ciclo mezcla razonamiento y acción de forma estrecha y, en muchos casos, es suficiente como arquitectura principal sin necesidad de construir un grafo enorme lleno de nodos.

Cierro el video con una reflexión importante: al igual que en la ingeniería de software tradicional, aquí también podemos caer en la sobreingeniería. No siempre hace falta un grafo complejo con orchestrators, evaluators, routers y paralelización. A veces un solo modelo bien “prompteado”, con algunas tools y quizá un pequeño loop, resuelve el caso de uso de forma simple, barata y mantenible. La clave es iterar, probar, medir y decidir si tu caso realmente necesita una arquitectura compleja o si con un patrón más sencillo como chaining o React es suficiente. Mi objetivo con este contenido es darte el mapa mental de estos patrones, para que puedas reconocerlos en cualquier framework, elegir los que mejor encajen en tu problema y, sobre todo, no perderte entre modas y herramientas, sino diseñar agentes efectivos y llevables a producción con criterio propio.