 Te voy a mostrar cómo yo estoy utilizando varias tecnologías de inteligencia artificial para generar contenido de forma automática. Esto lo utilizo, por ejemplo, para ciertos posts en LinkedIn, Twitter, etc. Y no, no te sientas defraudado, es decir, yo soy autor de esos LinkedIn, de esos tweets, pero sí me apoyo en varias herramientas de automatización basadas en IA. Y todo eso fue inspirado precisamente en una herramienta, o más que herramienta, un concepto, una prueba que hizo Microsoft en un repositorio en donde ellos hicieron algo similar. Te lo voy a mostrar, te voy a mostrar mi versión, cómo funciona, y espero tus comentarios al respecto. Este es, este es el repositorio. En Microsoft lo puedes encontrar como Microsoft Podcast Pilot, precisamente porque ellos crearon una idea, una prueba de concepto de cómo podían generar contenido automático basado en los podcasts que ellos grababan. Y esto lo presentaron en el MS Build del 2023. Ni siquiera el de este año, el del 2024, que de por sí fue hace poco, sino fue el de hace dos años. Y es una prueba de concepto que desde que yo lo vi me pareció interesante y he estado trabajando con una versión propia, que es la que te voy a mostrar hoy. Tampoco es que está determinada, pero pues la estoy poniendo aquí a público y ponerla en conversación cómo es que estas herramientas de IA nos pueden ayudar para generar contenido. Entonces, ¿cuál era el caso de ellos? El caso de ellos es que ellos grababan una entrevista con una persona. Entonces, esa entrevista, el audio lo pasan por Whisper, ¿no? Esos son como los pasos que ellos tienen. Hay unos pasos que corren en local, otros que corren en la nube, pero por ejemplo, ya tengo un video en mi canal acerca de cómo obtener el transcript con Python, porque todo esto está en Python y mi repositorio también está en Python. Pero básicamente aquí hay un modelo que te dice, ¿cómo generar la transcripción de lo que se dijo? Entonces yo le paso un audio y me pasa la transcripción. Es un modelo sencillo. Whisper lo puedes encontrar en mi canal de cómo utilizarlo. Entonces, una vez tienen como la entrevista, pues básicamente entonces obtienen el transcript. Luego tienen Dolly, que es un language model chiquitito, como no tan potente como GPT-4 de OpenAI o Gemini de Google, pero pues es un modelo que sirve para, basado en la transcripción, como obtener el nombre del invitado, como quién es el invitado que estuvo hablando en ese podcast. Normalmente porque en el podcast hacen una introducción, como hoy estoy aquí con tal persona y vamos a hablar, a hacer, acerca de tal cosa. Entonces ese Dolly, que es un language model chiquitito, pues te ayuda en eso. Aquí podrías utilizar GPT-4 también y ya no hay tanto problema. Luego buscan utilizando ya la nube y el buscador de Microsoft, que es Bing, buscan como información relevante de esa persona, como extraer como su biografía, bla, bla. Luego utilizando GPT-4 y como una y utilizando Azure, básicamente generan como una de esas, como una de esas, como una descripción, como una, una con base en la transcripción, pues generan como un resumen y también con base a ese resumen, pues genera una imagen utilizando Dalí y luego literalmente con un plugin de LinkedIn lo pasan y generan ese post en LinkedIn. Entonces me pareció bastante interesante esa prueba de concepto. Te voy a mostrar cuál es mi versión de por si vamos a entrar a mi GitHub y así como ellos le llamaron Podcast Copilot, yo le llamé como Channel Copilot porque lo utilizo como para las cosas de mi canal de YouTube, Channel Copilot y fíjate que está privado. Lo voy a poner público en este momento, lo voy a poner público para ti, para para que reciba tus comentarios en este video acerca de cómo ves esta prueba de concepto. Voy a cambiar la visibilidad y ahora es un repositorio público. Literalmente tú también lo puedes clonar. Y ahora me pide mi autenticación de seguridad de GitHub, que es interesante. Vamos a hacerlo rápido por el poder de la edición. Listo, ya literalmente ya ahora sí quedó como público. Channel Copilot, un repo que estaba trabajando de forma privada, pues está ahora público. Listo. Qué es este repositorio? Básicamente le coloco descripción, le coloco un buen rime, aunque por aquí hay un buen, un, un, un, como cosas que yo tenía anotadas. Entonces, siguiendo como ese mismo paso que utiliza Podcast Copilot, básicamente lo que yo hago es grabar mi contenido, mi siguiente video de YouTube. Y lo que hago es el primer paso es pasar este video hacia la transcripción, también utilizando Whisper. Y aquí ya hay una como una conversación que siempre hay en Internet. Por si voy a pasar a la cámara principal y esa conversación es es es bueno empezar a generar contenido simplemente pidiéndoselo a una ella y sobre todo porque entonces el contenido ya no tiene como mi mi autenticidad, como mi forma de ver las cosas, sino que ya es la forma entrenada de una. Y ahí no como pedirle a una y dime algo, un tweet o un post en LinkedIn acerca de Angular y los y unites y no y pues él lo crea y yo lo publico y ya estoy generando contenido basado en ella aquí hay algo que me gusta de este concepto y es que al final lo que yo hablo en un video literalmente son mis pensamientos, mi forma de pensar, mi forma de expresar las cosas, es mi forma de dar a entender ciertos conceptos. Ese soy yo entonces o relativamente en ese pedazo de video o al menos lo que se hace hacia YouTube, pero eso soy yo hablando y expresando cierto tipo de conocimiento. Entonces, cuando yo paso ese video, lo transformo, pues saco el video, saco el audio primero, por si saco el audio y después del audio saco el transcript con Whisper, ahí como que ya hay cierto tono, cierta forma. Y ya con utilizando Promo Engineering, pues le digo mira, con base a pues lo que hablé aquí, generarme un LinkedIn, un post en LinkedIn, un post en Twitter acerca de lo que yo dije y cómo lo dije y respetando un poco como la forma en la que yo me expreso. Hay varias cosas de por si que a veces no me gustan y no es que yo copie y pegue, sino que literalmente lo genero y luego lo leo y digo yo no hablaría así. Yo no hablo así, no es mi forma de comunicarme y corrijo ciertas cosas. Ahorita hago ciertas correcciones manuales, no hago nada automatizado, como que hago la toda la corrección manual, porque a veces sí, como que no me gusta en el tono en el que queda generado ese tweet, ese post, lo que sea, esa descripción, lo que sea y lo corrijo. Pero probablemente con nuevos modelos, con modelos más potentes que están saliendo o con simplemente mejorar el prompt, pues podría casi decir listo, así es como más o menos yo me expreso. Entonces hable y genere un post en LinkedIn, en Twitter, un hilo para cierta plataforma de red social. Entonces vamos, te voy a explicar un poco cuál es el paso a paso y cómo funciona el repositorio. Lo primero acerca de este repositorio es que todo funciona. Funciona como con como si fuera una herramienta de línea de comando. O sea, no tengo ninguna interfaz gráfica todavía. Si lo tengo en planes, pero como es algo muy personal, todavía no le he puesto una interfaz gráfica. Entonces simplemente se ejecuta como una herramienta de línea de comandos. Y como está hecha en Python, hay una herramienta creada por el mismo creador de FAS API, que es Sebastián Ramírez, de Angular, que es Typer, que es una forma de cómo crear herramientas basada en Python en Python. Entonces, yo tengo un repositorio que es un repositorio de Python, que es un repositorio de Python, que es un repositorio de Python, un repositorio de Python, un repositorio de Python. Y en Python, como que yo hago una herramienta de línea de comandos. Entonces básicamente, como que yo corro y ejecuta cosas, y hay una forma bastante bonita como de hacerlo, de recibir comandos, etcétera. Eso es casi la base del repositorio. Por eso, por ejemplo, todo se genera como en base a un audio, digo, a un comando. No vamos a ver mucha interfaz gráfica. Pero vamos a ver este. Vamos a ver cuál es el primer paso. Generar el audio. Ok, entonces normalmente yo utilizo acá como input utilizo un video. Entonces esto es un video. Esto es un video que grabé, no sé, para un video de Cloudflare, para un video de los que hago en mi canal y son bastante pesados. Normalmente yo los exporto en una calidad bastante grande para que YouTube tenga una buena calidad. En fin, aquí creo que ni siquiera se va a reproducir porque son 10 gigas lo que pesa este video. Entonces este, en la carpeta input, lo voy a hacer un poquito más de zoom, no está de por si está ignorada dentro del repositorio. Normalmente yo cada vez que genero un contenido, jalo esa carpeta ahí. No sé por qué no está cargando el gitignore, pero bueno. Jalo el video con el cual quiero generar como contenido y simplemente lo pongo ahí como en esa parte. De por si acá está, está ignorado el input. Todo lo que yo ponga en input lo ignoro porque sería bastante pesado para el repositorio. Entonces subo el video, el último video que haya puesto. ¿Cómo genero la transcripción? Ese es el primer paso, generar la transcripción. De por si para generar la transcripción necesito el audio. Entonces lo que hago es pasar el video a audio. ¿Cómo hago eso? Literalmente aquí en el archivo main.py hay un comando que eso es lo bonito de Typer, como que te deja exponer comandos a través de funciones. Entonces si yo le pongo Python y el archivo main.py, que es donde están declarados todos los comandos, todos los comandos están declarados aquí, pues simplemente va a buscar el comando o la función audio que está como un comando. Y acá literalmente le digo mira, el video está en este, en este pad. Genera el audio y esto es una función de Python. O sea, no es nada más. Es una función de Python. Utilizo, por ejemplo, aquí la librería de un movie.py en el cual le digo mira y esto de por si creo que hasta me lo generó GPT o sea o GFACO pilot, como oye necesito una función para convertir un video en audio, o sea, solo necesito el audio, no necesito video, necesito solo el audio de ese video. Entonces aquí utiliza esto y literalmente me arroja. Yo le digo que escribo un archivo en .wap en donde ya queda todo el audio. Básicamente lo primero es transformar ese video en audio y en audio. Pues que obviamente queda más chiquito, ya queda no de una giga, queda de 428 megabytes, queda mucho más chiquito y acá está el audio de ese video. En este video. Literalmente ese es el audio del video. Listo. Una vez tengo el audio del video, me voy y corro el segundo paso. Y aquí tengo una mala arquitectura de carpetas. No me critiquen. Esto es un demo y es una prueba de concepto. Lo interesante es cómo, cómo se puede hacer esto con IA. Luego ya mira, uno ya mira cómo crear buena arquitectura para este prototipo. Pero aquí literalmente le digo bueno, con base a ese audio transcriba y déjeme la transcripción en esta, como en este folder en específico. Y recordemos que acá la tarea es transcript. Entonces busquemos aquí el comando transcript. Ahí está. Básicamente yo tengo un pad fijo. Yo ya espero que yo ya haya corrido el comando anterior, que es el de el audio. Entonces yo espero decir a mira, el audio está ahí, está en este archivo. Ahora, genérame la transcripción. Tengo una función para generar la transcripción y utilizo Whisper. Si quieres ver un poco más acerca de Whisper, literalmente hice un video completo de cómo utilizar Whisper. Entonces aquí básicamente hago la transcripción. Y es más, podemos correr. Es más, voy a correr el comando, voy a correr el primer comando ya que tengo ese archivo ahí. O sea, el audio es lo que va a hacer es reescribirlo. Pero entonces si lo corro, pues literalmente va a tomar el video y va a pasarlo a audio. Eso es lo primero que hace. No sé si de pronto ahorita vaya a molestar porque ya hay un archivo. Creo que no. Ahí está haciendo, pasando de audio a video. Ese es el primer paso, el que te dije que hacíamos con la librería. Es una librería de Python normal que es MoviePy. Listo. Entonces ahí se me va a generar y me deja ese archivo en donde yo le haya indicado que es input slash audio y ahí lo dejo. Mira, ahí está. Entonces mi siguiente paso, ¿cuál es? Pues es generar el transcript. El comando del transcript es este y yo le digo mira, aquí algo bueno de Typer es que de nuevo me permite, creo que ya cerré la documentación de Typer, pero volvamos a abrir. Me permite como recibir comandos para luego yo hacer cosas con él, no como recibir cositas como atributos del comando. Entonces aquí yo le estoy enviando el path como si fuera un atributo. Entonces este este pat es el que me llega acá. Entonces acá le digo mira, corre con base a este audio. Pues a generarme la transcripción. El corre el modelo de Whisper para generar la transcripción y déjamelo en el path que yo te dije punto transcript. Voy a hacer un demo aquí, por ejemplo, hago demo y voy a crear una carpeta que se llama data. Aquí es las transcripciones que yo he hecho para diferentes videos, para cosas que yo he hecho, pero pues vamos a poner uno que se diga demo. De por sí le puse una carpeta que no. Fíjense que todavía sigue siendo manual varias cosas, pero pues es la idea. Es un prototipo que vamos a empezar a mejorar, de pronto automatizar, de pronto ponerlo en ya en una API y generar producto. No sé. Este producto es muy interesante. Te voy a mostrar uno que igual también es bastante interesante, que ya como que hace esto, pero pues simplemente con una interfaz en pero listo. Entonces yo le digo que basado en ese comando, por favor vaya a punto data y el transcript me lo deje en la carpeta demo y me lo deja con el nombre de transcript. TXT. Entonces si yo corro esto, pues básicamente lo que va a hacer ahí es correr el modelo de Whisper para con base a ese audio. Todo lo que se diga es de ese audio me va a generar el transcript. Entonces aquí ya hace un proceso. Por ejemplo, acá yo estoy utilizando Whisper la versión creo que el modelo base. Fíjate que ni siquiera estoy utilizando. Creo que estoy utilizando el arch. Sí, aquí le estoy utilizando el parámetro. Fíjate que aquí primero le envío en dónde está el audio y luego cuál modelo quiero utilizar de Whisper, que si no le envío nada coge base, pero como si le estoy enviando el parámetro que es este large, pues entonces pues va y le pasa el tipo que el tipo lo está recibiendo acá. Y pues en fin, básicamente estoy utilizando el modelo large para hacer una traducción de alta calidad y fíjate que acá empieza a ser la transcripción. De por sí debería, creo que hacer un ejemplo de un video más cortito, porque este audio, este audio, el que estamos analizando ahorita son 42 minutos. Si no estoy mal. Y pues es un es casi una hora de audio. Entonces obviamente el transcript se va a demorar. A ver si tengo uno. Creo que no tengo uno chiquito, pero son 42. Vamos a ver cuánto se demora haciendo esta transcripción. Pero fíjate que lo que está haciendo ahí es literalmente pasar ese audio. Y este es el proceso más largo. Este es el de por si lo que más demora es esto, hacer la transcripción. Luego generar resumen, generar un texto a partir de esta transcripción va a ser relativamente fácil porque utilizamos un modelo como GPT 4 y ya y el genera y es bastante rápido. Pero también te vamos a una herramienta muy interesante que utilizo para generar eso y aquí ya te hago un spoiler alert si no has visto Lansmith, un servicio creado por Lanshain para poder administrar prompts. Y esto es una de las cosas que tal vez me ha gustado y que he podido experimentar. De por sí creo que luego voy a hacer un video solo. Aparte de Lansmith, pero ahorita te voy a contar rápido como yo lo estoy utilizando. Pero pues nada, esperemos que esto termine porque ya lo puse a ejecutar y creo que no tengo un video un poquito cortito para probar y quiero hacer algo como con un caso real. Entonces con la magia de la edición vamos a esperar y tú ya simplemente vas a ver esto ya cuando acabe y yo voy a tomar un vaso de agua mientras esto acaba. Nos vemos ahorita. Y fíjate que listo, que ya terminó, demoró literalmente 10 minutos, 10 minutos en hacer esta transcripción y ya debió entonces dejar el archivo. Vamos a ver el archivo. Ahí está demo punto transcript. Aquí está todo lo que dije en el tono que dije, cómo lo dije, cómo me quería expresar, lo que expliqué, etcétera. Literalmente este es el transcript de ese video. Ok, vamos a ir al segundo paso, no al tercero. Entonces ahora de nuevo le digo que en esa carpetita, que es la de demo, le voy a poner el archivo de la versión que yo quiero hacer. Y aquí es donde entonces vamos a ver el comando del resumen, porque la transcripción es muy grande, es un contexto muy grande, aunque realmente modelos actuales como GPT-4 o Gmini Pro soportan modelos gigantes. O sea que ahorita el transcript no debería ser así sea tan grande. No debería ser un problema de contexto. Sin embargo, también es bueno como que resume todo eso, como condensa algo, como un título y demás, pero como condensarlo para luego generar un tweet. O ese es mi proceso al menos o mi fórmula de alguna manera para hacerlo. Y aquí es donde entonces va algo interesante. Entonces le digo mira, ok, aquí en Summary le digo mira, con base al transcript que ya es un archivo de texto, ya es texto literal, lo leo y le digo que por favor genere un resumen y lo deje en Summary.txt. Ahora eso lo llamo con un chain. Y acá estoy utilizando LanChain y fíjate en esta en esta línea tan chiquita. Bueno, en 11 líneas, porque acá estoy utilizando un servicio que se llama LanChain Lan, Lan, Lan Smith. Ahorita sí, este es Lan Smith precisamente. Entonces acá tengo LanChain, que es lo que me permite precisamente como interactuar con modelos LanChain, si no lo conocen. Bueno, yo creo que si lo conocen es uno de los frameworks más famosos para poder interactuar o manipular LanWord, las LanWord Models, manipular a cada una de las cosas que me parece muy interesante es que yo puedo decirle mira, quiero que utilizar GPT-4 Turbo o quiero utilizar Gemini, o quiero utilizar Cloud. Entonces tú como que es un framework agnóstico y tú dices mira, solo quiero interactuar con este tipo de modelo y ya. Listo, entonces en este caso lo voy a dejar con GPT-4. Obviamente tienes que tener un, un key de OpenAI en tu Cloud para que, pues para que puedas poder acceder a GPT-4. Es un modelo de paga al final. Yo tengo ahí mi clave, entonces él simplemente la va a obtener y generarlo. Pero en dónde está el prompt? En dónde, en dónde está ese prompt que yo le digo oye, con base a la transcripción, entonces bla, bla, bla, bla, bla, bla. Dónde está ese prompt? Hay algo muy interesante y es el servicio precisamente que te comentaba de Lan Smith. No sé si conoces el concepto, pero es un servicio de un CMS o una base de datos. Y aquí quiero hablarte directamente a ti. Precisamente una base de datos es como un repositorio de datos o un CMS, un Content Management System. Normalmente es utilizado mucho para blogs y demás. Lan Smith se convierte como en ese administrador de prompts para no tener como el prompt quemado directamente en el código, que se puede. Pero qué pasa si luego yo quiero iterar el prompt un poquito, cambiarle cierta cosita, tengo que entrar al código, hacer un release en mi aplicación, compilar, pasar pruebas unitarias, todo el proceso de despliegue para hacer un cambio simple en el prompt. Ahora, Lan Smith se convierte como en esa base de datos de prompts. Literalmente en esos prompts que tú le colocas un ID se puede hacer por organización. Es decir, si tú estás desarrollando chatbots o tu propio chatbot empresarial, sería bueno que crees una organización y ahí entonces cualquier persona de la organización puede iterar ese prompt, puede decir puedo mejorar aquí, puedo mejorar allá, lo despliego. Y literalmente yo lo consumo como si fuera a llamar este prompt desde mi aplicación. De por sí, aquí te voy a mostrar la llamada. Aquí está la llamada. Este es de Lanchen Import Hub. Ese hub es el Lan Smith y normalmente hay un barra. Aquí me equivoqué en mi nombre de usuario. Debería ser Nico Bytes, pero no lo he podido corregir. Quedó como Nico Buttes. Pero literalmente tú pones el nombre de tu organización, que puede ser privada o lo que sea, y pones como el ID, como si esto es como la forma de reconocer tu prompt. En este caso yo le puse Nico Bytes Summary Transcription. Él va a encontrar ese prompt y luego lo va a inyectar y ya. Y luego pues ya tengo acá, tengo ya el transcript que lo paso como una variable. Básicamente se lo paso como un input. Acá está. De por sí, si tú miras acá le paso. Cuando yo tengo ese chain lo invoco y le paso ese transcript. Ese transcript está definido aquí para que llegue como variable. Luego el prompt que viene de ese hub o de ese administrador de prompts. Luego le digo con qué modelo va a operar este prompt. En este caso lo va a hacer con GPT-4 y luego un output parser, que es una manera de todo eso que hizo pasarlo a un string plano. Listo. Vamos a mirar un poquito cuál es el prompt de ese Summary Transcription. Entonces aquí me voy a loguear con GitHub porque si no estoy mal, creo que estoy logueado con GitHub. Vamos a ver por acá. Y aquí tengo el user literalmente. Aquí precisamente debería ver si ya puedo cambiar mi nickname, pero todavía no sé si lo puedo cambiar y que ya no diga Nico Bootes, sino Nico Bites. Pero bueno, entonces aquí, aquí en el hub, creo que por acá está el hub. Dónde está el hub? Esto lo han venido cambiando. Acá está prompts. Ahora ya no se llama, no se llama hub, sino lo llaman prompts. O al menos desde la interfaz. Entonces fíjate que acá tengo el prompt de Summary Transcription y aquí es donde uno administra el prompt. Entonces aquí se vuelve muy interesante porque acá es donde yo puedo hacer pruebas, donde puedo mirar si puedo iterar el prompt, cambiar alguna cosita. También el prompt puede recibir parámetros. Por ejemplo, aquí recibe el transcript, literalmente recibe el transcript. Y aquí me dicen cómo yo puedo llamarlo ya desde mi código en JavaScript o en mi código, en este caso en Python. Lo puedo probar. Por ejemplo, puedo editar en un Playground y le puedo decir mira, acá literalmente está el prompt. Tú eres un asistente que puede escribir un suma, un resumen en parágrafos, en párrafos, dado una transcripción de un video. El resumen debería ser usado para crear contenido online en redes sociales. El resumen debería ser escrito en primera persona. Como si yo lo hubiera escrito. Sí, en primera persona. Y luego acá está el prompt del humano diciéndole por favor lo haga en español. Y acá le paso el contexto del transcript. Y aquí lo interesante es que literalmente yo le puedo poner aquí, pues como probar un transcript, literalmente en teoría debería poder copiar aquí el transcript. Por ejemplo, este todo este vamos a ver si me soporta ese número. Acá, ahí está. Lo copié. Acá literalmente también puedo probar un modelo. Voy a probar con GPT-4, por ejemplo. Le puedo mirar la temperatura, que si se vuelve más creativo o no. En fin, lo voy a dejar en uno y puedo probar. O sea, puedo. Esto es lo bueno de la. Y creo que ya estoy haciendo el video de Lansmeet, pero creo que literalmente si voy a hacer un video aparte, aquí te voy a hacer una explicación sencilla. Pero aquí puedo como iterar. Entonces tu equipo podría ver. Fíjate que acá me dice que el modelo sólo soporta un contexto. Fíjate que hay problemas de contexto. Dice que entonces por eso creo que está utilizando GPT-4 Turbo, que tiene un contexto más grande. Vamos a ver si este modelo GPT-4 Turbo. Fíjate que él sí soporta un modelo, pues como un contexto más grande. Y acá literalmente está la respuesta. Entonces, ¿qué es lo que me permite Lansmeet? Que aquí yo tengo un laboratorio para poder iterar, para poder evaluar prompts, para decir bueno, ¿qué pasa si le cambio aquí? Le cambio acá, le cambio acá. Lo pruebo con diferentes modelos. Mira que acá hay Azure, bla, bla. Hay Chat Vertex, hay un modelo de Homing Face. Bueno, como que puedo cambiar y ver cómo operarlo, etcétera. Entonces aquí se vuelve y si tú lo utilizas para una compañía, se vuelve un administrador. De pronto. Y listo. Entonces aquí como que alguien lo administra, lo itera, lo mejora y simplemente tú en tu código como desarrollador, simplemente lo jalas de esta manera. Mira lo que hay allá, lo que es la última versión, porque esto también se versiona. Es más, por aquí tengo como el historial. Uno normalmente puede ver como el historial de cómo lo ha... Aunque este es el historial de Rund. Creo que había un historial, déjame ver si hay un historial de versiones. Así es. Como commits, ¿no. Por ejemplo este. Literalmente este prom lo tengo hace cinco años y otros que se ha iterado mucho más a este De summary y no lo he iterado mucho. Literalmente se quedó en esta fecha. Probablemente debo mejorar este prom para mejorar la calidad del summary. Pero algo muy tan positivo de esto es que es público. Ahí pueden, pueden haber proms privados para tu compañía, para tú. No quieres que todo el mundo vea. O puede ser público que quiere decir eso, que ves que yo tengo aquí un usuario, yo podría buscar en como prompts que hayan sido construidos por pues por alguien más vamos a ver si esto si ya me deja y acá acá está el lanche de hub y yo a ver si hay un prompt para summaries para hacer un summary entonces lo busco lo voy a buscar y fíjate que todos estos usuarios tienen prompts para hacer summary de por si esta técnica de refine chain density o esta técnica de la densidad del prompt es una técnica para hacer mejores summaries entonces podría probar este prompt y lo bueno es que entonces yo puedo probar este prompt y decir mira yo quiero probar el prompt del usuario tal entonces me lo traigo entonces ya no voy a hacer el prompt con mi versión de prompt sino con el de este usuario esos serían los prompts que son públicos y ya ahí lo utilizo obviamente hay que tener en cuenta si este prompt recibe por ejemplo acá recibe varias literalmente recibe muchos atributos fíjate que hay un montón de atributos que recibe muchas atributos que recibe en todos esos recibe es más si yo lo corro y déjame ver si me deja correrlo no creo que no me deja correrlo que raro que no me deje evaluarlo pero todas estas variables que están como por escritas como por acá acá son variables que yo le tengo que enviar como el máximo de palabras la categoría del contenido las iteraciones para que mejore el proceso acá el máximo de relationships o sea como que uno depende obviamente de la categoría del contenido de la categoría del contenido de la categoría del contenido a la cantidad de cosas que reciba de prompts pues yo entonces debería empezar a enviarle esto en mi versión sólo recibió de un argumento que es el de transcript entonces voy a proponer mis prompts el de summary y fíjate que yo sólo recibo una transcript sólo le envío una también debes tener en cuenta si quieres jalar uno de esos públicos que variables debes enviarle si quieres construir los tuyos pues empezar a ver cuál otro y esto es muy interesante realmente causa mucha interés como uno puede también tener un administrador de prompts y puede iterar, dárselo a una persona que no tiene que entrar el código para editar el prompt, lo puede iterar, subir una versión y en mi código ya se consume y no tengo que hacer ningún cambio si yo lanzara un nuevo release. Por ejemplo, si yo quisiera ahorita cambiar y decir, no me lo genere en español, genéremelo que el language sea un atributo. Entonces, escríbalo en, y acá le digo language. Y ahora language debería, yo ya se lo puedo enviar. Y en código, entonces yo debería enviarle en qué idioma quiero que me genere el summary. Y el summary ahora es parte del prompt. El lenguaje es parte del prompt. Entonces ahora yo debería enviárselo. De por sí ya tengo otros que envían como el idioma por acá, entonces voy a copiármelo. Ya que estoy iterando en ese momento este prompt, y acá sería una muestra de cómo estoy iterando ese prompt. Vamos a ponerlo acá. Vamos a ponerlo acá. Vamos a ver aquí. No, este no es. Déjame ver. Me voy a basar en este de LinkedIn. Sí, es como un diccionario. Y acá. Sí, lo voy a hacer como en ese formato. Entonces aquí. Aquí lo encierro en esto. Entonces voy a encerrarlo. Parampán, parampán, parampán. Listo. Entonces este lo voy a poner acá. Lo voy a poner acá. Quiero que me quede bien formateado. Nada más yo soy muy como especial en que esté el código ordenado para que sea fácil de lectura. Entonces ahí creo que ya es fácil de leer. Listo. Entonces aquí, ¿qué está pasando? Que yo le estoy enviando el transcript como una variable. Estoy creándole una nueva variable para que Spanish no sea su única forma, aunque normalmente yo genero contenido solo en español. Pero es interesante que yo pueda mandarle el idioma en que genere el summary como una variable más. Y luego simplemente la va a traer del prompt. Hasta podría decirle, bueno, si no me llegue nada, pues por defecto sea español, pero ya lo comando desde acá. Y el prompt es flexible. Entonces aquí ya sí me ha tocado hacer un commit para publicar una nueva versión de ese prompt. Entonces ahora sí tengo una nueva versión. Vamos a ver. Fíjate que aquí en los commits, ahora ya hay una nueva versión que fue hace pocos segundos. Esa nueva versión del prompt ahora es a la que yo le puedo enviar el idioma. Listo. Y voy a hacer una modificación aquí sencilla. Acá, por ejemplo, fíjate que yo le enviaba el transcript como diccionario. Entonces ahora lo voy a enviar así, también como diccionario. Solo que aquí déjame ver. Acá enviado como diccionario. Acá transcript. Ay, pero otra vez cometí el mismo error. De nuevo. Diccionario. Copio transcript. Y se lo manda. Listo. Entonces ahora, cuando yo lo invoque, necesito enviarle el transcript que lo lee del archivo que generó whisper. Y el lenguaje que aquí ya lo puedo cambiar en español, en inglés. Bueno, yo ya lo puedo como aquí cambiar. Es más, en algunos lados lo tengo también como una variable que se recibe como parte del comando. Pero listo. Ya he explicado eso. Ya he explicado el Lansmith y cómo funcionan los prompts. Pues acá, fíjate que tú puedes probar como con varios modelos. Pero aquí tú, literalmente yo le estoy diciendo que ya cuando lo esté ejecutando, necesito que sea GPT-4 Turbo. No 3 ni nada, sino aquí ya soy el que yo tomo la decisión. Aquí tú puedes probar como con varios tipos de modelos. Aquí. Pero luego que simplemente lo llamas, ya puedes aquí en códigos y decirle no, yo quiero no GPT-3, sino GPT-4 o cualquier otro modelo. Pero listo. Entonces corramos ahora ese comando. Entonces si yo le digo generame el summary. Entonces va a correr este comando que es summary, que le pasa el transcript, que le pasa el transcript como diccionario, el lenguaje, que esto llama al chain, que al final se conecta con Lansmith, que le manda esos parámetros a Lansmith, ejecuta ese prompt. Bueno, le manda estos parámetros a este prompt, lo ejecuta con el modelo GPT-4 y luego la respuesta. Y esa respuesta al final la dejo en un archivo dentro de la carpeta que se llama summary.txt. Veámoslo. Entonces ejecutámoslo. Y veamos a ver qué pasa. Entonces este debería demorarse un poquito menos. No deberíamos hacer tanto como la transcripción, que es tomar un audio de 40 y pasarlo a texto. Va y lo llama. Espero no tenga ningún error con el cambio que ahorita hice en el prompt. No debería. Creo que fue un cambio bastante chiquito. Entonces listo. Aquí está. Ahí está. El summary. Entonces ahora tengo un archivo que dice summarize. Y este es ya como el resumido de toda la chachara que hablé en ese video. Fíjate que aquí podría iterar más el prompt. Podría iterar y decir respeta mi tono, respeta. Hay uno de otros puntos que sí lo tengo un poco más literal. Respeta como la forma en que yo me expresé. Aquí podría iterar más el prompt de summary, pero pues solo es ir a Lansmith, iterar, jugar, un poquito con un prompt hasta que pues como que me dé algo que me guste. Listo. Entonces acá tengo el summary. ¿Qué pasa después del summary? ¿Qué hago después del summary? Y fíjense que así funciona literalmente la prueba de concepto del de Microsoft es así. Te dicen, mira ve, instálalo, corre este archivo, ejecuta esto. Como que no es producto, es una prueba de concepto. Luego obviamente uno puede crear producto con esto, ponerle una interfaz gráfica, hacerlo bonito, ¿no? Pero literalmente si ustedes ven, si tú ves el de ellas aquí, pues es código. De por sí yo lo tengo de por sí mucho más limpio en varios archivos. Ellos tienen todo aquí en una sola cosa. Pero me basé mucho en como su estilo y como lo hicieron y sobre todo en la idea, ¿no? Me parece una idea bastante interesante. Acá yo lo tengo un poquito más dividido con Typer y pues con archivos y con Lansmith, etc. Listo. Ya tengo el summary. Ahora, ¿qué hago? Normalmente yo utilizo, y si entras a mi canal de YouTube, crear en la descripción y eso o un video enganchante, digo, un título enganchante. Normalmente esto sirve o la IA sirve para romper la hoja, el papel en blanco, la hoja en blanco. Vamos a verlo. ¿A qué me refiero con esto de la hoja en blanco? Normalmente no deberíamos, o desde mi punto de vista, no deberíamos utilizar la IA para que simplemente me llene yo copiar y pegar, sino que me ayude un poco a ver la hoja en blanco. A mí, por ejemplo, tengo tiempo limitado de crear contenido, etc., de pensar en qué sería un título enganchante, aunque es labor del creador de contenido pensar en esas cosas, pero si ya tenemos IA podemos apoyarnos en eso, pero es apoyarnos, no es simplemente dejarle la tarea. Entonces yo ya con el summary le digo, tengo otro prompt diciéndole, mira, basada en el summary, que es el resumen de lo que dije en mi transcripción, crea un video, crea un título como enganchante y crea una descripción y créame los keywords, ¿no? Como en YouTube normalmente tienes que poner keywords para posicionar tu video, como las palabras clave, igual que una website que pones keywords, entonces yo le digo modelo que con base al summary, pues dígame qué keywords debería poner, qué descripción debería poner, qué título debería poner. De nuevo, yo lo reviso, yo digo, si me gusta o no me gusta, etc. Y aquí, precisamente en los últimos videos, pues he utilizado eso, ¿no? Como cómo desplegar, por ejemplo, si yo miro la descripción de este video, la descripción es un poco lo que me generó este proceso que te vengo mencionando, ¿no? Y lo he estado probando como en los últimos videos. Realmente YouTube no indexa o no se preocupa mucho por la descripción, o sea, la descripción es lo menos importante para que un video sea exitoso en YouTube, de por sí hay muchas cosas raras de no sé cómo es que realmente un video es exitoso en YouTube, pero una de ellas es la descripción, ¿no? Entonces esto es lo que menos me importa, o sea, como que la descripción no, uno no le mete tanto cariño a la descripción. Uno sí le mete mucho cariño al título del video y al thumbnail. El thumbnail, obviamente sí lo hago yo, no hay ninguna guía que lo haga. En el de podcast ellos sí generan como el lo que van a compartir a LinkedIn, lo generan con un modelo de Dalí, pero yo no. Ahí sí tengo como una línea gráfica personal en el cual tengo como recientemente como una fotito mía, con una expresión, con una tipografía, para generar el thumbnail. El thumbnail todavía no lo estoy generando por ella, no creo todavía que lo haga, pero sería interesante también probarlo. Pero se puede, se podría, no lo quiero hacer todavía, pero se podría. Entonces normalmente aquí lo estoy utilizando para el título, la descripción y los keywords. ¿Cómo es ese programa? Pues veámoslo. Si ya tengo el summary, si ya tengo el summary, tengo entonces otro comando, que sería el de YouTube. Entonces aquí recibo el path, otra vez le digo en dónde quiero que me deje. Fíjate que de nuevo tengo pasos todavía muy manuales, pero pues quiero liberar literalmente esta versión, recibir feedback. No, ponerla en público precisamente para ver que otras cosas ya uno podría ir mejorando, ponerle una interfaz en Angular, ponerle ya, desplegarla, etcétera, ¿no? Pero listo. Entonces aquí le digo, mira, corre el comando de YouTube y déjame el resultado, déjamelo en data.demo. Ok, entonces acá está YouTube y acá ya se empieza a volver repetitivo. Ok, con base al summary, entonces corre ahora que fue lo que generamos en el paso anterior, toma el chain de YouTube, en el cual le digo, fíjate que este recibe el summary y resube y recibe el lenguaje. ¿En qué lenguaje lo quiero generar? Le estoy diciendo en español. A veces me toca colocarle la TAM, porque a veces el modelo me habla como en español de España. Como vos otros podéis no sé qué. Hoy os recomiendo y yo como yo no hablo así o no es el tono. Entonces me toca ponerle Spanish de Latinoamérica, no el Spanish de que él piensa que porque a veces me lo genera como con ese tipo de y es divertido como lo genera, pero como yo no hablo así, pues me toca a veces decirle oye, español latinoamericano. En fin. Pero ya lo puedo unir como variable, ya lo puedo manejar. Es una variable más. Entonces aquí vamos a ver el chain y fíjate que aquí está el fíjate que otra vez el chain es algo cortito. Le digo utiliza GPT-4 y vamos a ver, por ejemplo, cuál es el prompt. Creo que ese sí lo tengo un poquito más refinado, espero, y si no me toca refinar muchos prompts. Pero vamos a ver el de YouTube. El de YouTube, acá está. El de YouTube. Vamos a ver. Acá tengo, ¿no? Dice tú eres un experto para generar títulos, descripción y tags de un canal de YouTube basado en un summary. El título debería ser atractivo para los usuarios. La descripción debería ser atractiva. Debe ser de un parágrafo escrito en primera persona y los tags deberían ser escritos, deberían ser separados por coma. Crea un título y descripción. Acá tengo la parte de human. Este es el sistema human. Entonces, en fin, esto ya es como funciona PromEngineer. En fin. Crea un título y descripción basado en este lenguaje y acá te mando. Listo. Entonces, listo. Perfecto. Si yo quisiera cambiar algo, no tengo que cambiar el código, lo cambio ya. Y esto en una aplicación de deployment. Si esta aplicación ya vive en la nube, pues ya no tengo que hacer deployment. Si quiero hacer un ajuste en el prompt, lo hago en la speed y ya. Y automáticamente aquí va a llegar. ¿Vale? Ok. Entonces veamos qué pasa si yo ahora corro ese comando. ¿Cuál es la salida de ese comando? Entonces, ahora corro el de YouTube. Entonces, vamos por acá y corramos el de YouTube. De nuevo, este proceso no debería ser tan demorado. El proceso más demorado es sacar la transcripción, sobre todo de videos tan largos. Tanto demorar menos en los videos, realmente. Pero no creo que la calidad deba cortarse. Pero sí he tratado de reducir. Pero fíjate, aquí ya tengo las tres cosas que le pedí. Título, descripción y tags. Aquí, por ejemplo, como es manual, como todavía yo lo estoy haciendo muy manual y todo está quedando como en archivos txt. Acá tenemos el otro archivo de YouTube. Todo está quedando acá. Acá está el título. Me dice, mira, el título debería ser cómo desplegar aplicaciones en Angular con servers. I run it en Google, en Cloudflare. Guía completa. Fíjate que este fue el título que me sugiere. ¿Cuál fue el título que al final yo puse en el video? Vamos a verlo. Me da curiosidad. Creo que fue este. ¿Cómo desplegar Angular con servers? I run it en Cloudflare. El tutorial completo. Fíjate que ahí no utilice guía. Cambio pequeñas cositas, ¿no? Que, en fin, son ya detalles que uno ya va viendo. La descripción. Esta es la descripción. Esta casi que si la pongo directa porque YouTube es lo que menos me importa en la descripción. Y luego pongo los tags. Esto sí se pone internamente en una herramienta que uno tiene como creador para poner como los keywords del video. Y me dice que los tags deberían ser estos. Y los pongo. Y listo. Entonces aquí me ahorra un poco el proceso de pensar en los tags o de que realmente uno a veces se descuide y no pone buenos tags. Pero pues ya está la guía. Entonces generéme los tags y ya. Entonces listo. Acá tengo el de YouTube. Entonces listo. Ya tengo la descripción. Tengo el título. Tengo los tags. Voy y lo subo a YouTube. Listo. Ya quedó. Hay algo que si yo hago que eso sí no lo he podido automatizar que son los el timeline que es como esta forma de de como en cierta parte poner ciertos títulos. Y así aquí en YouTube aquí en YouTube te los deja como en capítulos. Pero eso sí no lo puedo automatizar. Tal vez se pueda. Tal vez no. No sé. Eso sí lo hago manual. Entonces este timeline sí lo hago manual. Es decir, sí tengo para generar como estos chapters. Literalmente pues acabar el video y donde pronto hacer un corte y ponerle un capítulo. No he automatizado eso. Eso sí me toca hacerlo manual. Pero descripción, tags, títulos sí es parte de esa automatización. Ok. Listo. ¿Qué más hago? Luego esto ya se vuelve literalmente como repetitivo. Entonces aquí una vez ya genero el digamos que el video en YouTube ya está publicado en YouTube. Entonces tengo otro para generar un tweet y tengo otro para generar un thread. El de thread no me ha funcionado muy bien. Realmente casi no lo utilizo. No. Porque en el thread yo a veces pongo imágenes y demás y todavía aquí no me genera imágenes. Sobre todo pongo imágenes de código. Como mira, en esta parte tú puedes hacer esto y esto. Realmente el de thread no lo he utilizado. Lo tengo aquí, pero no lo he utilizado. Y el de tweet tampoco creo. El que más utilizo creo que es el de LinkedIn. Pero estos dos todavía creo que me falta refinarlos, investigar, porque no me genera. No estoy satisfecho con lo que me genera pues la guía. Entonces aquí pongo el video. Fíjate que esto es otro ya le digo, mira, cuando genera el tweet, pues este es el video que necesito que hagas como push, como que mira este video. Y acá sí incluye un poquito más de banderas, de flags. Veamos un poco qué es eso. Vamos a ver el de tweet. El de tweet entonces mira que me genera el path para que vaya y lo tome. También lo genera en base al summary. Fíjate que acá ya empiezo a utilizar reutilizar el summary. Entonces la descripción, título y keywords lo hice en base al summary. El tweet también lo va a generar con base al summary. Pero aquí recibe varias cositas. Fíjate que aquí al chain de tweet le envío cuántas palabras debe durar. 140 que es como el límite by default de Twitter. A quién le estoy hablando. Esto me ayudó un poquito también a refinarlo. Como mi público son desarrolladores en Angular. O mi público son React developers. O son Node. Como que cambia un poquito la forma de comunicarse de acuerdo a la audiencia a la que yo le estoy hablando. Luego le digo el lenguaje. Miren que acá tengo latin, spanish. El link y el texto. ¿Qué el texto es? De nuevo el summary. Entonces si yo me voy a este, pues aquí encuentro es simplemente lo que venimos haciendo. GPT-4. Vamos a ver YouTube tweet. Vamos a ver ese al final ese es el que tengo ahí. Vamos a ver. Vamos a ver que tiene ese YouTube tweet. Entonces acá. Entonces si tengo un poquito uno más largo. Tú eres un experto, un chatbot un chatbot experto en Twitter. Genera un tweet conciso que esté dentro de este elemento de palabras. Es efectivo. Bueno, está dirigido para esta audiencia. Por favor no utilice más palabras de las que te di. Utiliza hashtags. Utiliza emojis. Utiliza este lenguaje. Bueno, en fin. Aquí ya está el prompt y pues él lo genera. Entonces con base a eso vamos a ver qué pasa. Entonces vamos a ver. Acá le doy el link. Le digo en qué carpeta quiero que me genere el resultado. En qué público quiero que lo tenga. Vamos a ver. Qué me mire el tweet. Y vamos a ver si es un tweet que me agrade o no. Como les venía diciendo, casi no lo utilizo porque no me gusta un poco el resultado. A veces sí, a veces no. A veces lo tengo que cambiar mucho. Entonces casi que no lo utilizo porque ajá. Pero fíjate acá. Me generó uno interesante. Desplegando apps Angular con server-tolerant. Platform es tu aliado. Discovery, ¿cómo? Edge Computing, bla, bla, bla. No está mal. Mira que acá me generó emojis. Me generó aquí mira el resultado completo. Y ahí me puso el link. Y luego puso algunos hashtags, ¿no? Que es muy popular en Twitter poner hashtag. Ah, ese podría ser bueno. Lo podría utilizar. Lo podría mejorar. Y podría ser un buen tweet para lanzar ese video, ¿no? Como decir, oigan, tengo un nuevo video. Vayan y véanlo. Listo. Sigamos con el de Thread. El de Thread. Vamos a ver. Vamos a hacer lo mismo. A ver cómo me genera el Thread. Si van y ven, estos prompts los tengo públicos. Entonces literalmente si se crea una cuenta en Lance Smith, pueden ver mis prompts y pueden ver los prompts de la gente que haya puesto públicos sus prompts. Entonces pueden ver muchos prompts públicos. Si ustedes están haciendo un prompt de para generar conversación, para muchas cosas, pues literalmente van al app y literalmente es acá, mira, código para evaluación, para escribir, para código, para sumarización. Hay muchos prompts muy interesantes. Entonces uno se puede también como guiar. Ah, mira cómo hicieron este prompt. O guiarte en los videos, por ejemplo, ¿no? En el que tengo acá. Este es de Thread. Vamos a ver. De por sí, fíjate que hay algo interesante también de Lance Smith. Y acá estoy vendiendo más Lance Smith que otra cosa. Pero uno puede hacer fork de un prompt. Por ejemplo, este, este es un prompt de un usuario. Y me gustó. Me gustó bastante como ese prompt. Entonces uno lo puede hacer fork, así como en GitHub. Uno lo puede copiar y de pronto hacerle una alteración, como quiero hacerle esta mejora, pero puedo hacer un fork. También podría crear uno y copiarme y pegarme, pero está bien hacer un fork, ¿no? Saber que yo partí de este usuario y luego ya, luego de forkearlo, pues le hice ciertas iteraciones para que mejorara, ¿no? Y entonces utilizo el mío, pero es un fork de este otro usuario, del prompt de este otro usuario. Listo. Entonces veamos acá. Acá ya me generó el Thread, ¿no? Entonces acá está el número uno. ¿Sabías que desplegar bla, bla, bla, bla, ¿no? Y acá está el Thread número dos y acá está el... Este, como les digo, no lo utilizo tanto porque ahorita estoy haciendo más que el hilo tenga también imagen y pues entonces me tocaría hacer que por cada tweet me genera una imagen. Ahí podría explorar con Dalí, con StepoDiffusion, que con base al texto me genera una imagen, pero a veces son comandos, son líneas muy específicas. Entonces no quiero que Dalí las invente. Entonces casi que me da lo mismo hacerlo yo porque pues no me va a ayudar mucho. Pero en fin, si a ustedes les sirve, si creen que funciona, pues miren, aquí yo le dije, génerame un hilo y acá está el hilo. Y listo. Y nos vamos por el último. Vámonos por LinkedIn. Este sí lo utilizo bastante. En LinkedIn sí se puede como uno expandir un poco más. O sea, en LinkedIn es normal y no sé si tengo aquí mi LinkedIn. Así por acá lo tengo. Es normal que que uno pueda escribir posts largos, no como en Twitter que uno tiene que escribir como un post chiquito. Aquí en LinkedIn es una red social más para profesionales. Entonces uno se puede explayar un poco más, ¿no? Como hablar un poco más y decir tan, tan, tan. Esto, por ejemplo, lo generé con pues con este flujo que te estoy comentando, pero le cambié varias cosas. Hay unas cosas como que no, no, a este, al de LinkedIn le pongo un poquito más de amor y cuidado. Al de Twitter y al de LinkedIn. A eso los refino un poquito bastantes, pero sí me ayuda a no empezar en vacío, ¿no? Como que la AI me dice mira, puede ser esto y yo está muy bien, puede ser esto, pero cambiélo aquí, así yo no hablo por aquí, yo diría esto así, tan, tan, lo publico y listo. Entonces veamos el de LinkedIn. Acá de por sí tengo más atributos porque lo estaba utilizando creo que no sólo para video, ¿no? O sea, no quiero que promueva sólo un video, quiero que promueva un blog, ¿no? Yo estoy lanzando también como mi blog en ahí está mi blog. No he escrito mucho, voy a escribir más, pero ¿qué pasa si quiero decirle a LinkedIn? Oye, promocionan un video, promociona también un post, un blog, promociona un podcast. Entonces casi que esa variable también la volví un poco ¿qué es lo que quiero promocionar? Y creo que esto era porque a veces yo quería pues, como es un blog, a veces le pasaba, el contexto ya no es el transcript, el concepto es, en sí, el texto del blog, entonces se lo pasaba en Markdown, ¿no? Yo escribo esto en Markdown, entonces le pasaba el contexto en Markdown, entonces aquí le paso el contexto, mira, esto está en texto plano, en este caso es un transcript de un video, entonces le digo, esto es texto plano o esto va a ser Markdown porque es un artículo que yo escribí, ¿no? Entonces, le paso esas variables, ahorita vamos a ver cómo está ese, lo que lo generamos, vamos a ver cómo está ese prompt, de nuevo, si voy y veo el comando, entonces acá está el de LinkedIn, bueno, y acá está también el de el de, el de tweet, el de, el de Lilo, pero acá está el de LinkedIn, este me gusta un poquito más, entonces tiene el tipo de contenido, cuántos párrafos quiero escribir, por favor, también escribo algo en, de nuevo, Latam Spanish, porque a veces lo pone muy español, el summary, el formato, el link y el tipo de audiencia, ¿no? Entonces, y otra vez, misma historia, simplemente repito la misma operación y vamos a ver que tiene este prompt, ¿no? LinkedIn, entonces vamos a, para acá, eh, siempre se me pierde, acá está, eh, ¿dónde está LinkedIn? acá está, entonces este también está, este también sí lo hice yo, tal vez si ustedes van al, al, si vamos al hub y buscamos uno de LinkedIn, allá hay cosas, ¿no? Bueno, creo que escribí mal LinkedIn, déjenme ver si sí escribí bien LinkedIn, así, bueno, acá aparece el mío y acá algo muy interesante es que se mira como también un tipo de métricas como cuántas personas han visto este prompt y este form todavía no tengo muy, bueno, este descargar no tengo muy claro qué es y si es las veces que yo le he hecho pull, ¿no? Como cada vez que lo he llamado para generarlo, fácilmente este puedo ser yo mismo, pero como es público, pues fácilmente puede ser otro usuario haciéndole pull a mi prompt y ejecutándolo, ¿no? Entonces, eh, no soy muy, no estoy muy claro si son solo las, las de los demás o me incluye también las que yo he hecho. Creo que me incluye las que yo he hecho, entonces, tal vez son las veces que literalmente he jalado ese prompt al código. Fíjense que por acá hay otros, eh, LinkedIn Learning, Podcast, no sé qué, no hay muchos, miren que el que más hay es este de acá. Entonces yo tengo este, eh, de nuevo acá está el prompt, bla, bla, en qué formato, resúmelo y listo, de nuevo, entonces es prompt engineering, haces tu prompt acá, lo exploras, lo ejecutas, lo iteras, cuando ya lo tengas, lo puedes publicar y ya lo puedes utilizar en tu código. Listo, vamos a ver qué me generó el de LinkedIn. Entonces acá, acá, LinkedIn, ¿no? Y fíjense que por cada uno de esos comandos me está dejando como un archivito, ¿no? Entonces acá, acá está el thread, acá está el tweet, acá está el post de LinkedIn, en teoría, ¿no? Entonces básicamente yo estoy guardando esos, fíjense que lo he hecho como desde acá, lo he hecho con el de el video de migration, el video de whisper, el video de angular views, como que lo voy guardando ahí, ¿no? Tal vez esto debería no guardarlo en archivos txt, tal vez, pues obviamente debería ser una base de datos, donde pues ya digo este contenido, una base de datos, se guarda y se puede, pues, consultar, ¿no? Ahorita, de nuevo, es algo que estoy haciendo como de forma muy exploratoria, así que un art txt funciona bastante bien. Entonces acá tengo el de LinkedIn, ¿no? Entonces aquí me deja el archivo, entonces, estás buscando más rendimiento, tu aplicación, entonces estos días escribo un artículo más pesado, más pensado para LinkedIn, etcétera, ¿no? Espero compartas comentarios, bla, bla, entonces, por ejemplo, este fue una base que yo utilicé para escribir este, luego ya lo refiné, le cambié, bla, bla, pero me sirvió mucho como base para poder escribir el post final. ¡Listo! Eso es, literalmente, hay otros dos comandos que tengo aquí, pero realmente creo que ahorita están rotos y estaba probando lo que hacía Microsoft en ese demo, que era como generar imágenes con base también como al tweet, al texto, estaba probando DALL-E, de por sí estaba probando StableDiffusion para no utilizar pues esos, por acá tengo DALL-E, entonces uno básicamente llama a la API de OpenAI y genera de acuerdo a cierta cosa, o tenía también como una pruebita chiquita que no avanzó mucho con StableDiffusion, ¿no? Correr StableDiffusion localmente y generar la imagen, pero no he avanzado con esos dos comandos. Y acá una lista de cosas como de qué quería hacer. Eso es, eso es como yo estoy utilizando ya para automatizar y generar cierto tipo de contenido. Dime, ¿qué pensamientos te trae esto? El repositorio ya está público, lo puedes clonar, lo puedes correr, ya pones tu llave de OpenAI y puedes hacerlo ahora con lo que con tu contenido, con tu blog, ya sabes cómo utilizar Lansmith para administrar prompts. Si no quieres utilizar Lansmith, puedes poner el prompt directo en tu código y también ejecutarlo. Pero me parece una idea bastante interesante, bastante válida, que me permite romper como esta hoja en blanco para escribir como este contenido y creo que como el contenido se basa en lo que yo dije en un video, es bastante fiel a lo que yo diría en un tweet, a lo que yo escribiría. De nuevo, yo no copio y pego, sino normalmente lo reviso un poquito, cambio alguna cosita, ya le pongo un poco más de mi estilo, pero eso ha sido más porque no he tenido un poco más de chance de seguir mejorando el prompt, de seguir de pronto pronto probando otros modelos, de seguir probando otras técnicas de Probe Engineering. Últimamente están saliendo más técnicas y más modelos para seguir refinando, entonces uno podría utilizar mejores y nuevas técnicas para de pronto ya no tener que hacer tanta refinación, sino con base a todas esas instrucciones, con base a mí, a lo que realmente dije en el transcript, pues que lo haga muy a mi estilo y de pronto que las correcciones no sean mínimas. Sin embargo, las correcciones yo creo que siempre van a estar presentes, uno debería verificar si lo que voy a publicar tiene sentido con mi marca personal, con lo que yo quiero expresar, etcétera. Déjame en los comentarios qué piensas acerca de esto, qué piensas de este repositorio, qué piensas del repositorio de Microsoft, qué piensas de la creación de contenido generada por AI. Te leo en los comentarios, es un tema bastante interesante, esta es una prueba de concepto que ya está publicada literalmente, y te quiero compartir una aplicación que me parece interesante también, si es que no quieres de pronto hacer todo en código, pero si hay una aplicación que me ha parecido interesante para que ya genere producto con esto. Esta es la aplicación, esta es la aplicación, no sé muy bien cómo se pronuncia, es root, es root, es no sé, en fin, pero me parece una aplicación a la que potencialmente por ejemplo, si yo ya tuviera que poner una interfaz gráfica a la aplicación, y hacer el backend, y toda la aplicación, probablemente termine como con algo muy similar, a modo de inspiración, pero me parece muy interesante si tú te logeas, vas a encontrar aquí como la aplicación y entonces puedes como decirle, mira, yo aquí, como que aquí tiene como una herramienta de AI, entonces también en teoría podría como decirle, mira, esta es la transcripción, aunque realmente no está muy pensada para generar contenido con base a un canal de YouTube, como el que yo tengo por ejemplo aquí, aquí voy a ponerle mi transcript, es más, voy a ponerle el summary, que es un poquito más corto, y debería estar mejor pues creada, acá, acá, nada más, bueno, content, le pongo, y acá tengo como algo para literalmente decir, mira, crea un borrador, crea no sé qué, y yo puedo como que por aquí administrar como, un poquito como el lansmith, como crear mis propios prompts, y decir como, generame un draft, generame, como, reiterame este contenido y reproponlo de alguna manera, para escribir un blog, por ejemplo, y aquí me dice como la audiencia, digo, ah, pues esto es para AngularDevs, eh, cuál es el objetivo, promover, promover CloudFair, digamos, Cloud, CloudFair, cuál es el tono, informativo, persuasivo, digámonos, y listo, entonces le digo, creo que perdí el, acá, hazlo así, creo que perdí lo que escribí ahorita, otra vez, AngularDevs, AngularDevs, a ver si me lo tengo completo, es un tutorial, un tono persuasivo, crea un blog, entonces él empieza, a escribir, empieza a escribirme como un post, en base a ese resumen, entonces, literalmente yo podría reutilizar esto, y entonces ya publicarlo en mi blog, entonces como que yo poner acá, y decir, con base al summary o a la transcripción, entonces ya tengo un post nuevo para escribir un artículo nuevo en mi blog, entonces, acá, Mastering Server 3D Render in CloudFair, y ya puedo ponerle cositas, otra vez puedo iterar, como, esta cosita sí, esta cosita no, fíjate que acá me lo escribí, o sea, yo le pasé en español, pero él me genera todo en inglés, aquí sí tiene una debilidad que no, o sea, el idioma no es parte como de los argumentos, de los parámetros, entonces todo me lo genera en inglés, porque pues es una aplicación gringa, entonces pues está más pensada todavía para ese mercado, pero, entonces uno acá le puede poner esos parámetros y tal, entonces, y luego ya aquí, de por sí lo estoy pensando, estoy pensando en voz alta, básicamente, podría coger esto de acá y tomar esto ya post, mejorarlo, cambiarlo, ponerle como algunos ejemplos de código, como por ejemplo aquí que ya, entonces hay ejemplos como de código, imágenes, no, y hay un ejemplo de código, bla, bla, bla, y ya tengo un post, o tengo otra vez una ayuda para escribir ya el post, para que me ayude en mi blog personal, entonces, fíjense que es muy parecido, por eso me gustaba mucho esta aplicación, porque como que tiene un poco de lo que yo esperaría, por ejemplo, si le pusiera frontend a mi aplicación, como aquí escojo, le digo en qué cada una de estas variables, escribo un post, escribeme un post para LinkedIn, escribeme un post para Twitter, en qué tono, bla, bla, y pum, se publica, no, eeeh, eso es lo que te quería compartir de esta herramienta, y listo, eso ha sido todo por hoy, por este video, de nuevo, quiero leerte en los comentarios qué te parece qué te parece esta forma de usar IA para generar contenido, te leo, o si vas a empezar a utilizar esta herramienta, que te compartí también para generar cosas, o el código directamente, o el Natsmith para precisamente administrar prompts, entonces te lo dejo ahí, así que compártelo, dale likes, me ha llamado un montón que se suscriban, que lo compartan, que literalmente pueden mandárselo a ya no sólo de pronto a desarrolladores que quieran empezar a utilizar esto como como parte de creación de contenido, o imagínense, literalmente una empresa de marketing que diga, quiero empezar a generar ciertas automatizaciones pero que la IA me ayude a automatizar ciertos procesos y ahorrar cierto tiempo, no sé, hay un montón de casos de uso, también si ven un caso de uso como, mira que esto se podría utilizar para esto, lo leo en los comentarios, no siendo más, hasta la próxima, chao.