 Te voy a mostrar cómo yo estoy utilizando varias tecnologías de inteligencia artificial para generar contenido de forma automática. Esto lo utilizo por ejemplo para hacer tus pocos el link de Twitter, etc. Y no, no te sientes de frotado, es decir, yo soy autor de esos link de los tweets, pero sí me apoyo en varias herramientas de automatización basada a Zenía. Y todo eso fue inspirado precisamente en una herramienta o más que herramienta un concepto, una prueba que hizo Microsoft en un repositorio en donde ellos hicieron algo similar. Te lo vamos a dar, te vamos a dar una inversión cómo funciona y esperas tus comentarios al respecto. Este es, este es el repositorio. Microsoft lo pueden encontrar como Microsoft, podcasts, co-calot, precisamente porque ellos crearon una idea, una prueba de concepto como pueden generar contenido automático basada como en los podcasts que ellos grababan y esto lo presentaron en el MSB del 2023. Ni siquiera al de este año del 2024 que de por si fase poco, sino fue el de hace dos años. Y es un concepto que desde que yo lo vi más interesante y está trabajando como una versión propia que es la que te voy a mostrar hoy, tampoco es que está determinada, pero pues las estoy poniendo aquí a público y poner en conversación cómo es que estas herramientas de idea nos pueden ayudar para generar contenido. Es cual es el caso de ellos, el caso de ellos es que ellos grababan una entrevista, con una persona. Entonces, es entrevista, el audio lo pasan por Whisper. Es eso como los pasos que ellos tienen. Hay unos pasos que corran en local, otros que corran en la nube, pero por ejemplo ya tengo un video en mi canal acerca de cómo obtener el transcript con Python porque todos estos están Python y mi repositorio también está en Python. Pero básicamente aquí hay un modelo que te dice, cómo generar la transcripción de lo que se dijo. Tú yo lo paso un audio y me pasa la transcripción, es un modelo sencillo. Whisper lo puede ser un otro audio en mi canal de cómo utilizarlo. Entonces, una vez tienen cómo la entrevista, pues básicamente entonces obtienen el transcript. Luego tienen Dolly que es un language model chiquitito, como no tan potente, como GPT4, OpenAI o Gemini de Google, pero pues es un modelo que sirve para basar en la transcripción, como obtener el nombre del invitado, como quién es el invitado que estuvo hablando en ese podcast. Normalmente porque en el podcast hacen una introducción, ¿no? Como hoy estoy aquí con tal persona y vamos a hablar acerca de tal cosa. Entonces ese Dolly que es un language model chiquitito, pues te ayudan eso. Aquí podrás utilizar GPT4 también y ya no hay tanto problema. Luego buscan utilizando ya la 9 de y el buscador de Microsoft, que es Bink, buscan como información relevante de esa persona, como Extriger, como si hubo Geografía, la habla. Luego utilizando GPT4 y como una utilizando Azure, básicamente generan como una descripción, como una... Con base a la transcripción generan como un resumen. Y también con base a ese resumen generaron una imagen utilizando Dolly. Y luego literalmente con un plugin de LinkedIn lo pasan y generan ese post en LinkedIn. Entonces me pareció bastante interesante esa prueba de concepto. Te va a mostrar cuál es mi versión, de por si vamos a enterrar a mi Github. Y así como yo le llaman un podcast co-pilot, yo le llame como Shannel co-pilot, porque lo utilizo como para las cosas de mi canal de YouTube, Shannel co-pilot. Y fíjate que está privado, lo va a poner público en este momento, lo va a poner público para ti, para que esperas, recierortos comentarios en este vídeo, acerca de cómo ves esta prueba de concepto, va a cambiarlad de la habilidad y ahora es un repositorio público. Literalmente tu también lo puedes clonar. Y ahora me pide mi autenticación de seguridad de Github, que es interesante. Vamos a hacerle rápido por el poder de la edición. Listo, ya literalmente ya, ahora sí que como un público, Shannel co-pilot, un repositor que está trabajando de forma privada, pues está ahora público. Listo. ¿Qué es este repositorio? Básicamente lo voy a colocar con la descripción, le voy a colocar como un rime, o que por aquí hay un buen, uno es como cosas que ya tenían detrás. Entonces, seguiendo como ese mismo paso que te les apodcasco pilot, básicamente lo que yo hago es grabar mi contenido, mi siguiente vídeo de Github. Y lo que hago es el primer paso es pasar este vídeo hacia la transcripción, también utilizando whisper. Y aquí ya hay una conversación que siempre hay internet de por si va a pasar a la cámara principal. Y esa conversación es, es bueno empezar a generar contenido simplemente pidiendo el celo a una AI. Sobre todo porque entonces el contenido ya no tiene como mi autenticidad, como mi forma de ver las cosas, sino que ya es la forma entre nada de una AI, como pedirle a una AI, dime algo, un Twitter, un post en en que hay en acerca de angular y los unitesten. Y pues, él lo crea y yo lo público, y ya estoy generando contenido basado en ella. Aquí hay algo que me gusta de este concepto, y es que al final lo que yo hablo en un vídeo, literalmente son mis pensamientos, en mi forma de pensar, en mi forma de expresar las cosas, en mi forma de dar a entender ciertos conceptos, ese soy yo. Entonces, o relativamente en ese pedazo de vídeo, o al menos lo que se muestra hacia YouTube. Pero ese yo hablando y expresando cierto tipo de conocimiento. Entonces, cuando yo paso ese vídeo lo transformo, pues saco el video, saco el audio, primero por si saco el audio después del audio, saco el transcripto con whisper, ahí como que ya es cierto tono, cierta forma, y ya con utilizando promise engineering, pues le digo mira, con base A, pues lo que hablé aquí generame un link, un post en link de un post en Twitter, acerca de lo que yo dije y cómo lo dije, y respetando un poco como la forma en la que yo me expreso. Hay varias cosas de por si que a veces no me gustan y no es que yo copie y pegue, sino que literalmente lo genero, y luego lo leo y digo yo no hablaría así, yo no hablo así. No es mi forma de comunicarme y corrigo ciertas cosas. Oita hago ciertas correcciones manuales, no hago nada automatizado, como que hago la toda la corrección manual, y porque a veces sí como que no me gustan el tono en el que queda generado de ese tweet, ese post, lo que sea, esa descripción lo que sea. Y lo corrigo, pero probablemente con nuevos modelos, con modelos más potentes que están saliendo o con simplemente mejorar el prompt, pues podría casi decir, ¿distos si? Así es como más o menos yo me expreso. Entonces, hable y genero un post en LinkedIn, en Twitter, un hilo para cierta plataforma de redes sociales. Entonces vamos a explicar un poco cuál es el paso a paso y cómo funciona el repositorio. Déjame lo. Y lo primero de hacer que de este repositorio es que todo funciona como se fuera una herramienta de línea de comando. O sea, no tengo ningún interface gráfica todavía. Si lo tengo en planes, pero como es algo muy personal, todavía no le he puesto una interfaz gráfica. Entonces simplemente se ejecuta como una herramienta de línea de comandos. Y como está hecho en Python, hay una herramienta creada por el mismo creador de FASA y PI que es, se bastía en ramide este ángulo, que es typear que es una forma de como crear herramientas pasada en Python para escribir celebis, como clientes de comandos, como que yo escribo un comando y haga algo. Entonces básicamente, pues como que yo corro y ejecuta cosas. Y hay una forma bastante bonita como de hacerlo de recibir comandos, etcétera. Eso es casi la base del repositorio. Por eso, por ejemplo, todo este genera como en base a un audio. Y digo, a un comando. Entonces no vamos a ver mucha interfaz gráfica. Pero vamos a ver, yo de por si lo tengo como, como divido en tantos en ciertos pasos, de por si no utilizo estos últimos dos, lo que se estaba explorando, pero vamos a ver cuál es el primer paso. General audio. Ok, entonces normalmente yo utilizo acá como input utilizó un video. Entonces esto es un video. Esto es un video que grabé, no sé, para un video de cláufra, para un video de los que hago mi canal. Y son bastante pesados. Normalmente yo los exporto en una calidad bastante grande para que YouTube tenga una buena calidad. En fin, aquí creo que no se queda se va a reproducir porque son 10 gigas, lo que pesa ese video. Entonces este, en la carpeta input, lo va a ser un poquito más de som, no está de por si está ignorada dentro del repositorio. Normalmente yo cada vez que género un contenido, halo esa carpeta ahí. No sé por qué no está cargando el g-tignor, pero bueno. Halo el video con el cual quiero generar como contenido y simplemente lo pongo ahí como en esa parte. De por si acá está ignorado el input. Todo lo que yo pongo en input, lo ignoro porque sería bastante pesado para el repositorio. Entonces se vuelve el último video que haya puesto. Como general la transcripción, esa es el primer paso, general la transcripción. De por si para generar la transcripción necesito el audio. Entonces lo que hago es pasar el video a audio. Como hago eso, literalmente aquí en la archivo main.pine hay un comando que eso es lo bonito de Typer, como que te deja exponer comandos a través de funciones. Entonces yo le pongo Python y la archivo main.pine que es donde están declarados todos los comandos. Todos los comandos están declarados aquí. Pues simplemente va a buscar el comando o la función audio que está como un comando. Y acá literalmente le go mira. El video está en este pad, general la audio. Y esto es una función de Python. No es nada más, es una función de Python. Utilizo por ejemplo aquí la librería de un boobie.py en el cual le digo mira. Y esto es por si creo que hasta me lo genero Gpt. O sea, o jefeco.py. Como hay un necesito de una función para convertir un video en audio. O sea, solo necesito el audio. No necesito pideo, necesito sobre el audio de ese video. Entonces aquí utiliza esto. Y literalmente me arroja. Yo le digo que escribamos un archivo en .wap en donde ya queda todo el audio. Entonces básicamente lo primero es transformar ese video en audio. Y en audio pues que obviamente queda más chiquito. Ya queda no de una giga que ha de 428 megabytes, queda mucho más chiquito. Y acá está el audio de ese video. Y en este video. Entonces literalmente ese es el audio del video. ¿Vistó? Una vez tengo el audio del video, me voy corro el segundo. Paz. Y aquí tengo una mala arquitectura de carpetas. No me quietíquen, esto es un demo y es una prueba de concepto. Lo interesante es cómo se puede hacer esto con ella. Luego ya mira como crear buena arquitectura para este prototipo. Pero aquí literalmente le digo bueno. Con base ese audio te transcribe y déjeme la transcripción en esta que, como en este folder en específico. Y recordemos que a calata de A es transcribir. Entonces busquemos aquí el comando transcribir. Ahí está. Pues básicamente yo tengo un patfijo. Yo ya espero que yo ya haya corredor el comando anterior, que es el de, pues el audio entonces yo espero decir, a mira, el audio está ahí, está en este archivo. Ahora, generalame la transcripción. Tengo una función para generar la transcripción y utilizo Whisper. Si quieres ver un poco más acerca del Whisper, literalmente hice un video completo de cómo utilizar Whisper. Entonces aquí básicamente hago la transcripción. Y es más, podemos corrarles más. Voy a corrar el comando. Voy a corrar el primer comando. Ya que tengo ese archivo ahí. O sea, el audio es lo que va a hacer es rescribirlo. Pero entonces si lo corro, pues literalmente va a tomar el video y va a pasarlo a audio. Eso es lo primero que hace. No sé si de pronto ahorita vayamos a leclar porque ya hay un archivo. Creo que no, mira, ahí está haciendo pasando de audio a video. Es el primer paso que te dije que hacíamos con la librería. Una librería de Python normal que es MoviePy. Disto. Entonces ahí se me va a generar y me deja hacer chivo en donde yo le ha indicado que es Input SlashAudio. Y ahí lo dejo. Mira, ahí está. Entonces mi siguiente paso, ¿cuál es? Pues es general del transcripción. El comando del transcripción es este. Y yo le digo, mira, aquí algo bueno de Typer es que, pues, de nuevo, me permite, creo que ya se ha resladado la recomendación de Typer, pero lo vamos a abrir. Me permite como recibir comandos para luego yo hacer cosas con él, como recibir cositas, como atributos del comando. Entonces aquí yo le estoy enviando el pat como si fuera un atributo. Entonces este pat es el que me llega acá. Entonces acá le digo, mira, corre con base a este audio, pues, generalmente, la transcripción, el corre modelo de whisper para generar la transcripción. Y déjame lo en el pat que yo te dije punto transcripción. Entonces voy a hacer un demo. Entonces aquí, por ejemplo, hago demo. Y voy a crear una carpetica que se llama data, que es las transcripciones que yo he hecho para diferentes videos, para cosas que yo he hecho. Pero pues vamos a poner uno que se llega de nuevo. De por si le puse una carpeta que no le dejo. Fíjense que todavía sigue siendo manual varias cosas, pero pues es la idea, ¿no? Es un prototipo que vamos a empezar a mejorar, de automatizar, de pronto ponerlo en una API, general producto, no sé. Aunque ya hay productos muy interesantes, te vamos a estar en uno que igual también es bastante interesante, que ya como que hacía esto, pero pues simplemente con una interfaz. Pero listo, entonces yo le digo que basado en ese comando, por favor vaya a punto de data y el transcripción, me lo deje en la carpeta demo. Y pues me lo deje con el nombre transcripción.tdxt. Entonces si yo corro esto, pues básicamente lo que va a hacer ahí es correr el modelo de Whisper para combarse a ese audio, todo lo que se dedica a ese audio me va a generar el transcripción. Entonces aquí ya hace un proceso. Por ejemplo, acá yo estoy utilizando Whisper la versión. Creo que el modelo base, fíjate que ni siquiera estoy utilizando. Creo que estoy utilizando el arch. De verdad. Sí, aquí le estoy utilizando el parámetro. Fíjate que aquí primero le envío. En donde está el audio y luego cuál modelo quiero utilizar de Whisper, que si no le envío nada con GBAs, pero como si le estoy enviando el parámetro, que es este el arch. Pues entonces pues va y le pasa el tipo que el tipo lo está recibiendo acá. Y pues en fin, básicamente estoy utilizando el modelo LARGE para hacer una traducción de alta calidad. Y fíjate que aquí empieza a hacer la transcripción. De por si debería, creo que hacer un ejemplo de un vídeo más cortito porque este audio, este audio, el que estamos analizando ahorita, son 42 minutos. Si no estoy mal. Y pues es casi una hora de audio. Entonces obviamente el transcripción se va a demorar. A ver si tengo uno, creo que no tengo uno chiquito. Pero son 42. Vamos a ver cuánto se demora haciendo esta transcripción. Pero fíjate que lo que está haciendo ahí es literalmente pasar ese audio. Y este es el proceso más largo. Este es el de por si lo que más se demoras esto, hacer la transcripción. Luego genera resumen, generar un texto a partir de esta transcripción va a ser relativamente fácil. ¿Por qué usamos un modelo como GPT-4 y el genera y es bastante rápido? Perteo a tapete, vamos a una herramienta muy interesante que utilizo para generar eso. Y aquí ya te hago un spoiler alert. Si no has visto LANESMIT, un servicio creado por LANCHEND para poder administrar prompts. Y esto es una de las cosas que les me ha gustado y que podido experimentar. De por si creo que luego voy a hacer un video solo aparte de LANCHEND pero ahorita te va a contar rápido como yo lo estoy utilizando. Pero pues no, esperemos que esto termine porque ya lo puse a ejecutar y creo que no tengo un video un poquito cortito para probar. Y quiero hacer algo con un caso real. Entonces con la magia de la edición vamos a esperar. Y tú ya simplemente vas a ver esto ya cuando acabe. Y yo voy a tomar un vaso de agua mientras esto acaba. No tenemos ahorita. Y fíjate que listo que ya terminó. Demoró literalmente 10 minutos. 10 minutos en hacer esta descripción. Y ya debió entonces dejar el archivo. Vamos a ver el archivo. Ahí está. Demo punto de transcript. Aquí está todo lo que dije en el tono que dije, cómo lo dije, cómo me quería expresar lo que expliqué, etcétera. Literalmente este es el transcrib de ese video. Ok. Vamos a ver el segundo paso. No, el tercero. Entonces ahora de nuevo le digo que en esa carpetita, que es la de demo, me deje un sumar y aquí es donde entonces vamos a ver el comando del resumen porque la transcripción es muy grande. Es un contexto muy grande. Aunque realmente modelos actuales como GPT-4 o Jiminy Pro soportan modelos gigantesos, o sea que ahorita el task group no debería ser. Así sea tan grande, no debería ser un problema de contexto. Sin embargo, también es bueno como que resume todo eso como condensa, algo respetando a mi estilo y demás, pero como condensa, para luego generar un tweet o ese es mi proceso al menos o mi fórmula de alguna manera para hacerlo. Y aquí es donde entonces va algo interesante. Entonces me digo mira. Ok, aquí en sumar y le digo mira. Con base al transcripto que ya es un archivo de texto, ya es texto literal lo leo y le digo que por favor genera un resumen y lo deje en sumar y punto teque. Y usted ahora eso lo llamo con un chain y acá estoy utilizando Lanchen y fíjate en esta línea de archedito. En 11 líneas. Porque acá estoy utilizando un servicio que se llama Lanchen Lan, Lan, Lan es mi ahorita si este es Lan es mi precisamente. Entonces acá tengo Lanchen que es lo que me permite precisamente como interactuar con modelos Lanchen si no lo conoce de nuestro bueno yo creo que se le conocen es uno de los frameworks más famosos para poder interactuar o manipular Languer, las chelarwatch models. Mati manipular acá una de las cosas que me parece muy interesante es que yo puedo decirle mira. Quiero que utilizar Gpt4 a Turbo o que lo utilizar el Gemini o que lo utilizar Cloud. Entonces como que es un framework agnóstico y tú dices mira solo quiero interactuar con este tipo de modelo y ya. Disto entonces en esta casa lo bajar con Gpt4. Obviamente tienes que tener un aquí de OpenAI en tu Cloud para que pues para que puedas poder acceder a Gpt4, es un modelo de paga al final. Yo tengo ahí mi clave entonces pues él simplemente la va a obtener y generarlo. Pero en donde está el prompt? En donde está ese prompt que yo le digo oye con base a la transcripción entonces blah blah blah blah blah. No? Donde está ese prompt? Hay algo muy interesante y es el servicio precisamente que aumentaba del Landsmeet. No sé si conoces el concepto de un SMS o una base data y aquí quiero hablarte directamente a ti. Precisamente una base de datos es como un repositorio de datos o un SMS o un content match and assistant. Normalmente se ha utilizado mucho para blogs y demás. Landsmeet se convierte como en ese administrador de prompts para no tener como el prompt quemado directamente en el código que se puede. Pero qué pasa si luego yo quiero iterar el prompt un poquito, cambiarle cierta cosita. Tengo que entrar al código, hacer un release en la aplicación, compilar pasar pruebas unitarias todo el proceso de despliegue, para hacer un cambio simple en el prompt. Ahora, Landsmeet se convierte como en esa base de datos de prompts literalmente en esos prompts que tú le colocas una ID, se puede hacer por organización. Es decir, si tú estás desarrollando chat bots o tu propio chat web empresarial, sería bueno que crees una organización. Y ahí,endo a cualquier persona de la organización, puede iterar ese prompt. Puede decir, no, puedo mejorar el equipo, mejorar allá lo despliego y literalmente yo lo consumo. Como si fuera a llamar este prompt desde mi aplicación, de por sí, aquí te va a mostrar la llamada. Aquí está la llamada, este, este Launching Import Hub, ese Hub es el Landsmeet. Y normalmente hay un barra aquí, me equivoque mi nombre de usuario de audiencia, San Nico Bites, pero no lo puedo corregir. Quiero comunicar un boteste. Pero literalmente tú pones el nombre de tu organización, que puede ser privada o lo que sea. Y pones como el ID, como si esto es como la forma de reconocer tu prompt, en este caso yo le puse Nico Bites, su maritranscription, el vaincontrar ese prompt y luego lo vainjecter. Y ya, y luego, pues ya tengo, acá tengo ya el transcript, que lo paso como una variable, básicamente se lo paso como un input, acá está, de por si si tú miras, acá le paso cuando yo tengo ese chain lo invoco y le paso ese transcript, ese transcript está definido aquí para que llegue como variable. Luego el prompt que viene de ese hub o de ese administrador de your prompts, luego le digo con qué modelo va a operar este prompt, en este caso lo va a hacer con GPT4 y luego un output parcer que es una manera de todo eso que hizo pasar a lo un string plano, listo. Vamos a mirar un poquito cuál es el prompt de ese sumo y transcription. Entonces aquí me va a loguiar con Github, porque si no estoy mal, creo que estoy loguiada con Github. Vamos a ver por acá, yo soy un beta user, literalmente aquí, precisamente debería haberse ya puedo cambiar mi nining, pero todavía no sé si lo puedo cambiar y que ya no digan y que no digan y que pude, butes, sino nico bytes. Pero bueno, entonces aquí aquí en el hub, creo que por acá está el hub, donde está el hub, esto lo han venido el cambiando, acá está prompts, ahora ya no se llama, hub, sino lo llaman prompts, o al menos es de la interfaz. Entonces fíjate que acá tengo el prompt de sumo y transcription. Y aquí es donde uno administra el prompt. Entonces aquí se vuelve muy interesante, porque acá es donde yo puedo hacer pruebas, donde puedo mirarse, puedo iterar el prompt, cambiar alguna cosita, también el prompt puede recibir parámetros. Por ejemplo aquí recibe el transcript, literalmente recibe el transcript. Y aquí me dicen cómo yo puedo llamarlo ya desde mi código en este caso en Python. Lo puedo probar, por ejemplo puedo dictar en un Playground y le puedo decir, mira, acá es literalmente está el prónio. Tuve de su asistente que puedes escribirlo en suma, pues en resumen en paráfors, en paráfors, dado una transcription de un video, el resumen debería ser usado para crear contenido online en redes sociales. El resumen debería ser escrito en primera persona, como si yo lubi el asquito. Sí, en primera persona. Y luego acá está el prompt del humano, diciendo el Pro, favor, lo hagan español. Y acá le paso el contexto del transcript. Y aquí lo interesante es que literalmente yo le puedo poner aquí por ser como probar un transcript, literalmente en teoría debería poder copiar aquí el transcript. Por ejemplo, todo este, vamos a ver si me soporta ese número, acá, ahí está. Lo copie, acá literalmente también puedo probar un modelo, voy a probar con GPT4, por ejemplo. Le puedo mirar la temperatura, que sí se vuelve más creativo, o no, en fin, lo bajaron uno. Y puedo probar. O sea, puedo, esto es lo bueno de la, y creo que ya estoy haciendo el video del Landsmeat, pero creo que literalmente si voy a hacer un video aparte, aquí te voy a hacer una explicación sencilla. Pero aquí puedo como iterar, entonces tu equipo podría haber, a no, fíjate, acá me dice que el modelo, se lo soporta un contexto, fíjate que hay problema de contexto, y se que, entonces, por eso creo que está utilizando GPT4 Turbo, que tiene un contexto más grande. Vamos a ver si este modelo, GPT4 Turbo, fíjate que el sí soporto un modelo, pues como un contexto más grande, y acá, literalmente está la respuesta. Es que lo que me permite, Landsmeat, que aquí yo tengo un laboratorio para poder iterar, para poder evaluar prompts, para decir, bueno, ¿qué pasa? ¿Se se te cambio aquí? Le cambio acá, le cambio acá. Lo probo con diferentes modelos. Mira que acá hay Azure, blah, blah. Hay chat, vertex, hay un modelo de Home Face, bueno, como que puedo cambiar y ver como operarlo, etcétera. Entonces aquí se vuelve y si tú lo utilizas para una compañía, se vuelve en un administrador de prompts y listo. Entonces aquí como que alguien lo administra, lo literas, lo mejora, y simplemente tú en tu código, como desarrollador, simplemente lojalas de esta manera, de que mira, lo que haya ya, lo que es la última versión, porque esto también se diversiona, es más, para que tengo como un historial, uno normalmente puede ver cómo hay el historial de cómo lo ha, aunque este es el historial de Run, creo que había un historial, la haberse un historial de versiones, y lo lo bla, así, hay como Comments, ¿no? Por ejemplo, este, literalmente este pronolo, tengo hace 5, hay otros que si he iterado mucho más, este es su marino, lo he iterado mucho, literalmente se quedó en esta fecha, probablemente va a mejorar este pron para mejorar la calidad del Sumer Y, pero algo muy tan positivo de esto es que es público, hay pueden haber prompts privados para tu compañía, para tu no quieres que todo el mundo vea, o puedes ser público, ¿qué quiere decir eso? ¿Qué? ¿Ves que yo tengo aquí mi usuario? Yo podría buscar en como prompts que hayan sido construidos por, pues, por alguien más. Vamos a ver si esto se llama deja acá, acá está el Launching Hub, y yo haberse un prompt para Sumer Y, para hacer un Sumer Y, entonces lo busco, lo buscar, y fíjate que todos esos usuarios tienen prompts para hacer Sumer Y, de por si esta técnica, de la Refine Chandensity, o esta técnica de la densidad del pron, es una técnica para mejor hacer mejores Sumer Y, Sumerization, entonces podría probar este pron, y lo bueno es que entonces yo puedo probar este pron, y decir, mira, yo quiero probar el pron del usuario, tal, entonces me lo traigo, ¿no? Entonces ya no voy a hacer el prompt con mi versión de prompts, sino con el destusto, eso sería los prompts que son públicos, y ya hay lo utilizado. Obviamente, que te den cuenta si este prompt recibe, por ejemplo, acá recibe varias, literalmente recibe muchas attributes, fíjate en todos esos recibe, más, si yo lo corro, y déjame al si me deja corregarlo, no, creo que no me deja corregarlo, que es verdad lo que no me deje evaluarlo, pero todas estas variables que están como por esquitas como por acá, acá, son variables que yo le tengo que enviar, como el máximo de palabras, la categoría del contenido, las citaraciones para que mejor el proceso, acá al máximo de relationships, o sea, como que uno depende obviamente a la cantidad de cosas que recibe hasta el prompt, pues yo entonces debería empezar a enviarle esto. En mi versión solo recibe un argumento, que es el detrásclup, entonces voy a dar otras de mis prompts, en su mar y fíjate que yo solo recibo una, en tu taskup, entonces solo le envío una. Entonces también debes tener en cuenta, si quieres hablar uno de esos públicos, que variables debes enviarle, si quieres construir los tuyos, pues empezar a ver cuál otro, y bueno, esto es muy interesante, realmente me causa mucha interés, como uno puede también tener un administrador de prompts, y puede literar, darse a una persona que no tiene que entrar al código para detectar el prompt, puede literar su ir una versión, y en mi código ya se consume, y no tengo que hacer ningún cambio, si yo lanzara un nuevo release, por ejemplo si yo quisiera ahorita cambiar, y decir no me lo generen español, género en el melo que el language sea un atributo, entonces escribalo en y acá le digo language, y ahora el language de verdad, yo ya se lo puedo enviar, y en código entonces yo debería enviarle en qué idioma quiero que me génerede el sumo, y el sumo haría ahora es parte del prompt, y digo el lenguaje es parte del prompt, entonces ahora yo debería enviarlo, de por si ya tengo otros que envían el idioma, por acá entonces voy a copiarme, ya que estoy literando en ese momento este prompt, y acá sería una muestra como estoy iterando ese prompt, no, no, no, no, acá, vamos a ver aquí, no, este no es, dejame ver una guabaza en el link, si es como un diccionario, y acá si lo vas a hacer como en ese formato, entonces aquí, aquí lo encierro en esto, entonces voy a encerrarlo, parampan, parampan, parampan, listo, entonces este, luego ponlo acá, luego ponlo acá, quiero que me quede bien formato y nada más, yo soy muy, como especial en que esté el código ordenado, para que sea fácil de lectura, entonces ahí creo que ya es fácil de leer, listo. Entonces aquí qué está pasando? Que yo le estoy enviando el transcripto como una variable, estoy creando en una nueva variable para que Spanish no sea su única forma, aunque normalmente yo que genero contenido solo en español, pero si hay que decirte que yo pueda mandarle el idioma en que genera el Sumary, como una variable más, y luego pues simplemente la va a traer del prompt, hasta podría decirlo bueno, si no me lleguen nada, pues por defecto sea español, pero ya lo comando desde acá, y el prompt es flexible, entonces aquí ya si me tocaría hacer un commit, para publicar una nueva versión de ese prompt, entonces ahora si tengo una nueva versión, vamos a ver, fíjate que aquí nos coméis, ahora ya hay una nueva versión que fue hace poco segundos, esa nueva versión del prompt, ahora es la que yo lo puedo enviar el idioma, listo, y voy a hacer una modificación aquí sencilla, acá por ejemplo, fíjate que yo le enviaba el transcripto, que como diccionario, entonces ahora no voy a enviar así, también como diccionario, solo que aquí, déjame ver, acá no enviaba como diccionario, acá transca, pero otra vez como tiene el mismo rol de nuevo, diccionario, copio, transcript y ser románta, entonces ahora cuando yo lo envoque, necesito enviar el transcript, que lo lee de el archivo, pues, que pegen el whisper, y el lenguaje que aquí ya lo puedo cambiar en español, inglés, bueno, ya lo puedo cambiar, ¿no? Es más, en algunos lados lo tengo también como una variable que se recibe como parte del comato, pero listo, ya explicado eso, ya explicado el lance mint, y cómo funcionan los prompts, pues acá, acá fíjate que tú puedes probar como con varios modelos, pero aquí literalmente yo lo estoy diciendo, que ya cuando lo estoy ejecutando, necesito que se será Gp4 Turbo, no trece nada, sino aquí ya soy el que yo toman la decisión, aquí tú puedes, aquí, como que tú puedes probar, como con varios tipos de modelos aquí, pero luego que, luego que simplemente lo llamas, ya puedes aquí encodigo, si decirlo, no, yo quiero no Gp3, sino Gp4 o cualquier otro modelo, pero listo, en dos corramos ahora este comando, entonces si yo lo digo, generalmente el Sumer, entonces va a correr este comando, que Sumer y que le pasa al transcript, que le pasa el transcripto como diccionario, el lenguaje, que esto llama al chain, que al final se conecta con lance mint, que le manda sus parámetros al lance mint, ejecuta ese prompt, bueno, le manda estos parámetros a este prompt, lo ejecuta con el modelo Gp4, y luego obtengo la respuesta, y esa respuesta al final la dejo en un archivo dentro de la carpeta, que se llama Sumer y de punto TXT, me amolo, entonces ejecuta uno, y veamos a ver, ¿qué pasa? Entonces, este debería de monarse un poquito menos, no deberíamos ser tanto como la transcripción, que es tomar un audio de 40 y pasarlo a texto, bailo llama, esperando tener ningún error con el cambio que lo habita diciendo el prompt, no debería, creo que fue un cambio bastante chiquito, entonces listo, aquí está, ahí está, la sumo vi, ¿no? Entonces ahora tengo un archivo que dice Sumer, y este es ya como el resumido de toda la chachara que hablé en ese video, fíjate que aquí podría terar más el prompt, podría terar y decir respetamiento o no respetar, hay o no otros puntos que diría, tengo un poco más literal, ese respeta como la forma en que yo me expresé, aquí podría terar más el prompt de Sumer, pero pues solo si era al antes de ver y terar jugar un poquito con un programa hasta que, pues como que me lea algo que me guste. Listo, entonces acá tengo el Sumer, ¿qué pasa es por el del Sumer, qué hago es por el Sumer, y fíjense que así funciona, o sea, literalmente, la prueba de concepto del de Microsoft es así, te dicen, mira, ve, está la locura de este archivo, escuta esto, como que no es producto, es una prueba de concepto, luego obviamente no puede crear producto con esto, ponerlo en el interfaz gráfico, hacerlo bonito, pero literalmente si ustedes ven, si tú ves el de ellos aquí, pues es código, de por si yo lo tengo, por si es mucho más limpio en varios archivos, ellos tienen todo aquí en una sola cosa, pero me va a hacer mucho en cómo su estilo y cómo lo hicieron y sobre todo en la idea, me parece una idea bastante interesante. Acá yo lo tengo un poquito más dividido con Typer y pues con archivos y con Landsmeet, etcétera. Listo, ya tengo el Sumer, ahora qué hago, normalmente yo utilizo y si entres a mi canal de YouTube, crear en la descripción y eso, o un video enganchante, o digo un título enganchante, normalmente esto sirve o laía sirve para romper la hoja, el papel en blanco, la hoja en blanco, vamos a ver. A que me refiero con esto de la hoja en blanco, normalmente no deberíamos, o desde mi punto de vista, no deberíamos utilizar la idea para que simplemente me llene yo copiar y pegar, sino que me ayuda un poco a romper la hoja en blanco a mí, por ejemplo, tengo tiempo limitado de crear contenido, etcétera, de pensar en qué sería un título enganchante, aunque es labor del creador de contenido, pensar en esas cosas, pero si ya tenemos y ya podemos apoyarnos en eso, pero es apoyarlo, no es simplemente dejarla en la tarea. Entonces, yo ya con el Sumer Y le digo, tengo otro prompt diciendo, le mirá, bastada en el Sumer Y, que es el resumen de lo que dije en mi transcripción, crea un video, crea un título como enganchante, y crea una descripción, y creáme los keywords, como en YouTube, normalmente tienes que poner keywords para posicionar tu video, como las palabras clave, igual que una website que pone keywords, entonces yo le digo un modelo que con base al Sumer Y, pues, digamos que keywords debería poner, qué descripción debería poner, qué título debería poner. De nuevo, yo lo reviso, yo digo, si me gusta, no me gusta, etcétera. Y aquí precisamente en los últimos videos, pues, utilizado esa, ¿no? ¿Cómo desplegar? Por ejemplo, si yo miro la descripción de este video, crea un sitio web, la descripción es un poco lo que me generó este proceso que te vengo mencionando, ¿no? Y lo he estado probando, como en los últimos videos, realmente YouTube no indexa o no se preocupa mucho por la descripción. La descripción es lo menos importante para que un video sea exitoso en YouTube, por si hay muchas cosas radas de, no sé cómo es que realmente un video sea exitoso en YouTube, pero una de ellas es la descripción, no. Entonces, esto es lo que me lo importa, o sea, como que la descripción, no le muete tanto cariño a la descripción. Uno es simplemente mucho cariño, el título del video y el thumbnail, el thumbnail, obviamente si lo hago yo, no hay ninguna idea que lo haga. En el de podcast, ellos sí generan como el, lo que van a compartir al Inquerin, lo generan con un modelo de Dalí, pero yo no, ahí sí tengo como una línea gráfica personal, en el cual tengo como recientemente como una fotitomía, con una expresión, con una tipografía, para generar el thumbnail, el tonto, todavía no lo estoy generando por día, no creo todavía que lo haga, pero sería interesante también probarlo. Pero, se puede, se podría, no lo quiero hacer todavía, pero se podría. Entonces, normalmente aquí lo estoy utilizando para, el título de la descripción, y los kibuts. ¿Cómo es ese? Pues, veámoslo, si ya tengo el sumarí, si ya tengo el sumarí, tengo en todo otro comando, que sería el de YouTube. Entonces aquí recibo el pat otra vez le digo en donde quiero que me deje, fíjate que de nuevo tengo paso todavía muy manuales, pero pues quiero liberar literalmente esta versión, recibir feedback, no ponerla en público precisamente para ver que otras cosas ya uno de poder ir mejorando, ponerle una interfaz en ángulo a él, ponerle ya, desplegarla, etcétera. Pero listo, entonces aquí le digo, mira, corre el comando de YouTube y déjame el resultado, déjame lo en de ir a punto de nuevo. Ok, entonces acá está el YouTube, y acá ya se empieza a volver repetitivo. Ok, con base al sumarí, entonces corre ahora, que fue lo que generamos en el paso anterior, toma el chain de YouTube, en el cual le digo, fíjate que esté recibo al sumarí y recibe el lenguaje, en que lenguaje lo que genera, le estoy diciendo en español. A veces me toca colocar la tamo, porque a veces el modelo me habla como un español de España, como vosotros podéis no sé qué, hoy os recomiendo y yo como, yo no hablo así, o no es el tono, entonces me toca ponerle Spanish de Latinoamérica, no es el Spanish de que piensa que, porque a veces me lo genera como con ese tipo de, y es divertido como la genera, pero como yo no hablo así, pues me toca a veces decirlo, yo es español Latinoamérica, en fin, pero ya lo puedo variar, ya lo puedo manejar, es una variable más. Entonces aquí vamos a ver el chain, y fíjate que otra vez, el chain es algo cortito, le digo, utilizad GpT4, y vamos a ver por ejemplo, cuál es el prompt, creo que ese sí lo tengo un poquito más refinado, espero y si no me toca refinar muchos prompts, pero vamos a ver el de YouTube, el de YouTube, acá está, el de YouTube, vamos a ver, acá tengo, dice, te voy a hacer un experto para generar títulos, descripción y tax de un canal de YouTube, basado en un sumo, el título debería ser atractivo para los usuarios, la descripción debería ser de un parágono, fue escrito en primera persona, y los tax deberían ser escritos, deberían ser separados por cor. Crea un título y descripción, acá tengo la parte de human, esto es el sistema human, entonces, en fin, esto es como funcionar, prompt engine, crea un título, descripción, basado en este lenguaje, y acá tengo un listo, está listo, perfecto, si yo quisiera cambiar algo, no tengo un cambio del código, lo cambio allá, y esto es en la aplicación de deployment, si está aplicación, ya vive en la nube, pues ya no tengo que hacer deployments, si quiero hacer un ajuste en el prompt, lo hago en el speed, y ya, y automáticamente aquí va a llegar, ¿vale? OK, entonces, veamos qué pasa, si yo ahora corras de comanda, ¿qué cuál es la salida de ese comanda? Entonces, ahora corro el de YouTube, ¿vale? Entonces, vamos, con acá, y corramos el de YouTube, va, de nuevo, este proceso no habría ser tan, tan demorado, el proceso más demorado es sacar la transcripción, sobre todo de videos tan largos, y he tratado de morar menos en los videos, realmente, pero no creo que la calidad de va a cortarse, pero sí he tratado de reducir, pero fíjate, aquí ya tengo las tres cosas que le pedí, título, descripción y taxa, aquí por ejemplo, como es manual, como todavía yo lo estoy haciendo muy manual, y todo está quedando como archivos techiste, acá tenemos el otro archivo de YouTube, todo está quedando acá, acá está el título, me dice mira, el título debería ser cómo desplegar aplicaciones en Angular, conserva el server, y ver unir en Google, en Cloud4, guía completa, fíjate que este fue el título, que me sugiere, ¿cuál fue el título que el final yo puse en el video? Vamos a verlo, me da curiosidad, creo que fue este, fue este, cómo es plegada Angular conserva, ¿casi grandir en Cloud4 el tutorial completo? Fíjate que ahí no utilice guía, cambia un pequeño escocito, ¿no? OK, en fin, son ya detalles que uno ya va bien, la descripción está la descripción, está casi que sí la pongo directa, porque YouTube es lo que menos lo importa en la descripción, y luego pongo los taxas, esto sí se pone internamente en una herramienta que uno tiene como creador, para poner como los keywords del video, y me dice que los taxes deberían ser esto, y los pongo, y listo. Entonces aquí me ahorró un poco el proceso de pensar en los tax, o de que realmente uno se se descuda y no pone buenos tax, pero pues ya está en laía, entonces déjenme los taxes, y ya, ¿no? Entonces listo, acá tengo el YouTube, entonces listo, ya tengo la descripción, tengo el título, tengo los tax, voy los suba YouTube listo, ya quedo. Hay algo que si yo hago, que eso sí no lo he podido automatizar, que son los el time-amp, que es como esta forma de como bien cierta parte, poner ciertos títulos, y así aquí en YouTube, aquí en YouTube te los deja como en capítulos, pero eso sí no lo he podido automatizar, tal vez se pueda tal vez no, no sé, eso sí lo hago manual. Entonces este time-amp sí lo hago manual, es decir, sí tengo para generar como estos chapters, literalmente pues toca ver el video, y donde pronto hacer un corte y ponerle un capítulo, no automatizar eso, eso sí me toca hacer el manual. Pero descripción, tax, títulos, sí es parte de esa automatización. OK, listo, ¿qué más hago? Vergostos ya se vuelve literalmente como repetitivo. Entonces aquí, una vez ya genero el, digamos que el, el video en YouTube ya está publicado el YouTube, entonces tengo otro página en Twitter, y tengo otro página en Facebook. El de 3 no me ha funcionado muy bien, realmente casi no lo utilizado, no porque en el 3 yo, veces pongo imágenes y demás, y todavía aquí no imagínen de la imagen, es sobre todo pongo imágenes de código, como mira, en esta parte tú puedes hacer esto. Realmente el de 3 no lo he utilizado, lo tengo aquí, pero no lo he utilizado, y el de Twitter tampoco creo. El que más se utilizo creo que es el del link, pero estos dos todavía creo que me falta refinarlos, investigar porque no me genera, no estoy tan satisfecho con lo que me genera, pues ahí, entonces aquí pongo el video, fíjate que esto es otro, ya le digo mira, cuando general tweet, pues este es el video que necesito que hagas como push, como que, mira este video, y acá sí incluye un poquito más de bandera, de flags, veamos un poco que es eso, vamos a ver el de tweet, el de tweet, entonces mira que me genera el pat para que vaya el auto, me también lo generan bastante al sumo, y fíjate que ya empiezo a utilizar el sumo, entonces la descripción, título y keywords, lo hice en bastante al sumo, el tweet también lo va a generar con base al sumo, pero aquí recibe varias cositas, fíjate que aquí al chain de tweet le envío, cuantas palabras debe durar, 140 que es como el límite, va el default de Twitter, aquí en el estoy hablando, esto me ha ayudado un poquito también a refinarlo, como mi público son desarrolladores anágrulas, o mi público son react developers, o mi, o son note, como que el cambio un poquito de la forma de comunicarse de acuerdo a la audiencia la que ya le estoy hablando, luego le digo el lenguaje, miren que acá tengo latan spanish, el link y el texto, que el texto es de nuevo el sumo, entonces si yo me voy a este, pues aquí encuentro, simplemente lo que venimos haciendo, el GPT4, vamos a ver, YouTube, vamos a ver ese al final, es el que tengo ahí, vamos a ver, y vamos a ver qué tiene ese, ese, soy YouTube, entonces acá, entonces si tengo un poquito, uno más largo, mira, acá tú eres un esporto, un chatboard, chatboard, esporto en Twitter, el generante YouTube consiste, que esté dentro de este elimento de palabras, es efectivo, bueno, no, está dirigido por esta audiencia, por favor no, utilice más palabras de las que te di, utilice hasta, utilice emoji, utilice a la lenguaje, bueno, en fin, aquí ya está el prompt y, y pues en lo general, pues con base a eso, vamos a ver qué pasa, entonces vamos a ver, acá le voy el link, le digo en qué carpeta quiero que me gener el resultado, en qué público quiero que luego, lo tenga, vamos a ver, qué van a ver el tweet, y vamos a ver si es un tweet que me agrae o no, como les devenida diciendo, casi no lo utilizo, porque no me gustó un poco el resultado, a veces sí, a veces no, a veces lo tengo que cambiar mucho, entonces casi que no lo utilizo, porque, pero fíjate acá, me generó un interesante desplegando a Singular con Server Server on the internet, que lo fue explorado, Discovery Com, es Computing, la verdad, no está mal, mira qué, que me generó emojis, me generó aquí, mira el resultado completo, y ahí me puso el link, y luego he puesto algunos hashtags, que es muy popular en Twitter, pone hashtag, esa podría ser bueno, lo que lo utiliza, lo podría mejorar, y podría ser un buen tweet para lanzar ese video, como decir, oigan, tengo un nuevo video, vayan y ver, listos, y vamos con el de Tread, el de Tread vamos a ver, vamos a hacer lo mismo, a ver cómo me generó el Tread, si van y ven, estos prompts los tengo públicos, entonces literalmente si se crearon a cuenta, en l'intensión, pueden ver mis prompts, y pueden ver los prompts de la gente que haya puesto públicos sus prompts, entonces pueden ver muchos prompts, públicos, ustedes están haciendo un prompt para generar conversación, para que, para muchas cosas, pues literalmente van al app, y literalmente, acá, mira código para evaluación, para escribir, para código, para sumarización, hay muchos prompts muy interesantes, entonces uno se puede también, como guiar, a mira cómo hicieron este prompt, o guiarte en los minios, por ejemplo, no, no, no, no, que tengo acá, este es de Tread, o sea, de por si fíjate que haya un interesante también, de lanzes mit, y acá estoy vendiendo más el admin que el que, que otra cosa, pero uno puede hacer fort de un prompt, por ejemplo, este, este es un prompt de un usuario, y me gustó, me gustó bastante como ese prompt, entonces uno lo puede hacer forcas, y como en Giphard, cuando lo puede copiar, y de pronto hacerle una alteración, como quiero hacerle esta mejora, pero puede hacer un forcas, también podría crear uno y copiar, no hay que pegarme, pero está bien hacer un forcas, a saber que yo partí de este usuario, y luego, ya, luego de forquearlo, puedes le dice ciertas iteraciones para que mejorara, ¿no? Y entonces utilizo el mío, pero es un fork de otro usuario, del prompt de este otro usuario. Listo, entonces vamos, creo que acá, acá ya es un méjano del tweet, entonces acá está el número uno, sabías que desplegar, blah, blah, blah, blah, no? Y acá está el tm, número dos, y acá está, este, como les digo, no lo utilizó, tanto porque ahorita estoy haciendo más que el hilo tenga también imagen, y pues entonces me toca hacer que por cada tweet, me gendar una imagen, ahí podría explorar con Dalí, con este putifusion, que compase el texto, me gendar una imagen, pero a veces esos encomandos son líneas muy específicas, entonces no quiero que Dalí las invente, entonces, casi que me da lo mismo a hacerlo yo, porque pues no me va a ayudar mucho. Pero en fin, si ustedes del cierre, si creen que funciona, pues me voy a decir, yo le dije, generalmente un hilo, y acá está el hilo. Y listo, y no vamos por el último, vamos a ponerse por LinkedIn, este sí lo utilizó bastante, en LinkedIn, si se puede como un expandido un poco más, o sea, en LinkedIn, es normal, y no sé si tengo aquí, mi LinkedIn, así por acá lo tengo, es normal que, que uno pueda escribir post largos, no como en Twitter que uno tiene que escribir como un post chiquito, aquí en LinkedIn, se está, es una retocial más para profesionales, entonces uno se puede explicar un poco más, como hablar un poco más y decir, tant, tant, tant, esto por ejemplo, lo generé con, con, pues con esta, flujo que te estoy comentando, pero le cambia varias cosas, hay unas cosas como que, no, no, no, este, el de LinkedIn le pongo un poquito más de amor y cuidado, al de Twitter y al de LinkedIn, a esos post los refino un poquito bastantes, pero sí me ayuda a, no empezar en vacío, ¿no? Como que, el AI me dice, mira, puede ser esto yo, está muy bien, puede ser esto, pero cambe en la aquí, así yo no hablo por aquí, yo diría esto así, tanto han lo público y listo. Entonces, vamos al de LinkedIn, acá de por si tengo más atributos, porque lo está utilizando, creo que no solo para video, no, o sea, no quiero que, promuevas a un video, quiero que promuevas un blog, no, yo estoy lanzando también como mi blog, en nicobite.com, ahí está mi blog, nos escrito mucho, puedas escribir más, pero qué pasa si quiero decir la LinkedIn, oye, promociona en un video, promociona también un post, un blog, promociona un podcast. Entonces, casi que esa variable también da volví un poco, qué es lo que quiero promocionar, y creo que esto era porque, a veces yo quería, pues como es un blog, a veces le pasaba el contexto, ya no es el transcript, el concepto es en sí el texto del, pues, del blog, entonces, él lo pasaba en Mardown, yo escribo esto en Mardown, entonces le pasaba el contexto en Mardown, entonces aquí le paso el contexto, mira, esto está en texto plano, en este caso es un transcripto de un video, en cuanto del digo, esto está en texto plano, o esto va a ser Mardown, porque es un artículo que yo escribi, ¿no? Entonces, le paso a esas variables, ahorita vamos a ver cómo está ese, lo que lo generamos, vamos a ver cómo está ese, y, para nuevo, si un boi y veo el comando, saca hasta el LinkedIn, venía acá está también el, el, el, el, el tweet, el, el, el hilo, pero acá está el LinkedIn, este me gustó un poquito más, entonces, tiene el tipo de contenido, cuantos parafos quiero escribir, por favor también es que lo en, si, de nuevo, lata Spanish, porque a veces lo pone muy español, el Sumari, el formato, el link y el tipo de audiencia, entonces y otra vez, misma historia, simplemente repito la misma operación, y vamos a ver que tiene este plot, de quites link. Entonces, vamos a, parca, siempre se me pierda acá está, donde está la link y de la casa. Entonces, esto también está, este también si lo hice yo, tal vez si ustedes van al, si vamos al, al hop y buscamos un nuevo LinkedIn, allá ya, cosas, ¿no? Bueno, creo que os escribí más LinkedIn, dejarlo ver si os escribí bien, así, venía acá, aparece el mío, y acá hay algo muy interesante, es que se mira como también un tipo de metricas, como cuantos personas han visto este prompt, y este form todavía no tengo muy, bueno, este descargando tengo muy claro que es, y si es, las veces que yo le he hecho pull, como cada vez que lo he llamado para generarlo, fácilmente este puedo ser yo mismo, pero como es público, pues fácilmente puede ser otro usuario, haciendo le pull a mi prompt y ejecutándolo, ¿no? Entonces, no estoy muy claro si son, solo las de los demás, o me incluye también las que yo he hecho. Creo que me incluye las que yo he hecho, entonces, tal vez en las veces que literalmente he alado ese prompt al código. Fíjense que por acá hay otros, el link en Learn, podcast, no sé qué, no hay muchas, miren qué, que más hay, es este de acá. Entonces, yo tengo este, de nuevo, acá está el prompt, la habla, en qué formato, resúmelo y listo de nuevo, entonces, prompt ingenieren, hace esto para maca, los ploras, los ejecutas, los literas, cuando ya lo tengas, lo publicas, y ya lo pueden utilizar, en tu código. El listo, vamos a ver, que me generó el link. Entonces, acá, acá, link de inno, y fíjense que por cada uno de esos comandos me está dejando como un archivito, entonces, acá, acá está el thread, acá está el tweet, acá está el post de link de inno, en teoría. Entonces, básicamente, yo estoy guardando esos, fíjense que lo he hecho como desde acá, lo he hecho con el video de Migration, el video de Whisper, el video de Angular Views, como que lo voy guardando ahí, ¿no? Tal vez esto debería no guardarlo en archivos, techiste, tal vez, pero obviamente debería ser una base de datos, donde ya digo, este contenido, una base de datos, se guarda y se puede, pues, consultar. Ori-tat, de nuevo, es algo que estoy haciendo como de forma muy exploratoria, así que un art techiste, funcionaba bastante. Entonces, acá tengo el link de inno, entonces, aquí me deja de leer chiventas. Estas buscamos a la rendimiento de esta aplicación, entonces, esto es de escribir un artículo más pesado, más pensado para link de in, etc. Espero compártas comentarios, verá, verá. Por ejemplo, este fue una base, que yo utilicé para escribir este, luego ya lo refine, le cambié, verá, verá, pero me sirvió mucho como base para poder escribir el post final. Listo, eso es literalmente, hay otros dos comandos que tengo aquí, pero realmente creo que lo detastan rotos, y estaba probando lo que hacía Microsoft en ese demo, que era como generar imágenes con base también, como el tweet, el texto, estaba probando Dalí, de por si estaba probando este bultifusion para no utilizar, pues, esos, por acá tengo Dalí, entonces uno básicamente llama la API de OpenAya y genera de acuerdo a cierto cosa, o también como una prohibita chiquita que no avanza mucho con este bultifusion, corrar este bultifusion localmente y generar la imágenes. Pero no he avanzado con esos dos comandos. Y acá una lista de cosas como que quería hacer. Eso es, eso es como yo estoy utilizando vía para automatizar generar cierto tipo de contenido. Vime, ¿qué pensamiento esté trae esto? El repositorio está público, lo puedes clonarlo, puedes correr, ya pones tu llave de OpenAya y puedes hacerlo ahora con lo que, con tu contenido, con tu blog, ya sabes cómo utilizar Landsmeet para el Ministro de Prons y no quieres utilizar el Landsmeet, puedes poner el Prons directo en tu código y también ejecutarlo. Pero me parece una idea bastante interesante, bastante válida, que me permite romper como está ojan blanco para escribir como este contenido. Y creo que como el contenido se basan lo que yo dije en un video es bastante fiel a lo que yo diría, en un Twitter lo que yo escribiría. De nuevo, yo no cobri pego, sino normalmente lo revisé un poquito, cambió alguna cosita, ya le pongo un poco más de mestilo, pero eso ha sido más porque me he tenido un poco más de chance de seguir mejorando el Prons. De seguir de Pronto Prons, tus modelos, de seguir probando otras técnicas de Promenginian. Ultimamente están saliendo más técnicas y más modelos para seguir refinando, entonces uno podría utilizar mejores y nuevas técnicas para de pronto ya no tener que hacer tanta refinación. Si no, con base a todas esas instrucciones, con base a mí, a lo que realmente dije en el transcript, puedes que lo haga muy a mi estilo y de pronto que las correcciones no sean mínimas. Sin embargo, las correcciones, yo creo que siempre van a estar presentes, uno debería verificar si lo que voy a publicar, pues tiene sentido con mi marca personal, con lo que yo quiero expresar, etc. Dejame en los comentarios, ¿qué piensas de esto? ¿Qué piensas de este repositorio? ¿Qué piensas de repositorio de Microsoft? ¿Qué piensas de la creación de contenido generada por AI? Te leo en los comentarios, eso es un nuevo bastante interesante. Esta es una prueba de concepto que ya está publicada literalmente. Y te quiero compartir una aplicación que me parece interesante también. Si es que no quede desde pronto, hacer todo en código, pero sé una aplicación que me parece interesante, para que ya genera producto con esto. Esta es la aplicación. Esta es la aplicación. No sé muy bien cómo se pronuncia. Es route, es route, es... En fin, pero me parece una aplicación a la que potencialmente, por ejemplo, si ya tuviera que poner una interfaz gráfica de la aplicación y hacer el backend y toda la aplicación, probablemente te armené como con algo muy similar, a modo de inspiración. Pero me parece muy interesante si tú te lo que has... vas a encontrar aquí como la aplicación, entonces puedes como decirle, mira. Yo aquí, como que... Aquí tiene como una herramienta de AI, entonces también teoria podría como decirle, mira, esta es la transcripción. Aunque realmente no está muy pensada para generar contenido con base a un canal de Github, como el que yo tengo, por ejemplo, aquí. Aquí voy a ponerle mi transcripción. Es más, voy a ponerle su marie que es un poquito más corto y debería estar mejor, pues, creado. Aquí, aquí, vamos más. Y bueno, con... Le pongo y acá tengo como algo para literalmente decir, mira, crea un borrador, quedan, no sé qué. Y yo puedo como que por aquí a mi Instagram, como un poquito como Lensmith, como crear mis propios prompts y decir, como, generalmente un drab, generalmente, como, reiterame este contenido de repropondo de alguna manera para escribir un blog, por ejemplo. Y aquí me dice como la audiencia, digo, pues, esto es para AngularDabs, ¿cuál es el objetivo? Promote Cloudfords, digamos, CloudFords. ¿Cuál es el tono? Informativo, persocibo, digamos, ¿no? Está, el distinto te digo. Creo que perdí el acápelo así. Creo que perdí lo que escribí ahorita. Está AngularDabs, AngularDabs, ahora sí me lo compré, está. Es un tutorial, le un tono persocibo, crea un blog. Y entonces él empieza a escribir, ¿no? Empieces a escribirme como un post en base a ese resumen. Entonces, literalmente, yo podría reutilizar esto. Y entonces, ya publicarlo en mi blog, ¿no? Entonces, como que yo poner acá y decir, con base al sumario a la transcripción. Entonces, ya tengo un post nuevo para escribirme un artículo nuevo en mi blog. Entonces, acá, más trainings are worth rendering in CloudFront, y ya puedo ponerle cositas otra vez puedo iterar, ¿no? Como esta cosita sí, esta cosita no. Fíjate que acáme lo escribió. O sea, yo le pase en español, pero el me genera tuve en inglés. Aquí si tiene una debilidad que no, o sea, el idioma no es parte como de los argumentos, los parámetros, entonces todo me lo genera en inglés. ¿Por qué puedes hacer una aplicación gringa? Entonces, pues está más pensado todavía para ese mercado. Pero, entonces, uno acá le puedo poner esos parámetros y tan, ¿no? Y luego, ¿ya qué? De por si lo es pensando en vos, estoy pensando en vos alta, básicamente. Voy a acoger esto de acá y tomar esto de este Japón. Mejorarle, cambiarle, ponerle algunos ejemplos de código, como por ejemplo aquí, que ya, entonces, hay ejemplos como de código. Imagines, ¿no? Y hay un ejemplo de código, blah, blah, blah. Y ya tengo un post o tengo otra vez una ayuda para escribir ya el post para que me ayude en mi blog personal. Entonces, ¿fíjense que es muy parecido por eso me gustaba mucha su aplicación? Porque como que tiene un poco de lo que yo esperaría, por ejemplo, si le pusiera fronana mi aplicación, como aquí es cojo, le digo que cada una de esas variables, es que me puse, es que me puse para LinkedIn, es que me puse para Twitter, en que tono, la habla y puse publicas. Eso es lo que te quería compartir este herramienta. Y listo, eso ha sido todo por este video de nuevo. Quiero learte en los comentarios que te parece que te parece a forma de usar y a para generar contenido. Te leo o sin fácil de reutilizar este herramienta que te compartí también para generar cosas o el código directamente o el transmit para fracidamente administrar prompts. Entonces, te lo dejo ahí. Así que compártelo, darle likes, me ha llegado un montón que se suscriban, que lo compartan, que literalmente pueden mandárselo a ya no sólo de pronto, a desarrollarse, quieren empezar a utilizar esto como parte de creación de contenido. Hoy imagínense, literalmente, una empresa de marketing que, quiere empezar a generar ciertas automatizaciones, pero que leía, me ayude a automatizar estos procesos y a ahorrar cierto tiempo. No sé, hay un montón de casos de uso también, si ven un caso de uso como, mira que esto se puede utilizar para esto, los de los comentarios. Nos vemos en la próxima. Chao.