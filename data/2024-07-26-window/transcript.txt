 Google Chrome quiere integrar inteligencia artificial directamente desde el navegador y recientemente está explorando una nueva API para tener un LLM con el cual podamos interactuar sin necesidad de un servidor, sin necesidad de una API, sino ya está integrada como una API en el navegador. Así que vamos a explorar esta API y de qué trata. Se trata de Windows.ai que fue expuesta por Google Chrome en este documento que te lo bajaré en los enlaces de la descripción. Entonces, básicamente aquí están proponiendo lanzar, y esto lo hablaron en el IA del 24, en donde proponen tener un LLM directamente en el navegador. Realmente todavía no está hábil en los navegadores, vamos a ver que hay unos pasos para poderlo habilitar, pero aquí antes de entrar como a las restricciones vamos a ver un demo sencillo. Esto es básicamente la API Windows.ai. Esta sería la API en la cual yo puedo crear una sesión para interactuar con ese LLM y luego puedo presentar. Y luego puedo pedirle como, hey, escriba un poema y él me entrega el resultado. Este es el nuevo namespace o objeto que estaría disponible en el navegador. Veamos por ejemplo si hacemos esto en un navegador en Chrome normal, ¿qué nos responde? Si abrimos aquí una pestaña, por ejemplo, vamos a inspeccionar aquí y voy a darle mucho zoom. Bueno, creo que ya es demasiado zoom. Y de Windows.ai, pues básicamente esta API no existe, todavía no está hábil en todo Google Chrome. Necesitamos de algunos pasos instalar una versión de la API. Y de aquí vamos a ver que está bien. Vamos a ver que está bien. Vamos a ver que está bien. Vamos a ver que está bien. Vamos a ver que está bien. Vamos a ver que está bien. Y de acá vamos a ver que está bien. Entonces ya está. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Por ahora voy a hacer como la configuración, hay que instalar Google Chrome Dev y hacer ciertos pasos para habilitar esa AI y luego interactuar con esa API. Pero si quieres ver simplemente cómo funciona, te puedes saltar la parte de configuración. Aquí ya descargué Google Chrome, entonces simplemente está haciendo el paso de instalación. Recuerda que no es el Google Chrome normal, sino el especial para desarrolladores o el Canary, en el cual vamos a poder activar esta nueva API. Entonces simplemente seguir los procesos de instalación. Una vez tengas ya la instalación, vamos a digitar y abrir esto en nuestra ventana de Google Chrome. Entonces vamos a ir por acá, voy a copiar esto, voy a abrir Google Chrome Dev. Ahí está Google Chrome Dev. Pegamos esa, digamos, URL, es más, voy a pegar este doc aquí para tenerlo como más rápido. Aunque normalmente nos va a tocar reiniciarlo varias veces. Acá, listo. Tenemos este Enable Optimization Guide on Device. Ok, entonces aquí vamos a ver qué nos toca hacer en el setup. Básicamente nos toca hacer... Hacer que esto esté con esta opción, Bypass Per Requirement. Entonces vamos a decirle que esté en esa opción. Fíjate que acá él mismo nos dice que nos toca hacer un Relaunch. Entonces vamos a relanzarlo. Y listo, ya quedó habilitado. Perfecto, ahora nos toca ir a esta otra flag. Entonces vamos a ir por acá y vamos a asegurarnos de que eso esté Enable. A ver, déjame lo cargo otra vez. Ahí está. Dice Prom API for Gemini Nano. Ok, perfecto. Hacemos Enable y hacemos otra vez el Relaunch. Perfecto. Luego nos toca decir que si podemos, o sea, tenemos que confirmar si Gemini Nano está disponible. Y fíjate que aquí ya empieza a ocurrir algo interesante. Que si yo ya voy a una pestaña y abro la consola. Vamos a ir por acá, vamos a hacerle un poquito más de zoom. Abro la consola y doy Windows. Bueno, este como es el navegador nuevo, entonces me toca decirle que permite... Pues, pegar, copiar y pegar aquí en la consola. Y aquí si hago Windows.ai, fíjate que ya tengo algo. Ya tengo una API con la cual puedo interactuar. Algunos métodos con los cuales puedo interactuar. Cosa que si yo hago en mi Google Chrome normal, el de toda la vida, pues no existe. Esto está en Undefined. Porque solo está todavía disponible y lo acabamos de habilitar en el Google Chrome. Sin embargo, en el Google Chrome Dev. Sin embargo, este no es todos los pasos que nos toca hacer. Fíjate que por acá nos dicen... Vamos a ir por acá. Acá. Nos dicen que necesitaríamos ejecutar esta línea para saber si ya está disponible. Porque una cosa es habilitar la API, otra cosa es descargar el modelo que se necesita para esta API. Entonces para eso vamos a correr CanCreateTextSession. Entonces vamos a ir por acá. Vamos a limpiar aquí la consola y vamos a ejecutarlo. Fíjate que acá nos dice que no, que el modelo no está hábil. La API, la Prom API ya está hábil, pero el modelo todavía no está. ¿Qué nos hace falta? Lo que nos haría falta es que esto nos tiene que contestar Rudele. En donde nos dice que listo, que ya el modelo está listo y disponible para crear sesiones, para preguntar. Pero si todavía nos dice que no, que no está listo, nosotros necesitamos ir a Chrome Components. Entonces vamos a ir a Chrome Components. Vamos a hacerlo por acá. Chrome Components. Y vamos a ver que por acá deberíamos buscar... Esta línea. Vamos a buscar. Fíjate que no nos aparece. Creo que nos toca hacer un relaunch. Entonces vamos a... Voy a copiar esta URL y vamos a quitar Chrome. Y vamos a volverlo a lanzar. Vamos a ver si ya nos aparece. Fíjate que todavía no nos aparece. Y aquí de por sí hay una... Como una forma en donde forzar a reconocer la API. Vamos a verla. Entonces aquí, por ejemplo, vamos a decirle... Este create session. Vamos a forzar para ver si ya nos aparece la sesión. Vamos a ir acá a inspeccionar. Y esto probablemente nos dé un error. La sesión no puede ser creada. Perfecto. Pero quiero ver si ya nos aparece aquí el modelo. Voy a hacer un relaunch otra vez. Haciendo el relaunch. Vamos a ver. Haciendo ya el relaunch. Fíjate que acá ya nos dice que hay una... Optimización. Bueno, aquí ya nos permite descargar el modelo. Entonces le voy a decir que check for update. Acá podemos ver aquí con un zoom. Que ya nos aparece esta opción. Entonces cuando nos aparezca esta opción. Simplemente le damos check for update. Y él básicamente va a descargar Gemma Nano. A través de configurarlo y dejarlo configurado dentro de Google Chrome for Devs. Y luego ya podríamos interactuar con esta API. Una vez pases esa configuración. Ya deberías entonces tener este name space. Con el punto AI. Es decir, ya tenemos disponible la API. Y también descargamos el modelo que sería Gemma Nano. Para que esté integrado aquí a través de Google Chrome. Normalmente esos pasos de configuración. Ya deberíamos ahorrarlos. Cuando ya lo lancen a todo el público. Pero por ahora hay que hacer unos pasillos. Pero básicamente ya podemos tenerlo. Por ejemplo aquí me aseguré de tener este name space. Pero también podríamos correr este método. Para asegurarnos. Uno es para ver si el name space ya está dentro del navegador. Y otro es para ver si ya el modelo. Está descargado. Está listo para empezar a hacerle preguntas. Google Chrome precisamente lo que quiere. Es que esta API esté integrada directamente en el navegador. Y no tengas que hacer un backend. O preocuparte por disponibilizar un modelo. Sino directamente aquí desde el navegador. Podrías interactuar con JavaScript. Y un LLM. Esto se volvería como básicamente una de estas APIs. Que nosotros ya somos muy frecuentes en utilizar. Por ejemplo aquí tenemos. Navigator.Geolocalization. Por ejemplo. Vamos a hacer. Geolocalization. Ahí está. Y por ejemplo podemos obtener la posición del usuario. Esta es una API. Que ya está disponible. Que normalmente cualquier desarrollador de JavaScript. Sabe que está disponible. Y puede obtener la posición. Latitud y longitud del usuario. A través de esta API. Y eso es lo que quiere hacer Google. Con esta nueva. Este nuevo name space. Con Windows.AI. Entonces ahora podríamos tener un LLM. Con el cual vamos a poder interactuar directamente. Con JavaScript. Y por ende dentro de nuestra. Desarrollo. Una de las ventajas de esto es. On device. Correr un modelo on device. Que vamos a hablar un poco. A ver de qué trata esto. Google está queriendo que estos modelos corran on device. Qué significa esto. Que literalmente el modelo está. Lo más cerca al usuario posible. O al dispositivo. En este caso está directamente en Google Chrome. Y no tienes que ir al cloud. A la nube precisamente. A la nube. A la nube. A la nube. Precisamente a enviar tu request. A enviar tu prompt. A enviar tu texto. Sino todo está ocurriendo directamente on device. En este caso directamente en el navegador. También Google está queriendo llevar esto directamente a su sistema operativo. Como Android. Que directamente en Android. Tenga también un LLM ya integrado. Para poder en aplicaciones. Como tal en Android. Podamos también consumir ese modelo. Ahora en la web lo está llevando a través de Google Chrome. Que dentro de Google Chrome. Ya haya este modelo. Y podamos interactuar directamente con él. Y así. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Vamos a ver. Esto tiene algunas ventajas. Como por ejemplo la privacidad. Porque al final en nuestra chat. Nuestra información. No se está yendo a la nube. Simplemente estamos interactuando con algo. Que está dentro del dispositivo. Puede funcionar offline por ejemplo. En algunos puntos con aplicaciones web progresivas. Por ejemplo podría como ya está instalado en el navegador. Podríamos darle cierta privacidad. Y funcionar de forma offline. Y pues hay. Pues al final. porque no tienes que esperar a una respuesta de un emboite sino que la respuesta es casi inmediata porque ya está ahí el modelo así que después de como verlo interactuar un poquito con él vamos a probar cómo se crea una sesión aquí de chat una conversación y ver cómo funciona esta API para eso me voy a abrir un html sencillo aquí básicamente es un html que luego voy a ejecutar en ese navegador y voy a tener aquí pues un script entonces aquí necesito de por sí lo que quiero hacer es ejecutar esas líneas de código voy a poner aquí un await un poco las líneas que vimos de por sí aquí para poder interactuar con él entonces primero voy a ver si se puede crear o no una sesión de chat entonces podría hacerlo pues podría ejecutar esta línea y también lo que voy a hacer es que voy a crear una sesión de chat voy a hacer es bueno acá por ejemplo ya nos dan un if que si es más copiaron literalmente está este ejemplo de ahí vamos a ponerlo por acá listo entonces si es diferente a no entonces pues significa que ya puedo acceder que si se puede crear una sesión de chat es aquí literalmente se crea esa sesión de chat y luego literalmente yo ya puedo empezar con esta sesión creada empezar a interactuar con él y decir oye mira escriben un poema y luego aquí obtenemos el resultado entonces vamos a ejecutar esto algo que de pronto vamos a tener aquí es que esto tiene que correr en un contexto asíncrono y este script de html por defecto no lo hace entonces vamos a crear una función anónima que se ejecuta sola entonces vamos a tener un contexto a saint por acá y vamos a ponerlo por acá esto esto lo vamos a poner en este contexto como asíncrono para que podamos utilizar el agua y luego ejecutamos como este contexto si yo corro estoy en el chrome de pues debería funcionar y aquí debería tener un resultado con un poema aquí tenemos el archivo entonces como no estoy utilizando ningún framework ni empaquetado de nada es html y ya y javascript vamos a abrirlo aquí directamente en el google chrome de vamos a abrirlo vamos a ver aquí inspeccionar aquí por ejemplo no tenemos allí nada por acá nos dice que la sesión no pudo ser creada nos da un error por otro lado por acá nos dice que no pudo ser creada nos da un error por eso es porque se İxăz alăuis anălăuşimă acá, hagámoslo en reload, eso, aquí le dicen reload, vamos a esperar, por ejemplo aquí no hay nada, pero seguramente como es un asíncrono, está como procesando y escribiendo el poema, luego tendríamos que meter un load y algo así ya más en la interfaz, pero fíjate que aquí literalmente nos dice listo, aquí tienes un poema y pues literalmente nos dio un poema en la consola y esto es interactuar con Gemma Nano, una de las versiones de Gemini dentro de Google Chrome, directamente instalado y puesto en un API desde el navegador, pero vamos a jugar un poquito más con esto, voy aquí a crear un HTML básico y por aquí por ejemplo voy a ponerle un h1 con el estado, aquí de por sí voy a poner un id y le voy a poner esto, va a ser status, luego voy a poner un textarea, aquí, aquí le voy a poner message y digamos que acá voy a tener un párrafo con la respuesta del llm y por aquí le voy a poner response, listo, esto va a ser como mi marca, entonces aquí estoy interactuando de forma como directa, voy a crear estas variables para estos elementos, entonces aquí voy a ponerle h1 element y listo, ya me autocompletó, vamos a poner ahora el textarea element, ahí también ya me autocompletó para poder obtenerlo, fíjate que al final, es un get element by id y listo y ahora voy a poner el p element, listo, ahí está, entonces ya tengo la referencia a mis tres elementos que están en el html directamente con el javascript y lo que voy a hacer es como empezar a interactuar con este llm, listo, entonces lo primero que voy a hacer es ver en el h1 si está disponible o no, entonces por ejemplo aquí le voy a obtener el, este response, bueno, déjamelo como can create, una vez esté como can create, lo que voy a hacer es poner en el h1, listo, entonces aquí voy a ponerle h1 element, un inner, un inner text, sí, un inner text va a funcionar y simplemente voy a utilizar un pop, poner ahí la respuesta directamente, entonces vamos a poner aquí, entonces aquí con un backtick voy a poner precisamente en ese que sí puede ser creada y la respuesta para pues ver en algún momento si eso está listo o no, aquí literalmente pues estamos creando la sesión, acá está el prompt, entonces en ese momento lo que yo debería hacer, entonces listo, voy a crear una sesión como global, aquí voy a tener un let session, session ai, voy a ponerle, por el momento inicializa en nulo y una vez tenida la sesión, entonces simplemente voy a pues reutilizar esa variable session ai, listo, el resultado y todo lo que es el prompt vamos a ponerlo directamente como un listener del textarea, acá entonces voy a poner el textarea element y voy a agregar un listener, en este caso voy a poner el listener, el de presionar una tecla, porque quiero que cada vez que haya como un enter, entonces pues pueda yo ejecutar algo, se vaya como esa pregunta a el lm, listo, entonces vamos a ponerlo por acá, vamos a ponerlo por acá, perfecto, listo, entonces vamos a ver acá, entonces aquí cada vez que escriba algo, de por si aquí ya me autocompleta algo, dice si la sesión ai, pues si esto está disponible, entonces voy a enviarlo, entonces voy a enviarlo, ahora realmente este envío, no es de esa manera, vamos a poner aquí el message, entonces el message viene de lo que es el textarea value, entonces si, básicamente ahí es donde ponemos session ai.prompt, vamos a ponerle prompt y listo, y ponemos el mensaje, entonces yo le digo, oye, escríbeme un poema, pues me va a escribir el poema, esto debe ocurrir en un contexto asíncrono, porque a esto le tengo que hacer await y esto sería la respuesta, no? response, luego vamos a probar un poco más con qué tipo de prompt le podemos poner allí, pero una vez tenía la respuesta, pues básicamente pongo el element y lo mando literalmente en nuestro párrafo, no? que está acá, sin embargo yo quiero que esto solo se ejecute si realmente pues el usuario le dio enter, entonces voy a poner aquí is enter key, voy a poner acá, si la tecla que le dio es enter, entonces vamos a ver aquí, acá deberíamos tener un evento y si el evento, vamos a ver, si el evento es la tecla enter, pues deberíamos enviar eso y si existe una sesión, pues deberíamos enviarlo, entonces es más, aquí voy a hacer un console.log de lo que estamos enviando, respondiendo esto a la IA y ponemos el mensaje, entonces vamos a ver si toda esta interacción nos funciona, listo, aquí ya estamos como con un h1, nos dice que literalmente se puede crear la sesión, entonces aquí tenemos un test, entonces aquí tenemos un test, entonces aquí tenemos un test, entonces lo voy a poner, hola, cómo estás? y si le doy enter, listo, nos dice que eso fue enviado y acá nos contesta, literalmente nos está contestando el LLM, entonces aquí ya literalmente estamos interactuando con él, le puedo preguntar si tiene un nombre, cómo te llamas? me llamo Google Assistant, supuestamente dice, me imagino que como es entrenado por Google, pues tiene como contexto de cosas de Google, voy a preguntarle algo, le voy a preguntar algo, vamos a ver, la capital de Colombia es Bogotá, vamos a ver por ejemplo la de Bolivia, ahí hay un truquito con la de Bolivia, porque la mayoría piensa que es La Paz, pero en teoría es Sucre, vamos a ver qué nos dice, ahí está, la capital de Bolivia es Sucre, entonces la inteligencia artificial sabe que es incorrecto lo que nos han enseñado en el colegio, donde nos decían que es La Paz y nos dice que es Sucre, pero literalmente, literalmente, literalmente, estamos interactuando con un modelo de IA integrado en el navegador. Ahora, solo por ponerlo más bonito, porque no me gusta un poco ese test area, voy a integrar Pico CCS, que es un minimal framework CCS, que simplemente utiliza como el HTML semántico para poner un estilo por defecto. Entonces voy a poner este estilo, solo porque no me gusta como se ve así de feo. Entonces vamos a ponerlo por acá, lo llevo aquí. Y simplemente nos va a dar un estilo como por defecto. Fíjate, acá nos dio ya como algo más leíble, de por si tiene una clase que se llama container, solo para poder leer mejor. Vamos a refrescar. Listo. Entonces fíjate, hola de nuevo. Hola, ¿cómo estás? Ahí está. Hola, ¿cómo estás? Me preguntó otra vez lo mismo. Esto está un poquito raro, pero vamos a ir viendo precisamente algunas mejoras de Prompt. Y veamos un poco la documentación. Depende de cómo Google nos dice que deberíamos empezar a hacer Prompting a este modelo. Si nosotros vamos aquí a la sesión, si nosotros vamos a la sesión, fíjate que él también tiene una forma de hacer Prompt Streaming, que es esto como que te va escribiendo y te va escribiendo y te va como autocompletándolo. Es más, probémoslo a ver cómo funciona. Voy a copiarme esta línea. Nos dice que tendríamos que hacer un for await y ir reescribiéndolo. Vamos a hacerlo directamente en el código. Entonces en vez de esperar como por... En la await de aquí y poner el texto, vamos a ir streameando la respuesta. Entonces acá está. Acá tengo el stream. En vez de poner... Acá sería el Prompt que yo le escribo. Entonces vamos a ponerle un message, el message del usuario. Este response ya no lo utilizaría. Hacemos una await y lo que hacemos es que acá está el chunk, ¿verdad? Entonces aquí en teoría deberíamos poder reescribir ese inner text a medida que nos va enviando la respuesta. Vamos a ver cómo funciona. Entonces, estando aquí, vamos a decirle escribe, escríbeme un poema largo. Largo. Vamos a ver si funciona. Aquí tengo un error de session is not final y tiene razón porque mi variable de sesión se llama session ai. Listo. Vamos a recargar y escribe un poema largo. Vamos a ver. Ja, por acá hay algo. Tengo un error. Vamos a corregirlo. Y de nuevo aquí tengo un error porque puse response y es chunk. Listo. Entonces vamos a ir acá. Vamos a recargar y de nuevo escribe un poema largo. Y ahí está. Entonces me está autocompletando y me está escribiendo en automático. Entonces ahora dime información de Colombia. A ver. Acá está. Geografía. Fíjate. Por acá de por sí me empieza a enviar en Markdown, que es como un texto para poder luego transformarlo en HTML, aunque aquí como que se se se pausó un poquito. A ver, información de Bolivia. Ahí está. Bolivia es un país bla bla bla bla bla. Que es Angular para web. Vamos a ver si sabe el contexto de lo que es Angular. Angular es un importante framework. Es un programa de desarrollo de web creado por Google que facilita la creación, etc. Entonces allí literalmente estamos directamente interactuando con ella y directamente en el navegador. Aquí realmente en este documento que ya lo puedes mirar un poco más con calma y ver de qué trata esta API. Acá nos dan varias opciones de la sesión. Por ejemplo, cuál es la temperatura? Normalmente un modelo tiene hiperparámetros. La temperatura es qué tan creativo quiero básicamente que sea. Si quiero que sea muy serio porque por lo tanto yo tengo un programas que necesito que no alucine tanto, que no invente tanto, entonces podría tener una temperatura en cero, pero si quiero que sea súper creativo e invente y haga cosas, pues puedo empezar a subir la temperatura, etc. Son como hiperparámetros que uno le puede tener a ese modelo. También podemos terminar la sesión. Fíjate que está session destroy en donde yo ya puedo destruir la sesión con la que estoy hablando y aquí ya hay como algunas cosas más de prompting en donde me dice bueno, qué cosas hacer y no hacer por acá, por ejemplo. Y acá. Si entonces uno me dice qué cosas hacer y qué cosas no hacer. Por ejemplo, yo puedo ponerle literalmente poner contextos dentro del texto en donde lo finalizo como con este control 123, que es como un stop o una forma de decirle a este modelo que esto es una como un set o un conjunto aparte. Entonces aquí literalmente tenemos future prom y acá tenemos un buen shot, pero este será un guayón prom que es simplemente como un prom de ejemplo para. Señale un poco al modelo cómo responder y acá tenemos varios. O sea, aquí no hay solo uno, sino tenemos varios. Ahora, de qué trata esto? Pues literalmente este modelo de lo que yo he probado no es muy bien, no es muy bueno siguiendo como un hilo conversacional, como pero sí es muy bueno respondiendo preguntas exactas como listo, cuál es la capital de Colombia, cuál es dando la información exacta, pero recuerda que entonces puedes meterle un contexto o puedes guiarlo. Por ejemplo, vamos a hacer lo siguiente. Aquí voy a insertar un prom que ya tengo un poco preparado simplemente para no escribirlo todo desde cero, entonces acá tú eres un asistente muy útil, que tu nombre es Nico Bot y tú ayudas a responder las preguntas del usuario. Y le digo mira, el usuario respondió tal no inyecta. Entonces es el prom que yo le voy a escribir y uno precisamente puede hacer un poco de prom en general y decirle mira, comporta de esta manera que tienes que responder en este de esta forma. Este es tu nombre, etcétera. Entonces fíjate que acá ya le puse un poquito de prompting y vamos a ver cómo se comporta. Entonces, por ejemplo, si yo le pregunto, es más, si yo fíjate que todavía no le he enviado este prom, le estoy enviando el mensaje directo. Les voy a poner cómo te llamas. Todavía no le he enviado mi prom, pero quiero probar antes y después. Me dice que se llama Google Assistant, pero si esta vez yo ya no le envío el mensaje directo del usuario, sino que le pongo una guía al prom y luego si inserto el mensaje del usuario, vamos a ver cómo se comporta, vamos a recargar y le digo otra vez cómo te llamas. Acá está. Hola, yo me llamo Nico. Entonces yo ya aquí le dije por prompting cómo es su nombre, cómo un poco debe comportarse, que debe responder de cierta manera y en teoría yo le puedo insertar contexto, por ejemplo, vamos a ver el siguiente ejemplo. Si yo le pregunto en este momento. Quién? Quién es Luis? Quién es Luis? Vamos a ver. Luis es un nombre que es correcto. Luis es un nombre, pero vamos a pasarle contexto. Digamos que yo tengo aquí algún texto de algún fundador. Por ejemplo, sé que hace poco fui a Tarija en Bolivia y el fundador de eso aparentemente es pues un Luis. Vamos a poner Tarija Bolivia. Vamos a ir a Wikipedia. Vamos a ver. Vamos a ver. Vamos a ir a Wikipedia. Y por acá Tarija es fundada por mentiras, por Sam Verdano existe. En fin, digamos que tenemos este contexto, no? Entonces tenemos ese texto que lo voy a copiar por acá como si fuera parte de un párrafo y lo copio por acá. Sin embargo, este texto lo voy a poner aquí como un ID. Voy a ponerlo como context y pues le voy a crear su variable para obtener el elemento, el párrafo de allí. Entonces context element. Y le digo que va a preguntar por el contexto. Ok, entonces de acuerdo a ese párrafo quiero insertarle un contexto. Entonces acá le digo mira, es más, creo que de una vez lo voy a obtener aquí dentro de la constante context ahí está el inner text. Ese contexto lo voy a poner acá. Tú eres un asistente que se llama Nick Gómez y tú estás ayudando al usuario a responder una pregunta. Quizás ha de ponerle dos puntadas, ¿no? Óxido las otras cinco. En fin, mejor disponibles aquí sobre todo las que no se les pareceś a utilizar. Es así. Ok, voy a hacer el 우리는 de las más pequeñas. Si me parece no es tan muy rápido. Si no me Luz, por ejemplo. Jeinner de Poder, dehabilitan muchas multas de la sameasa. Este uno es la queength las más pequeñas. Entonces esta es una Brendan Hangett. Entonces son не un más que trauda y esto es un reloj que no puedo utilizar, le voy aיבank a este de aquí a King David March Entonces una pregunta basada en el siguiente texto, ok, entonces fíjate que acá el prompt ya es diferente, es más, si imprimimos el prompt, console.log y pues imprimo el prompt, vamos a ver cómo realmente se está yendo eso a el método prompt streaming, entonces vamos a preguntar de nuevo. Listo, entonces vamos a probar, entonces aquí tengo el texto, dice Tarija es una ciudad con el nombre, ah mira, San Bernando no es el nombre quien lo fundó, sino como su primer nombre, San Bernando es el nombre, digamos, entonces voy a ponerle, ¿quién es San Bernando? Voy a ponerle, ¿quién es San Bernando? Es el nombre de la ciudad con la que Tarija fue fundada, entonces fíjate y acá estoy viendo cómo se está yendo ese prompt, digamos, acá tú eres un dadadán, tú eres y este está el contexto. Y aquí le inserté el contexto y luego le dije pues responda al, el prompt le dice como la pregunta del usuario es este, entonces él responde en ese contexto, si no tuviera ese contexto, pues simplemente él dice San Bernando, no sé, es un nombre, es algo X, pero aquí yo le puse un contexto al prompt. Con esta API se abren nuevas formas de interactuar con la AI directamente dentro de nuestro JavaScript o dentro de nuestras aplicaciones web, fíjate que le pusimos un contexto, le puedo preguntar cosas precisas. En lo que. He probado con él de nuevo, no es muy bueno como siguiendo un hilo conversacional, yo creo que se lo van a ir puliendo y ahorita vamos a ver un poco de APIs futuras de cómo están manipulando o cómo están pensando, por ejemplo, pues cargarlo de algún historial precisamente para seguir un flujo conversacional, pero por ahora en lo que he probado es muy bueno contestando directamente preguntas. Entonces, fíjate, analiza como contextos o features que le podemos meter a las aplicaciones en donde, no sé, yo subrayo un texto y con un clic secundario le digo tradúceme, resúmeme. Algo muy puntual que está ahí ya podría ser directamente en local sin latencia con la privacidad de los datos de los usuarios porque no está yendo a ninguna nube, simplemente creo la sesión con esta API y él responde, yo le puedo poner un contexto y si era mira el texto subrayado por el usuario transcríbelo o reformó o reformulado o redacta mejor este texto. En fin, puedo empezar a tener features de ese tipo en donde, por ejemplo, los text areas les puedo poner un botón y decir oye, quieres que te reescriba esto? Oye, aquí tienes un error gramatical, etcétera, como que puedo empezar a tener ciertas features directamente y nativamente dentro de mi aplicación y teniendo hasta ella ayudando al usuario en varias tareas. Ahora veamos un poco de cómo esta API también quieren empezar a ponerle un sentido más conversacional. Veamos un preview de esa API. Parte también de esa exploración de esta API es que nosotros podamos tener un system prompt, que es un poco lo que nos tienen acostumbrados algunos LLM, que es decir, oye, este es el prompt del usuario. Del sistema digo en cómo se debe comportar. Entonces uno al momento de crear la sesión y no solo hacerlo como por inyectar cosas en el prompt, sino directamente en crear la sesión. Le digo mira, esto se debe comportar de esta manera o por ejemplo ya insertar un contexto más conversacional. Por ejemplo, una conversación que haya tenido el usuario y decirle insertarle como todos unos initial prompts con unos roles en donde le digo mira, tú eres el rol del sistema. El usuario antes contestó esto y luego tú respondiste esto, que sería como. Un poco de few shots examples para el prompt y decirle mira, así hemos venido llevando la conversación, entonces responde. Normalmente esto también se puede ser muy útil para pues ya para conversaciones en donde yo le digo oye, mi nombre es tal y estoy en tal ciudad y necesito X ayuda. Entonces le inyecto el contexto de no sé mi texto de lo que yo quiera ya insertarle. Normalmente ya hay técnicas para inyectar este tipo de contexto a los prompts. Y allí literalmente ya el bot. Y aquí ya respondiendo con base a ese contexto y también con base al historial. Entonces este es también una de esas preliminares cosas que se están trabajando, que se están proponiendo para este IP ahí y que todavía están como en desarrollo. Recuerda que este IP ahí todavía está en preview, no está todavía hábil y es precisamente lo que te quería mostrar cómo Google está planteando esta nueva API dentro de Chrome para JavaScript y listo. Esta es la forma en que Google está proponiendo integrar AI on device directamente en sus plataformas en Android. En Google. En Google. En Google Chrome. Y aquí lo único que me preocupa es un poco la interoperabilidad. Es decir, otra vez podríamos estar en algunas épocas en donde los cada navegador estaba trabajando como en su propia API y luego pues habría que empezar a hacer como preguntas de si esa API está hábil o no en el navegador. Porque al final nosotros como desarrolladores web no sólo desarrollador son sólo desplegamos o queremos que nuestros usuarios utilicen Google Chrome. Si bien es el navegador más usado, pues puede haber un usuario que esté en Firefox. En Safari. Y esta API no tendría sentido. No va a correr porque precisamente sólo corre dentro del contexto de Google Chrome. Entonces aquí perdemos un poco de interoperabilidad, pero es bastante interesante. Te escuchan los comentarios de nuevo. Esto está en preview apenas. No sé si en algún momento como las otras APIs geolocalización, battery, etcétera. Todas las otras APIs los navegadores se pongan de acuerdo y todos tengan un AI integrado. No sé si eso vaya a pasar, pero al menos es este primer paso del Google Chrome de tenerlo integrado. Así que te escuchan los comentarios. Recuerda suscribirte al canal, compártelo y nos vemos hasta la próxima.