 ¿Por qué los agentes son tan importantes en este momento? ¿Y por qué está causando tanto interés en el ecosistema de inteligencia artificial? Realmente el 2025 se está denominando como la era de los agentes, pero ¿qué es esto? ¿Cómo nosotros podemos empezar a desarrollar nuestro sistema de agentes? ¿Y qué significa un agente? Realmente cada compañía, cada empresa, cada framework tiene como una definición, o sea, como que cada quien tiene su propia definición. Entonces hoy quiero precisamente primero, antes de empezar a echar código y crear nuestros propios agentes en Python, vamos a definir qué es un agente, qué características deben tener estos sistemas y cómo vamos a lograr crearlos. Así que empecemos. El 2025 se va a considerar como el año de los agentes, en el cual vamos a tener sistemas mucho más sofisticados, basados en la language models, pero aún así mucho más sofisticados. Ahora, ¿cómo podríamos definir un agente? Por ejemplo, si yo me voy a la definición de un agente, por ejemplo, lo que dice el Lanchen acerca de un agente, dice que un agente de inteligencia artificial es un sistema que usa un large language model para definir su flujo. Y eso es bastante interesante porque los agentes no son como la programación tradicional, como que yo tengo un montón de if o un montón de instrucciones y siguen una secuencia de pasos, sino que normalmente el agente tiene una serie de tools, herramientas, como de directivas, pero él mismo y con base a su conocimiento y con base a lo que uno más o menos lo haya programado, él empieza a tomar decisiones de cómo desarrollar una tarea en específico. Normalmente un agente lo que uno lo podría como encapsular es algo que yo le puedo dar una tarea y él la cumple. ¿Cómo? Pues obviamente uno le tiene que dar las herramientas y muchas cosas, pero normalmente eso es transparente para el usuario. Digamos, si yo creo un agente para crear post en redes sociales, su tarea es, no sé. Ir, ver de dónde saca el recurso, de pronto mejorar la redacción y luego ir y publicarlo en LinkedIn. Ese podría ser un agente. Ahora, se pueden colaborar entre varios sistemas de agentes y es un poco lo que quiero abarcar hoy, cómo funcionan estos sistemas para que luego cuando empecemos a desarrollarlos, pues nos quede claro cuáles son estas características y qué alcance tienen. Ahora, esto también da pie a algo muy interesante y es que según varios artículos, según varios medios, según la mayoría de prensa e insiders, realmente a las grandes empresas como Google, como Anthropic, como OpenAI, les está costando crear mejores modelos o optimizaciones. Si ustedes han visto los nuevos modelos, no son una mejora tan grande como por ejemplo lo que experimentamos cuando fue el salto de GPT-2 al 3, del 3 al 3.5, cuando llegó 4, pero realmente traen una mejora grande, considerables, hacia por ejemplo un GPT-5, no lo están logrando alcanzar. Bien. Y eso tiene que ver con algo muy interesante y eso no sólo tiene que ver con OpenAI, literalmente como veía OpenAI, Google, Anthropic, están teniendo como estos bloqueos en donde ya no está siendo suficiente. No, digamos que el performance de esos modelos, así lo llenemos de más datos, pues no están siendo realmente mejores. Entonces parece, parece, que estamos llegando a un punto en el que, bueno, entonces parece, parece, que estamos llegando a un punto en el que, bueno, llegando como a un tope de lo que podemos entrenar estos Large Language Models. Entonces, ¿qué va a pasar? Hasta aquí ya llegó toda esta innovación de los Large Language Models. Hasta aquí es como el punto que tenemos en este momento. Pues hay varias cosas interesantes. No creo que sea obviamente el final, pero sí las empresas les está costando entrenar mejores modelos a los existentes. Ahora, este señor es uno de los cofundadores de OpenAI y también pues ya ha salido de OpenAI, pero hace poco dio una charla y precisamente, está hablando de esto de que la computación está creciendo. Por ejemplo, tenemos mejor hardware. Por ejemplo, tenemos el nuevo procesador Willow de Google. Tenemos mejores algoritmos, tenemos más clusters, pero la data no está creciendo. Literalmente ellos están diciendo, o sea, toda la, todo el Internet público ya lo consumimos, ya de eso entrenamos a GPT-4, por ejemplo, y los otros, Google y los demás, ya entrenamos con toda la información pública, ya está entrenado. ¿De dónde vamos a sacar más? Hay dos variantes allí. Es como dejar de inyectarle más datos públicos o los que están ahí afuera en Internet, o mejorar la calidad de los datos. Y normalmente mejorar esa calidad de los datos cuesta bastante. Es por eso no están como logrando tener estas mejoras significativas. Sin embargo, si esto es cierto, o al menos él lo dice, dice que entonces, ¿qué va a ser lo siguiente? Precisamente menciona la parte de agentes, la parte de que pueden entender, y pueden como tener una conciencia, no la conciencia humana, pero, o sea, como que sí saben o son conscientes de lo que fueron diseñados y qué objetivo necesitamos. Y normalmente todo esto puesto en un sistema de agentes. Y normalmente los agentes nos sirve para literalmente superar de pronto este bache que tenemos de los language model que no se pueden como tener más. Y de por sí, de pronto vamos a cambiar de approach a tener modelos más específicos y ya voy un poco a hablar de ese punto en específico. Sin embargo, también es verdad que el CEO ahorita de OpenAI dice que realmente no hay muros. Entonces, es un poco raro. O sea, literalmente la prensa, varios insiders dicen, oigan, ya llegamos a esos límites. Pero también están otros que dicen que realmente esos muros o esos límites todavía no los hemos tocado. Así que hay que empezar a verlo. Pero sin embargo, hay mucho furor por el tema de agentes. Huayco Mineros, que es una de las empresas o las inversoras más grandes, pues de la región en específico, literalmente en todas sus nuevas startups que están aceptando, casi que el 80% son agentes. Agentes que reemplazan algo. Agentes que literalmente están haciendo la labor de customer service. Están haciendo la labor, por ejemplo, de hacer pentesting. Literalmente hay un agente que hace todas las pruebas y vulnerabilidades de un sistema en automático. Como que detecta qué cosas puede probar. Y eso lo está haciendo un agente. IBM se está montando el tema de los agentes. Muchas inversiones estas dicen que literalmente hasta ahí, o el 2025, va a ser como la forma en la que vamos a poder por fin llevar de forma operativa AI a las empresas. No sólo como de pronto algún juguete, sino realmente tenerlo en las compañías. Entonces, hay otro concepto o otra forma de definir los agentes que me gusta, que es de Amazon. Y es que los agentes son autónomos, o sistemas autónomos inteligentes, que pueden hacer una tarea en específica sin una intervención humana. Sin embargo, hay un concepto que se llama Human in the Loop, o el Human Layer, en donde de pronto todavía no tenemos tanta confianza en un agente. Entonces, nosotros como que lo dejamos operar. Lo dejamos como, hey, opera. Pero cuando ya llega una decisión de pronto compleja, como no sé, una transacción bancaria, como por ejemplo habilitar o deshabilitar ciertas cosas, porque normalmente los agentes sólo se les da como permiso de lectura, pero muy pocas veces se les da permiso de escritura, de eliminación, de edición. Y de pronto cuando llegan esas tareas críticas, necesitamos que un humano vaya y revise si lo que hizo el agente está bien, y le dé como, ok, sigue haciendo lo que, o cómo vas, vas bien, y hacer un check. Sin embargo, aquí para esto vamos. Son literalmente agentes que pueden realizar una tarea sin intervención humana. De nuevo, ahorita estamos como en nuestras primeras épocas de los agentes, entonces ahí el concepto de human in the loop es interesante, es importante, y de por sí también hay varias como librerías que nos dejan en nuestro sistema de agentes poner un humano para que él apruebe o no cierta decisión, de pronto integrado a Slack, de pronto integrado ya a una interfaz gráfica, etc. Bien. Pero para definir precisamente cuáles son las características de un agente, estas son las... cuatro, y aquí me equivoqué en la enumeración, uno, dos, cuatro y cinco, pero básicamente son cuatro, ¿no? La primera es como que él pueda reflexionar o... esto tiene que ser como a... como que él puede saber en base a la conversación, en base al historial, en base a lo que se está resolviendo, reflexionar de alguna manera y crear un plan para ejecutar esta tarea. Ahora, esta tarea puede necesitar de herramientas, ¿bien? Entonces, esa es la otra categoría. Esa es la primera característica, que un agente puede conectarse a APIs, conectarse a base de datos, conectarse a la web, si nosotros queremos, para ejecutar ciertas tareas. Entonces, el segundo feature o característica es que pueda utilizar herramientas. Conectarse a sistemas. Que pueda ejecutar un plan y lo pueda seguir o lo pueda refinar. Que él mismo se pueda evaluar. Esa es otra estrategia. Hay una estrategia que se llama... bueno, la Language Model como jurado, donde, literalmente, antes de como determinar la tarea, uno le da un check a más y el mismo como agente se evalúa a sí mismo, diciendo, creo que sí cumple esta la tarea o no, y si sí la cumplió, pues listo, done. Pero si no, pues como que vuelve a refinar, a hacer otras cositas para terminar como el objetivo. Y lo otro es que pueden ser colaborativos. Es decir, un agente puede colaborar con otro. Esas son como las cuatro características importantes de los agentes y los que deberíamos tener. Y creo que sí le pondría una quinta, o al menos en estas primeras etapas, que es human in the loop. Como una persona en todo este ciclo, al menos en estas primeras etapas, es importante. Es una de esas características de los agentes. Pero esto ya lo había estado trabajando, o para que lo logremos ejemplificar mejor, Microsoft ya había lanzado antes de GPT-4, que son estos modelos multimodales, es decir, que pueden analizar, es decir, que pueden analizar fotos y texto en un mismo modelo. Normalmente había modelos separados para esto, pero luego llegaron los modelos multimodales. Entonces podían hacer más de una cosa a la vez, no solo texto, podían generar. Si ahorita en chat GPT yo le digo, génerame una imagen, él me genera la imagen. O si yo le subo una imagen, es más, con las otras en esta semana, Google y OpenAI ya lanzaron características en donde con video, ya es como consciente de lo que está pasando en el video y podemos hablar al respecto. Pero básicamente Microsoft había lanzado un paper antes de existir el multimodal de cómo con un Large Language Model sencillo, o sea, con los que había en ese momento, un GPT-3, GPT-3.5, podríamos tener sistemas multimodales. Sin embargo, esto es muy parecido a cómo funcionarían los agentes. Es decir, por ejemplo, yo tengo una tarea en específico. Acá, por ejemplo, la persona dice, puedes describirme como esta imagen y contar cuántos objetos hay en la tarea. Y en la foto, eso ya lo podría hacer GPT-4 sin ningún problema, porque es multimodal. Sin embargo, en ese momento, una approach era, ok, pues mira, hagamos que la Language Model tome como que divida esa tarea en varias específicas chiquitas, las voy a planear, voy a escoger qué modelo ejecutar y luego las ejecuto en un orden específico. Entonces, como que de acuerdo a esa tarea, como que la divide, luego va a varios modelos para resolver como eso y luego lo vuelve a unir en una sola respuesta. Acá hay otro ejemplo de pronto un poco más conciso en donde dice, mira, por favor, generame una imagen donde una niña esté leyendo un libro y su pose sea igual a la del niño en la imagen. Supongamos que se suba una imagen. Por favor, describa la nueva imagen con tu voz. Entonces, aquí le estamos pidiendo muchas cosas, que literalmente crea una imagen, que me dé la respuesta en voz, que, pues de acuerdo a una foto, emule esa pose y entonces la nueva foto la haga con esa pose, etc. Entonces, esto, por ejemplo, en la propuesta de Microsoft, lo que harían es hacer una primera etapa de Tax Planning, es decir, ok, qué modelos, qué necesito para poder resolver esta tarea. Luego que yo ya tengo ya las tareas separadas, selecciono cuál es el modelo, selecciono cuál es el modelo más acorde para ejecutar esa tarea. Por ejemplo, utilizar el modelo de Facebook Open Source para reconocimiento de la pose del cuerpo y luego utilizar, no sé, Stable Diffusion para generar la imagen. Entonces, es como se empiezan a colorear varios modelos. Luego, pues que ya sé qué modelos escoger, ejecuto, hago la ejecución y luego como reúno y le doy la respuesta. Si bien esto era una forma para que nosotros pudiéramos tomar, tener modelos multimodal, que ya los tenemos ahora, algo así van a funcionar o están funcionando los agentes. Es decir, nosotros vamos a hacer una planificación, escoger qué agente es el mejor para resolver una tarea en específico, con unas herramientas en específicas y luego entonces generar una respuesta. Entonces, acá hay algo muy interesante y es, ok, no necesitamos modelos más grandes o tal vez no tan generalistas, sino de pronto vamos a tener modelos más especiales. Y la coordinación de esos modelos va a ser lo que tengamos agentes o sistemas de agentes poderosos. Bien, entonces, por ejemplo, tenemos Zero One Preview de OpenAI, que éste literalmente puede razonar más antes de responder. ¿Cuál es el costo? Que se demora más. No es tan rápido como un GPT 3.5 Turbo o el 4. La respuesta se demora más, pero razona y eso nos podría servir mucho para hacer toda la planificación del agente. Entonces, aquí empezamos a tener, es como unir varios modelos especializados para luego ponerlo a disposición en nuestro sistema de agentes. Tenemos, por ejemplo, literalmente modelos enfocados a código, como CodeLama, bien, de meta, en donde si yo tengo una parte de la gente que necesita escribir código, pues realmente yo podría conectar a CodeLama, que es especialista en código, y entonces podría generar recomendaciones, code reviews, bueno, lo que sea que es, pero sabemos que él es especialista en código. También está Cloud 3.5 Sonnet, que literalmente, por ejemplo, es el que más yo uso o el que usa Cursor, que es el ID que yo utilizo para programar, y él utiliza por detrás este modelo y es muy bueno haciendo predicciones de código. Entonces, lo que vemos es como modelos ya más específicos en vez de modelos más grandes, modelos más específicos y ya queda a un sistema de agentes que sepa cómo evaluar, cómo ejecutar, y cuándo utilizar cada modelo, bien. Bueno, y aparte de los, las language model, pues tenemos nuevos modelos ya de otras características, por ejemplo, como los de video, ¿no? Entonces, ahí Google lanzó su nueva versión de sus modelos de generación de video a partir de un texto que también, por ejemplo, Sora de OpenAI. Entonces, vamos a tener como estos modelos específicos que ya se empiezan es a focalizar en alguna, en resolver bien una tarea, que simplemente entrenar uno más, que sea más grande, muy generalista. Esto para los agentes es muy beneficioso, o sea, tener modelos especializados hace que literalmente podamos resolver tareas muy complejas, pero necesitamos poderlos orquestar, que se colaboren entre sí y pues poder ya ejecutar una tarea. Entonces, es una manera como divide y vencerás, ¿bien? Entonces, ah, y otra cosa, también tenemos mejores tools. Por ejemplo, con toda esta cosa pues de AI, hemos tenido mejores herramientas, entonces ya no solo tenemos modelos más enfocados y no de pronto más generalistas, sino enfocados en algo específico, sino que también tenemos mejores tools para que ellos se conecten, pues herramientas y pues hagan actualizaciones, hagan scripts, modifiquen cosas, etc. Por ejemplo, este es un sistema que es pensado como en un Selenium, en un Playwright, en un Cypress, básicamente es un browser que corre en la nube que está pensado para agentes. Entonces, literalmente yo puedo decir, digamos, que yo tengo un agente que revista todos los hoteles o todos los sitios de hoteles para buscar la reservación. Entonces, literalmente yo, esta infraestructura, yo puedo conectar este tipo de sistemas a mi sistema de agentes para que él vaya y haga como Scrapping o busque, literalmente, y luego ya me entrega esa información y luego pues simplemente yo la uso. Entonces, cada vez van saliendo también tools más especializadas a las cuales yo le puedo dar permiso a mis agentes, para que vayan y utilicen esas tools. También tenemos, por ejemplo, Anthropy, que creó su nuevo protocolo, el Model Context Protocol, que es una forma de Cold Functions, pero mucho más avanzado. Literalmente le dan como casi acceso a todo un sistema y literalmente con eso empiezan a jugar con un agente. Entonces, no solo tenemos modelos especializados, sino también mejores herramientas. También está PGAI, que es como un fork de Postgres, en donde normalmente, por ejemplo, si yo quiero hacer un RAC, o sea, un alimentar de mi propia información, por ejemplo, los documentos de la empresa, por ejemplo, una base de datos de todos los productos que hay en la compañía, y yo quiero hacer un bot que de acuerdo, o un agente que de acuerdo a toda la información que yo le ingrese, realmente pues se pueda contestar con base a esa información. Normalmente mantener ese sistema es complejo, porque tú necesitas estar vectorizando esa información, ponerla en una base de datos vectorial, y luego unirla y como inyectarle ese conocimiento a un Large Language Model. Bien, es como una especie de FI Tuning, pero realmente no es un FI Tuning, es simplemente pues un RAC, un sistema de RAC. Ahora, ¿a qué voy con esta herramienta? Que hacer eso es complejo. Normalmente tenemos que saber cuando se crea un nuevo producto, vectorizarlo y pues pasarlo a nuestra base de datos vectorial. Luego si se elimina, se actualiza, necesitamos como estar haciendo estas sincronizaciones para que nuestro sistema funcione bien. Bien, pues PGAI es un floor de Postgres en donde hace todo esto en automático, aprovechando como las bases de datos transaccionales, crea como una serie de pues relaciones, y literalmente si yo elimino, o creo, o actualizo, en automático como que en la misma base de datos, que ya se puede, por ejemplo, en base de datos como PGAI, pues hacer un PGAI, y luego en la misma base de datos, en base de datos como Postgres, tenemos PGAI Vector, entonces ahí mismo estoy guardando los vectores, y con PGAI podría estar como ahorrándome todo un proceso de extracción, de sincronización, etcétera. Bien, y luego entramos a la parte de colaboración. Ok, entonces, ¿cómo entonces empezamos a ver esos sistemas de agentes? Pues nosotros tenemos como un agente, un asistente general, pero luego podemos empezarlo a dividirlo, especializarlo. Entonces hay un agente especial en vuelos, pero hay uno especial en hoteles, y hay otro en renta de carros, y hay otro en excursiones. Cada agente, literalmente, tiene unas tools, por ejemplo, el de vuelos puede tener esta tool, se conecta a la tool esta que tiene el browser en la nube para buscar cosas, o el de excursiones tiene un rack donde yo indexé todos los lugares turísticos, y también puedo, el sistema de agentes también me deja hacer algo muy interesante, y es que no me caso solo con un modelo. Tal vez, por ejemplo, a mí me pasa, por ejemplo, yo estaba desarrollando un sistema de agentes y para hacer call functions me funcionó muy bien OpenAI. Bien, pero probé Mistral y no me fue tan bien haciendo call functions, pero sí fue muy bueno manteniendo un rack, ¿no? Como que yo le aumento esa información y él responde en base a esa información. Ahí no necesito un call function, solo necesito inyectarle el conocimiento que, pues, vectoricé. Entonces, aquí puedo tener un híbrido, ¿no? Entonces, en un sistema de agentes yo podría tener un Mistral, un Lama Code, un OpenAI, un Zero-One Preview para ciertas cosas que realmente de pronto necesiten más razonamiento. Entonces, yo como que empiezo a dividir, empiezo a focalizar mis, digamos, cada una de las tareas de la gente y ellos pueden empezar a colaborar entre sí. Entonces, por eso es que ese auge o ese hype en cuanto a los agentes, porque, primero, que todo, ya no necesitaríamos, no sería un problema que no podamos seguir entrenando modelos como más generales y más grandes, sino mejor que estemos más especializados para resolver cosas en específico y luego en un sistema de multiagentes dárselos y empezar a conectarlos. Normalmente este tipo de arquitectura tiene mucho más beneficio que simplemente pegarle a un modelo general que creamos que va a resolver todo. Bien. Y aquí, de por sí, hay una, esta gráfica que es muy interesante y es, ok, mira, de pronto, ¿dónde tú necesitas una arquitectura como esta, tan compleja? Pues si nosotros tenemos estos ejes, por ejemplo, arriba el complejo, el simple, el de razonamiento general o dominio específico, pues, por ejemplo, si yo tengo algo simple pero general, un Large Language Model me puede servir sin problema. Es más, si yo sigo teniendo algo complejo, pero necesitamos razonamiento general, no un conocimiento específico, un Large Language Model me puede servir. Bien. Pero ahora, si yo necesito, si me empiezo a mover a que realmente mi agente tiene que tener un dominio en específico, no sé, les mencionaba, el de pentesting, ¿no? Un agente que realmente sepa cómo contestarle al cliente de acuerdo a conectarse a su base de datos, resolver issues, entonces ahí ya no tengo que tener un razonamiento general, necesito especializarlo y que responda bien. Entonces ahí hay dos formas. Si es algo simple, con Promo Engineering, podemos resolverlo. Pero si yo necesito darle ya herramientas, tool rack, pues ahí ya me voy a un sistema en donde tengo que tener como una arquitectura de agentes. Esa sería como un poco la decisión en de cuando yo necesito un sistema como complejo como estos o simplemente con un Large Language Model o un Promo Engineering me podría funcionar. Bien. Y ahora, ¿cómo yo llevo esto a la realidad? ¿No? Porque eso es teórico, digamos. Pues ahí es donde entran los frameworks, los frameworks nuevos que están saliendo para orquestar y manejar agentes que cumplan literalmente con esas cinco características que puedan reflexionar, que puedan colaborar entre sí, que tengan acceso a herramientas, que tengan Human in the Layer y otro más que se me escapó por ahí. El de Plane, ¿no? Que puedan planear y poder decidir. Bien. Entonces, aquí les voy a presentar como los frameworks más útiles que ahorita están saliendo para crear este tipo de arquitecturas. Sin embargo, tenemos unas etapas muy tempranas de estos frameworks y todavía no sabemos quién es el ganador. Así que simplemente están saliendo. Literalmente es muy parecido a la época en que salían muchos frameworks de frontend. Siguen saliendo. Sin embargo, como que ya hay algo establecido, como que Angular React View o como en el lado de backend, no sé, PHP Laravel, Python, FACPy o Django y Ruby Runer Rails. Es como que ya uno los tiene en la mente. Y en frontend es como Angular React View. Pues ahorita han salido muchos agentes de frameworks para tener y resolver estos problemas. Yo desde mi punto de vista me parece que el que más me gusta y el que vamos a aprender hoy y vamos a hacer básicamente código es LandGraph. Bien. Literalmente este es el que creo yo que me permite hacer todo esto que estaba mencionando. Tener un sistema, tener el control de estos agentes. Y que de pronto no sea una caja negra, porque muchos de estos frameworks a veces son una caja negra. Es decir, simplemente como que yo creo varios agentes y él mira cómo los orquesta. Como llegó a la decisión de qué agente debía tomar la tarea, puede ser una caja negra. Y esa caja negra de pronto es donde nosotros generamos más valor. Y tener literalmente la decisión de cuándo sí y cuándo no. Y que nosotros tengamos control sobre nuestro sistema de agentes. Creo que es algo muy interesante. Sin embargo, eso hace que de pronto sea un poco más verbose. Es decir, hay que escribir un poquito más de código. Porque al final nosotros somos los que estamos controlando el sistema de agentes. Entonces creo que ahí es donde funciona muy bien LandGraph, creado por LandChain, en donde me da este control. Y es el que voy a estar grabando y haciendo contenido. Sin embargo, otro que yo he escuchado mucho es Crew.ai. Este es otro sistema también. Bueno, lo bueno de LandGraph es que es un sistema que es muy fácil de usar. Bueno, lo bueno de LandGraph es que es muy fácil de usar. Yo en 사실 se haیا algo perfecto. Un design contemporary que me encantaría hacer para aplicar mockups. Pero ya que eso se lleva suficiente tiempo,��co Eeven, aunque en lo sosto se comentaba alguna來 plays al flashback, no tengo una id ent. Pues no tengo una id da para ver un цветito. Eso, digamos la verdad los gadgets se dependen mucho y es frustrable. o estableciéndose como buenos frameworks de agentes es Landgraf y Crew.ai y los dos me parecen buenas opciones me voy más o me inclino más por Landgraf pero Crew.ai está chévere ahora, luego está Swarm de OpenAI bien, literalmente OpenAI está lanzando un framework experimental para orquestar agentes este es el que me parece que es un poquito una caja negra es decir, yo no tengo control de cómo literal, bueno, no tanto control tengo una especie de control pero no tanto como el que yo quisiera como que a veces es una caja negra y no se sabe cómo fue que llegó o por qué ese agente tomó la decisión en específico y ahí es donde yo creo que hay que tener bastante control, ¿no? para nuestros sistemas de agentes este todavía no está estable y de pronto lo que no me gusta mucho de este es que obviamente es de OpenAI y solo podemos utilizar modelos de OpenAI bien, creo que por ahí había un pull request para hacer que aceptar otros modelos no sé si lo vayan a aceptar o si esté dentro del roadmap del framework pero por ahora solo soporta que consumamos modelos de OpenAI cosa que de pronto sería una desventaja en tener un sistema de agentes en el cual yo puedo elegir un Lama Code un OpenAI para este punto un Cloud para este otro entonces a mí me parece que es una desventaja luego literalmente está Pydantic esta librería muy famosa en Python para crear esquemas y validarlos pues también lanzó su framework de agentes no lo he experimentado muy bien pero al menos hasta que viene la casa de Pydantic y ellos son bastante buenos entonces es otro de esos frameworks de agentes que han estado saliendo está el de Microsoft Autogen este me parece interesante porque dentro de su SDK hay una forma como de comandos pero no comandos como de códigos sino comandos en donde si yo ejecuto mi agente en un servidor por ejemplo literalmente puedo ejecutar como manipular aplicaciones ese tipo de cosas de por si creo que este framework que es Open Source y es de Microsoft Autogen lo están utilizando para construir varios de los productos que van hacia el cliente final dentro de la capa de Microsoft 365 que es como la capa en donde yo puedo hacer de Microsoft el CRM de Microsoft el ERP de Microsoft en donde yo gestiono facturación, clientes hay una versión de Microsoft para eso y ellos están poniendo a disposición varios agentes y esos agentes están desarrollados con su framework que es Autogen la documentación es feísima pero promete, promete digamos promete y es de Microsoft luego Amazon Amazon también está se metió en este cuento y está creando también un framework se llama Multi Agent Orchestrator este me pareció interesante el prompt que utilizan porque como es Open Source uno puede saber qué prompt están haciendo para saber a cuál agente definirlo aquí es donde me interesó y aquí es donde se va a hacer el primer paso y luego lo podemos chismosear y ver si de pronto nos copiamos esa misma estrategia para implementarlo en LandGraph pero Amazon también está en el juego y IBM IBM también tiene su sistema de agentes bien entonces esto yo diría que son como las formas todos están en Python todos todos todos todo esto de IA está en Python creo que el único que tiene una API que nos dejaría desarrollar con TypeScript es LandGraph ahí bien porque pues no sólo se ganan a la comunidad de Python sino también a la de TypeScript bien entonces esos son los ecosistemas que hay en este momento o el ecosistema y es como nosotros vamos a empezar a desarrollar agentes aquí literalmente vamos a empezar en este canal vamos a empezar a desarrollar agentes con LandGraph y espero que esta introducción te haya servido para de pronto aterrizar qué es un agente qué características tiene que tener un agente por qué modelos especializados son como una gran opción para romper esas barreras si realmente ya no tienes una API o realmente ya no tenemos o no podemos entrenar mejores modelos o al menos esas empresas ya se están encontrando con estos topes pues al final toda la approach de agentes es algo muy interesante porque se vuelve en algo que sí podemos dividir y desplegar para nuestros propios sistemas así que nada si te gustó dale like vamos a empezar a subir mucho contenido acerca de LandGraph en este canal así que suscríbete y mantente pendiente